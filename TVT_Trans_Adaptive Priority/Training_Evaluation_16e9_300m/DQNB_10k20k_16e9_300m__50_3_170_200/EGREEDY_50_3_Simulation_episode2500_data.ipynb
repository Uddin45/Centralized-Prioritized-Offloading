{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_2c3s5mPjSr"
   },
   "source": [
    "+++++[link text](https:// [link text](https://))### 1. Read environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32923,
     "status": "ok",
     "timestamp": 1705362321730,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "jc1n8GcSNWxH",
    "outputId": "abef88a4-81ad-407a-e969-720aa69ed4ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1705362321766,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "4v2mf8TUrIW6",
    "outputId": "edd8159b-c99d-48b5-bcfc-37a584fe662b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\uddin81\\Documents\\Customize_RL_MEC Env\\Test for Journal\\Final Result\\backup\\Test_1_V8_1_10k20k_16e9_300m__50_3_170_200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pw1W2pj5R-9H"
   },
   "outputs": [],
   "source": [
    "# ! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1705362324095,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "yDgZsDSYPjSu",
    "outputId": "33fb275d-ff33-4095-d717-846af1fc4bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "{}\n",
      "119\n",
      "72\n",
      "20\n",
      "{'data_size': 14461, 'circle': 8925963, 'user_index': 47, 'priority': 1, 'user_distance': [160.23217433072116, 140.4366621429166, 440.1937783033022], 'delta_max': 0.198}\n",
      "{'data_size': 19789, 'circle': 8703684, 'user_index': 49, 'priority': 2, 'user_distance': [122.24713924284066, 421.9559576229962, 721.9067095504939], 'delta_max': 0.185}\n",
      "{'data_size': 11833, 'circle': 8940746, 'user_index': 48, 'priority': 3, 'user_distance': [124.59297045116797, 176.0931545936179, 475.91405726624424], 'delta_max': 0.177}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALZLc1DEPjSw"
   },
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1705362324096,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "tLC_64NIPjSx",
    "outputId": "449b79d3-3ec3-41eb-e40f-0841df76c732",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{47: {'speed': array([14591.95814986,  7714.87010476,   475.9030547 ])}, 49: {'speed': array([1.41097203e+05, 6.16967706e+03, 1.22198266e+02])}, 48: {'speed': array([1.98914169e+04, 6.21673705e+04, 1.29109362e+01])}}\n",
      "Action size: 15\n",
      "Action space: [(0, 0.1), (0, 0.325), (0, 0.55), (0, 0.775), (0, 1.0), (1, 0.1), (1, 0.325), (1, 0.55), (1, 0.775), (1, 1.0), (2, 0.1), (2, 0.325), (2, 0.55), (2, 0.775), (2, 1.0)]\n",
      "Observes a state with length: 27\n",
      "state size: 27\n",
      "The state for the first agent looks like: [9.32633951e-02 9.01812084e-01 1.27134484e-01 4.93090078e-02\n",
      " 3.94330235e-02 3.97338039e-01 3.04169832e-03 7.81020960e-04\n",
      " 8.25192708e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.00000000e-01 1.00000000e+00 2.50000000e-01 7.23050000e-01\n",
      " 8.92596300e-01 9.90000000e-01 3.33333333e-01 9.89450000e-01\n",
      " 8.70368400e-01 9.25000000e-01 6.66666667e-01 5.91650000e-01\n",
      " 8.94074600e-01 8.85000000e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "\n",
    "task=mec_evn.get_task()\n",
    "\n",
    "states = mec_evn.get_state(task)\n",
    "print(mec_evn.trans_speed_matrix)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vapCU_9PjSy"
   },
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF7ASsRcPjSz"
   },
   "source": [
    "### 6. Take Actions with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dq2lQI0LPjSz"
   },
   "outputs": [],
   "source": [
    "epoch_no =3000\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OmtnPud5PjS0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from energy_greedy_agent import GreedyAgent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PSLBUj5oPjS1"
   },
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n",
    "model_path = os.path.join(current_directory, 'model_greedy_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 37.58324094593227), (37.58324094593227, 75.16648189186454), (75.16648189186454, 112.74972283779681), (112.74972283779681, 150.33296378372907), (150.33296378372907, inf)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "Mec_2_Mec=300\n",
    "Range=Mec_2_Mec/2\n",
    "max_dis=math.sqrt(10*10+Range*Range)\n",
    "\n",
    "\n",
    "\n",
    "bucket_ranges = [(10, 0.25*max_dis) ,(0.25*max_dis,0.5*max_dis),(0.5*max_dis,0.75*max_dis),(0.75*max_dis,1*max_dis),(1*max_dis,float('inf'))]\n",
    "\n",
    "print(bucket_ranges)\n",
    "# Function to determine the bucket for a given value\n",
    "def find_bucket(value, ranges):\n",
    "    for start, end in ranges:\n",
    "        if start <= value <= end:\n",
    "            return (start, end)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "egreedy_agent = GreedyAgent(action_size=action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250\tAverage Score: 23.8322\tmeantaskP1: 0.1786\tmeantaskP2: 0.1616\tmeantaskP3: 0.2492\tmeanenergyP1:                     0.3865\tmeanenergyP2: 0.3833\tmeanenergyP3: 0.3835 \tmeanlatencyP1: 0.1355 \tmeanlatencyP2: 0.1244 \tmeanlatencyP3:                     0.0969 \tmeandatasize: 14786.8980 \tmeandatasizeP1: 14841.4364 \tmeandatasizeP2: 14782.9828 \tmeandatasizeP3: 14753.4940 \tmean_tran_latencyP1: 0.0235                      \tmean_tran_latencyP2: 0.0330  \tmean_tran_latencyP3: 0.0387  \tmean_comp_latencyP1: 0.1120                      \tmean_comp_latencyP2: 0.0914 \tmean_comp_latencyP3: 0.0582\n",
      "mean_task_till_this_window 0.179944 T1:: 0.14816380512296762 T2:: 0.17564341835596228 T3:: 0.2143127546553339\n",
      "task_select_P1 317.352 task_select_P2 332.088 task_select_P3 350.56\n",
      "total_task_done_P1:: 46.984 total_task_done_P2:: 58.16 total_task_done_P3:: 74.8\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.232893747621419 0.19010869335809177 0.12101651514356454 0.057498018362896426 0.019969999877181194\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.25594445309880387 0.2188026269440649 0.14981113009070698 0.08692627097700165 0.0725938633859821\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.2813831196353324 0.25473025967043395 0.1988580521057206 0.13274451767887524 0.1372465168203178\n",
      "mean_task_P1_select_by_bucket_51_10_100 76.872 81.068 79.472 67.588 12.352\n",
      "mean_task_P2_select_by_bucket_51_10_100 79.492 84.388 82.148 69.88 16.18\n",
      "mean_task_P3_select_by_bucket_51_10_100 82.076 87.3 86.2 73.056 21.928\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002394592774526564 0.020204328257477693 0.05066718242246121 0.08060531694869018 0.021798309700553263\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0028212524051294667 0.020919817810592666 0.05170816279365408 0.08244278644214646 0.04265819542336638\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0027451009994772695 0.021361536721401682 0.053031939697099684 0.08079099152410266 0.04845431905081313\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.37224927692691007 0.3846244943446185 0.3994538348634993 0.4145927741404878 0.43649283869964695\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.37008854883885123 0.38052577586705444 0.39605578168622874 0.4211872208684527 0.4324601668665175\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.36996631461082585 0.3850811213746849 0.3999850295428566 0.4236472295588875 0.43065979504457735\n",
      "mean_data_P1_data_by_bucket_51_10_100 14944.42058872808 14921.364810455963 14824.126070160199 13981.13441088911 2822.436\n",
      "mean_data_P2_data_by_bucket_51_10_100 15015.823105102729 14940.018230588268 14761.434102280056 14636.361755988457 9487.201133333332\n",
      "mean_data_P3_data_by_bucket_51_10_100 14931.233495963197 15092.078430741483 14889.316878898042 14660.146148904552 13585.83186984127\n",
      "all_tran 0.07522830981294737 all_comp 0.3675336776141153\n",
      "all_tran_P1 0.07675297151553394 all_tran_P2 0.07486284607547329 all_tran_P3 0.07448766200134424\n",
      "all_comp_P1 0.38421879011541954 all_comp_P2 0.36962899163525004 all_comp_P3 0.34982354232385066\n",
      "all_data_P1 14988.68025604352 all_data_P2 15010.525150169338 all_data_P3 15002.551175627908\n",
      "epi_comp_energy 0.371681502080468\n",
      "epi_comp_freq 2013775600.0\n",
      "epi_comp_latency 0.3675336776141153\n",
      "Episode 500\tAverage Score: 24.1780\tmeantaskP1: 0.1573\tmeantaskP2: 0.1506\tmeantaskP3: 0.2622\tmeanenergyP1:                     0.3871\tmeanenergyP2: 0.3831\tmeanenergyP3: 0.3809 \tmeanlatencyP1: 0.1338 \tmeanlatencyP2: 0.1199 \tmeanlatencyP3:                     0.0982 \tmeandatasize: 14873.4490 \tmeandatasizeP1: 14964.7047 \tmeandatasizeP2: 15021.8575 \tmeandatasizeP3: 14736.8803 \tmean_tran_latencyP1: 0.0239                      \tmean_tran_latencyP2: 0.0323  \tmean_tran_latencyP3: 0.0341  \tmean_comp_latencyP1: 0.1099                      \tmean_comp_latencyP2: 0.0875 \tmean_comp_latencyP3: 0.0640\n",
      "mean_task_till_this_window 0.18484 T1:: 0.14694966097606216 T2:: 0.18100728950107783 T3:: 0.22267046070726418\n",
      "task_select_P1 312.408 task_select_P2 335.228 task_select_P3 352.364\n",
      "total_task_done_P1:: 45.948 total_task_done_P2:: 60.604 total_task_done_P3:: 78.288\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.22990538992145024 0.19583943868971804 0.11449405892650415 0.05751296628416221 0.02164612381082969\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.2598903594379225 0.22019937870718656 0.1617347688396803 0.09225929566085171 0.06947229059419664\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.2962478572724179 0.26178596386501274 0.20367650843427823 0.13826551490910718 0.14364497995706402\n",
      "mean_task_P1_select_by_bucket_51_10_100 75.352 79.68 77.86 67.484 12.032\n",
      "mean_task_P2_select_by_bucket_51_10_100 80.452 85.444 82.592 69.876 16.864\n",
      "mean_task_P3_select_by_bucket_51_10_100 82.616 88.636 85.8 72.976 22.336\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002492668253250217 0.02004020832782736 0.05141065537777463 0.08049170966048526 0.026454255997853313\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0026624284301069254 0.02061182582586175 0.05253949088891099 0.08225255101461883 0.03802865080321898\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0030752874691328527 0.02117730059255713 0.054058404839269214 0.07972931178133937 0.04802987392083469\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.3685251642269773 0.3769136551542574 0.39618250600793864 0.4180618262319524 0.43328538574886216\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.3697534346290463 0.3807241276577066 0.39459472295708053 0.42345931015751354 0.42946068724138126\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.37073244702044095 0.3846873529176227 0.40040592627898336 0.42068871038933836 0.4421563477631478\n",
      "mean_data_P1_data_by_bucket_51_10_100 15014.046039981231 14933.786405292063 14715.359548572056 14013.590867032968 3203.294\n",
      "mean_data_P2_data_by_bucket_51_10_100 14981.01190783178 14864.728445569906 14885.608818562292 14450.832643056941 9061.196914285714\n",
      "mean_data_P3_data_by_bucket_51_10_100 15059.501880347305 15003.71552306775 14911.01974956998 14784.406106016258 14243.377547619046\n",
      "all_tran 0.07557622830505344 all_comp 0.3590900970081392\n",
      "all_tran_P1 0.07769504896777335 all_tran_P2 0.07560931278641604 all_tran_P3 0.07390504465787547\n",
      "all_comp_P1 0.3787448890134572 all_comp_P2 0.36064634474494056 all_comp_P3 0.34012347753471717\n",
      "all_data_P1 15011.101839014098 all_data_P2 14994.960442774525 all_data_P3 15007.097004622916\n",
      "epi_comp_energy 0.3706702811546924\n",
      "epi_comp_freq 2013342800.0\n",
      "epi_comp_latency 0.3590900970081392\n",
      "Episode 750\tAverage Score: 24.3972\tmeantaskP1: 0.1765\tmeantaskP2: 0.1387\tmeantaskP3: 0.2472\tmeanenergyP1:                     0.3908\tmeanenergyP2: 0.4192\tmeanenergyP3: 0.3818 \tmeanlatencyP1: 0.1317 \tmeanlatencyP2: 0.1201 \tmeanlatencyP3:                     0.1018 \tmeandatasize: 14879.4526 \tmeandatasizeP1: 14996.7578 \tmeandatasizeP2: 14774.6524 \tmeandatasizeP3: 14817.8517 \tmean_tran_latencyP1: 0.0242                      \tmean_tran_latencyP2: 0.0318  \tmean_tran_latencyP3: 0.0345  \tmean_comp_latencyP1: 0.1075                      \tmean_comp_latencyP2: 0.0883 \tmean_comp_latencyP3: 0.0673\n",
      "mean_task_till_this_window 0.18839599999999998 T1:: 0.1509841836727424 T2:: 0.1854228915562415 T3:: 0.22513995166293901\n",
      "task_select_P1 311.82 task_select_P2 331.384 task_select_P3 356.796\n",
      "total_task_done_P1:: 47.076 total_task_done_P2:: 61.18 total_task_done_P3:: 80.14\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.23859443651341916 0.19609149549090865 0.12084928770743074 0.05728683170943193 0.02739781147644925\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.2619239141801021 0.23314349102568713 0.1621201552999484 0.09526912749410164 0.07416273688543325\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.29991407635900313 0.2635536010740723 0.20035314119422 0.1432505117566543 0.14819109847103504\n",
      "mean_task_P1_select_by_bucket_51_10_100 75.228 79.212 78.012 67.132 12.236\n",
      "mean_task_P2_select_by_bucket_51_10_100 80.228 83.372 81.78 69.564 16.44\n",
      "mean_task_P3_select_by_bucket_51_10_100 84.912 89.676 86.572 73.588 22.048\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002751460555324125 0.019661987321794725 0.050092559064163864 0.08149608293702203 0.03315706023823809\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.002949220635644067 0.0205605437097066 0.05318675410180596 0.08153453441873353 0.04447127031831654\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.002929708430999108 0.021687166225743154 0.053874032936480534 0.08058726305616697 0.04914126561802099\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.37267523642585443 0.3876248699546753 0.3964260779126936 0.4166024871133994 0.44344492517209005\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.3717788599591981 0.38133317041926207 0.4001780702583229 0.4206876800935196 0.4262362236256269\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.3709311091576618 0.3790121851679406 0.40189047383679866 0.4251971149412798 0.432939793037109\n",
      "mean_data_P1_data_by_bucket_51_10_100 15029.588469050515 14923.499284444631 14817.0365281222 14210.029395238094 4041.0486666666666\n",
      "mean_data_P2_data_by_bucket_51_10_100 15042.690900186557 14929.945118818297 14769.215083206456 14514.546270584971 9984.473761904761\n",
      "mean_data_P3_data_by_bucket_51_10_100 15078.707484548766 14906.828065812784 14877.427208312833 14720.817580384142 14318.409201587303\n",
      "all_tran 0.07521334997082241 all_comp 0.35515068318518356\n",
      "all_tran_P1 0.07718063168386939 all_tran_P2 0.07479209853128327 all_tran_P3 0.07415851173061386\n",
      "all_comp_P1 0.37272883793031875 all_comp_P2 0.3586069245551905 all_comp_P3 0.3356946901554118\n",
      "all_data_P1 15000.855910503871 all_data_P2 15009.839740611978 all_data_P3 14996.62206388348\n",
      "epi_comp_energy 0.37226694921579084\n",
      "epi_comp_freq 2014023600.0\n",
      "epi_comp_latency 0.35515068318518356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tAverage Score: 25.5347\tmeantaskP1: 0.1725\tmeantaskP2: 0.1338\tmeantaskP3: 0.2472\tmeanenergyP1:                     0.3881\tmeanenergyP2: 0.4109\tmeanenergyP3: 0.3872 \tmeanlatencyP1: 0.1306 \tmeanlatencyP2: 0.1181 \tmeanlatencyP3:                     0.1009 \tmeandatasize: 14836.4971 \tmeandatasizeP1: 14882.3467 \tmeandatasizeP2: 14962.8956 \tmeandatasizeP3: 14746.5883 \tmean_tran_latencyP1: 0.0239                      \tmean_tran_latencyP2: 0.0345  \tmean_tran_latencyP3: 0.0316  \tmean_comp_latencyP1: 0.1067                      \tmean_comp_latencyP2: 0.0836 \tmean_comp_latencyP3: 0.0693\n",
      "mean_task_till_this_window 0.212596 T1:: 0.17408005140172136 T2:: 0.20957277246734912 T3:: 0.2499908924575401\n",
      "task_select_P1 310.028 task_select_P2 330.116 task_select_P3 359.856\n",
      "total_task_done_P1:: 53.776 total_task_done_P2:: 68.924 total_task_done_P3:: 89.896\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.2678521142653965 0.2269896035448489 0.14498220761884476 0.0662591643468786 0.029622423070565486\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.2960805376011682 0.2625673417813749 0.18185136016349435 0.107712594013622 0.08662043698029834\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.3244049590230384 0.2967380150735177 0.23069702823103053 0.15501212403184614 0.17224066006035416\n",
      "mean_task_P1_select_by_bucket_51_10_100 74.692 79.332 77.604 66.696 11.704\n",
      "mean_task_P2_select_by_bucket_51_10_100 79.736 83.88 80.532 69.488 16.48\n",
      "mean_task_P3_select_by_bucket_51_10_100 84.948 90.744 86.588 74.976 22.6\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002570912353042005 0.019589550108761154 0.05268190666176616 0.07847774068628242 0.03310057211478216\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.002672659175031145 0.020793341555032718 0.05130854615380101 0.08384548324182231 0.04731471615466527\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.003051339175662515 0.020994619200748466 0.052525480174646415 0.08003348488763988 0.05131632215823035\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.3727775035484059 0.38309182198236547 0.39813741147354675 0.42185669543194365 0.4415626702089695\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.37004611111407165 0.3816333216138619 0.4023748604661892 0.4205556228651408 0.43213694537761826\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.3714321510354929 0.38073987147712574 0.4000468958309566 0.4251231519463484 0.42972714077045515\n",
      "mean_data_P1_data_by_bucket_51_10_100 14911.247367530541 14869.891846982786 14864.953032234002 14044.475727994228 3997.792\n",
      "mean_data_P2_data_by_bucket_51_10_100 14986.737573747369 14980.423682344686 14958.665589578286 14672.386206027306 10751.723666666669\n",
      "mean_data_P3_data_by_bucket_51_10_100 14969.241569496755 14936.615818455462 14921.484565739562 14642.6905035495 14669.547787734487\n",
      "all_tran 0.07486211345196166 all_comp 0.3289908974728569\n",
      "all_tran_P1 0.07648165688109684 all_tran_P2 0.07522351556658506 all_tran_P3 0.07334066853617463\n",
      "all_comp_P1 0.34617553102880066 all_comp_P2 0.3300849940076317 all_comp_P3 0.3125114637469038\n",
      "all_data_P1 15013.946509394254 all_data_P2 15007.137655856799 all_data_P3 15007.151597898066\n",
      "epi_comp_energy 0.3726392028596172\n",
      "epi_comp_freq 2015250800.0\n",
      "epi_comp_latency 0.3289908974728569\n",
      "Episode 1250\tAverage Score: 26.2078\tmeantaskP1: 0.1762\tmeantaskP2: 0.1636\tmeantaskP3: 0.2630\tmeanenergyP1:                     0.3896\tmeanenergyP2: 0.4069\tmeanenergyP3: 0.3892 \tmeanlatencyP1: 0.1310 \tmeanlatencyP2: 0.1169 \tmeanlatencyP3:                     0.1027 \tmeandatasize: 14825.4546 \tmeandatasizeP1: 14835.2992 \tmeandatasizeP2: 14933.1534 \tmeandatasizeP3: 14763.5463 \tmean_tran_latencyP1: 0.0258                      \tmean_tran_latencyP2: 0.0323  \tmean_tran_latencyP3: 0.0322  \tmean_comp_latencyP1: 0.1052                      \tmean_comp_latencyP2: 0.0846 \tmean_comp_latencyP3: 0.0705\n",
      "mean_task_till_this_window 0.22926400000000002 T1:: 0.18440164047279106 T2:: 0.2236527493476952 T3:: 0.273842799862965\n",
      "task_select_P1 310.208 task_select_P2 330.308 task_select_P3 359.484\n",
      "total_task_done_P1:: 56.78 total_task_done_P2:: 73.696 total_task_done_P3:: 98.788\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.28452986008107595 0.23547554537307983 0.1569262132102487 0.07115083629174282 0.03209242066245027\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.32017487802188543 0.27638373409008044 0.19398872366635728 0.11508771119820085 0.09331122620752315\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.35406511690749276 0.325505690278252 0.25511050945255886 0.1724947879871301 0.17977610292981613\n",
      "mean_task_P1_select_by_bucket_51_10_100 74.608 79.64 77.636 66.476 11.848\n",
      "mean_task_P2_select_by_bucket_51_10_100 79.008 84.0 81.192 69.468 16.64\n",
      "mean_task_P3_select_by_bucket_51_10_100 85.488 89.568 86.84 74.38 23.208\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0025985137960899208 0.019589840043871737 0.05169106824902996 0.0822029018261739 0.029325863986364525\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.002749195471688442 0.020814397411343916 0.05281803446844496 0.08047083075455162 0.04810087309264086\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.002876319100688203 0.020999806351808245 0.05351114643311615 0.08024425189731012 0.050775139517898596\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.3735551705037606 0.38030246733072454 0.40418007198976136 0.418830615105766 0.4343858544400334\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.37261707728863147 0.3826355929845518 0.4033611955878632 0.4217978544792031 0.44679931986496196\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.3718678839165464 0.38544422815087226 0.40331317631925867 0.42448174028034913 0.42963921793231935\n",
      "mean_data_P1_data_by_bucket_51_10_100 14993.501691002994 14888.25873225997 14780.428216312215 14366.799980352978 4152.154666666666\n",
      "mean_data_P2_data_by_bucket_51_10_100 15050.765766050321 14931.66081988534 14818.061379762754 14552.591054524559 10805.348266666666\n",
      "mean_data_P3_data_by_bucket_51_10_100 15054.55856671225 14996.813136376593 14872.684664661738 14711.288158338384 14474.593661904759\n",
      "all_tran 0.07520363517108684 all_comp 0.3112221503711652\n",
      "all_tran_P1 0.07649260108631407 all_tran_P2 0.07584540365337819 all_tran_P3 0.07373490747728552\n",
      "all_comp_P1 0.33087882360633686 all_comp_P2 0.3139797092226157 all_comp_P3 0.2910473981661202\n",
      "all_data_P1 15008.951293828808 all_data_P2 14990.963957671589 all_data_P3 15005.948788762558\n",
      "epi_comp_energy 0.3740030824621036\n",
      "epi_comp_freq 2016223600.0\n",
      "epi_comp_latency 0.3112221503711652\n",
      "Episode 1500\tAverage Score: 28.0459\tmeantaskP1: 0.1846\tmeantaskP2: 0.1822\tmeantaskP3: 0.2740\tmeanenergyP1:                     0.3911\tmeanenergyP2: 0.4031\tmeanenergyP3: 0.3895 \tmeanlatencyP1: 0.1301 \tmeanlatencyP2: 0.1169 \tmeanlatencyP3:                     0.1022 \tmeandatasize: 14886.3078 \tmeandatasizeP1: 14834.8285 \tmeandatasizeP2: 15043.9487 \tmeandatasizeP3: 14829.1048 \tmean_tran_latencyP1: 0.0248                      \tmean_tran_latencyP2: 0.0318  \tmean_tran_latencyP3: 0.0316  \tmean_comp_latencyP1: 0.1053                      \tmean_comp_latencyP2: 0.0850 \tmean_comp_latencyP3: 0.0706\n",
      "mean_task_till_this_window 0.27048 T1:: 0.22663265102282487 T2:: 0.2657567693883319 T3:: 0.313335874523896\n",
      "task_select_P1 308.824 task_select_P2 329.288 task_select_P3 361.888\n",
      "total_task_done_P1:: 69.956 total_task_done_P2:: 87.288 total_task_done_P3:: 113.236\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.3455533309082513 0.2965955160017121 0.18621159276559127 0.08786096815453967 0.03616376849844342\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.37630304080870053 0.32473831872300485 0.23640681654849527 0.13999722628571049 0.11576219748554874\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.40910046167909647 0.3658697172879121 0.2943706702640392 0.1933477658566624 0.21793260705459955\n",
      "mean_task_P1_select_by_bucket_51_10_100 75.78 78.776 76.744 65.52 12.004\n",
      "mean_task_P2_select_by_bucket_51_10_100 78.392 83.704 81.12 70.012 16.06\n",
      "mean_task_P3_select_by_bucket_51_10_100 85.52 90.572 88.128 74.264 23.404\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0027336355752718856 0.020717520838768815 0.05197931721809203 0.08159662534203736 0.03759275756884754\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0027249992195382162 0.020408009884879445 0.05249098765802116 0.08220182907475995 0.053095044749602395\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0029233491058335147 0.021017776211952402 0.053046089451189875 0.08170971462720175 0.05069146274180402\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.37332999181482174 0.3819127564115647 0.405780918151734 0.4242856401940304 0.4387605276143462\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.37863015709343517 0.3828722144610052 0.40789836725964707 0.4260166587496076 0.42914959889385124\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.38060678346490456 0.38640648559028234 0.40138088524634247 0.425220143901968 0.4484497205480197\n",
      "mean_data_P1_data_by_bucket_51_10_100 15064.717835796948 14964.466336396157 14791.65700020119 14327.451722077922 4797.696\n",
      "mean_data_P2_data_by_bucket_51_10_100 15066.60315626728 14922.754608593319 14793.871193029128 14704.157688838475 12322.673343722943\n",
      "mean_data_P3_data_by_bucket_51_10_100 15045.040468616497 15010.517227737255 14815.142583928464 14703.286463242106 14882.044155988455\n",
      "all_tran 0.07469015201709453 all_comp 0.26404259058819923\n",
      "all_tran_P1 0.07661421593794403 all_tran_P2 0.07523423490566448 all_tran_P3 0.07274481060410747\n",
      "all_comp_P1 0.2820121045125231 all_comp_P2 0.2647432234623269 all_comp_P3 0.24781276671414848\n",
      "all_data_P1 14995.305451354847 all_data_P2 15001.90666305317 all_data_P3 14992.102271567466\n",
      "epi_comp_energy 0.3765407352916152\n",
      "epi_comp_freq 2019204000.0\n",
      "epi_comp_latency 0.26404259058819923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1750\tAverage Score: 28.1366\tmeantaskP1: 0.2004\tmeantaskP2: 0.1850\tmeantaskP3: 0.2893\tmeanenergyP1:                     0.3906\tmeanenergyP2: 0.4033\tmeanenergyP3: 0.3913 \tmeanlatencyP1: 0.1300 \tmeanlatencyP2: 0.1168 \tmeanlatencyP3:                     0.1023 \tmeandatasize: 14847.5840 \tmeandatasizeP1: 14793.2783 \tmeandatasizeP2: 14992.1413 \tmeandatasizeP3: 14800.4566 \tmean_tran_latencyP1: 0.0256                      \tmean_tran_latencyP2: 0.0309  \tmean_tran_latencyP3: 0.0315  \tmean_comp_latencyP1: 0.1044                      \tmean_comp_latencyP2: 0.0859 \tmean_comp_latencyP3: 0.0708\n",
      "mean_task_till_this_window 0.271052 T1:: 0.22598354642311796 T2:: 0.26420037431173976 T3:: 0.317453396101517\n",
      "task_select_P1 304.756 task_select_P2 333.68 task_select_P3 361.564\n",
      "total_task_done_P1:: 68.6 total_task_done_P2:: 88.016 total_task_done_P3:: 114.436\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.3489412783313736 0.2921398118345338 0.1883348621723506 0.08609420981026668 0.04274211196365592\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.3769510940284257 0.32561424508505593 0.2299367807391546 0.1382764066956617 0.11446118592883164\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.40778665768291145 0.37595429945461184 0.2963580264385413 0.20227915868366164 0.21443396576909626\n",
      "mean_task_P1_select_by_bucket_51_10_100 73.812 77.948 76.232 65.248 11.516\n",
      "mean_task_P2_select_by_bucket_51_10_100 80.032 84.392 82.276 70.276 16.704\n",
      "mean_task_P3_select_by_bucket_51_10_100 85.204 90.34 87.472 75.404 23.144\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0024794017769119757 0.02024402605948381 0.051867733905489655 0.08172993220886865 0.042404801449115966\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0027781458588650447 0.020824838253602308 0.05217010763054891 0.08116220804532041 0.0485964946150374\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.002972406439699883 0.021502931654106314 0.05353501993624294 0.08161380182139746 0.05208232068516789\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.3728202161359146 0.3870080231947202 0.40476164432208656 0.42244854065463194 0.43969215006764273\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.37240721549769706 0.38449668636353146 0.40820946132173797 0.4202235456518417 0.44299679942277886\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.37581687831131727 0.3847231938235866 0.4064585728212428 0.4291301813685737 0.432718443396584\n",
      "mean_data_P1_data_by_bucket_51_10_100 14960.561051878827 14927.35010480623 14895.63111327612 14461.759896647796 5260.276666666667\n",
      "mean_data_P2_data_by_bucket_51_10_100 15022.67784847928 15020.002255860496 14803.872737977474 14584.2286360905 11617.103461904762\n",
      "mean_data_P3_data_by_bucket_51_10_100 14993.579687190471 14956.004339366686 14830.937309048528 14866.832777087666 14834.103552380953\n",
      "all_tran 0.07449682355557458 all_comp 0.2639171986049673\n",
      "all_tran_P1 0.0769038885360682 all_tran_P2 0.07464698883468744 all_tran_P3 0.07259333330842391\n",
      "all_comp_P1 0.28194006878841377 all_comp_P2 0.26519170207864057 all_comp_P3 0.24668418356624466\n",
      "all_data_P1 15014.725314523905 all_data_P2 15008.266255072573 all_data_P3 14997.874420825094\n",
      "epi_comp_energy 0.37643218089670366\n",
      "epi_comp_freq 2019158000.0\n",
      "epi_comp_latency 0.2639171986049673\n",
      "Episode 2000\tAverage Score: 28.2819\tmeantaskP1: 0.2054\tmeantaskP2: 0.2042\tmeantaskP3: 0.2934\tmeanenergyP1:                     0.3944\tmeanenergyP2: 0.4029\tmeanenergyP3: 0.3946 \tmeanlatencyP1: 0.1303 \tmeanlatencyP2: 0.1156 \tmeanlatencyP3:                     0.1018 \tmeandatasize: 14852.2685 \tmeandatasizeP1: 14754.1638 \tmeandatasizeP2: 14989.3993 \tmeandatasizeP3: 14836.7679 \tmean_tran_latencyP1: 0.0262                      \tmean_tran_latencyP2: 0.0311  \tmean_tran_latencyP3: 0.0314  \tmean_comp_latencyP1: 0.1041                      \tmean_comp_latencyP2: 0.0845 \tmean_comp_latencyP3: 0.0704\n",
      "mean_task_till_this_window 0.28125200000000006 T1:: 0.23465035302238876 T2:: 0.2770066734820937 T3:: 0.3256496927374563\n",
      "task_select_P1 299.376 task_select_P2 334.56 task_select_P3 366.064\n",
      "total_task_done_P1:: 69.776 total_task_done_P2:: 92.524 total_task_done_P3:: 118.952\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.36970300810175627 0.3008450339964925 0.1961765241733231 0.08858415516756311 0.04051946874934491\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.3874124896877727 0.33717459624251334 0.2483203034753123 0.14857701873342793 0.12702547290998004\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.4194799436356423 0.38131316822335193 0.3095405280372455 0.20630251924003307 0.20962952991680017\n",
      "mean_task_P1_select_by_bucket_51_10_100 71.632 76.448 74.608 64.672 12.016\n",
      "mean_task_P2_select_by_bucket_51_10_100 79.748 84.888 83.32 69.44 17.164\n",
      "mean_task_P3_select_by_bucket_51_10_100 86.492 91.28 89.164 76.02 23.108\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002576860473353192 0.019951173699684424 0.05102341038005881 0.08323303994787323 0.04233663336416223\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0028138640272867927 0.021097668318437776 0.05288099664218407 0.08279398082861399 0.05321586368821681\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0029424898631284766 0.021037527445525086 0.05327424237771925 0.08140049084199406 0.05131227001031109\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.38021692652317157 0.3913436593732646 0.4030267175577397 0.42629417743205317 0.44821283305155496\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.3760166073871073 0.38743813185269155 0.40827642106547435 0.42230644067063317 0.4358122251589626\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.37915027091243164 0.3877220842704478 0.4054920387753398 0.4304032719262189 0.4423608452748772\n",
      "mean_data_P1_data_by_bucket_51_10_100 14981.871687923618 14942.804139626134 14727.274200443268 14467.21537998668 5348.292\n",
      "mean_data_P2_data_by_bucket_51_10_100 15002.501923792644 14936.153794828862 14803.596599864311 14716.35782801117 12560.07429047619\n",
      "mean_data_P3_data_by_bucket_51_10_100 14929.896137041205 14974.765531099707 14903.293428656403 14737.799654333878 15004.830038672439\n",
      "all_tran 0.07512788419887045 all_comp 0.25571305349757284\n",
      "all_tran_P1 0.07847581070672237 all_tran_P2 0.0750709894093838 all_tran_P3 0.07258337212250177\n",
      "all_comp_P1 0.2742736976178249 all_comp_P2 0.2571257785515593 all_comp_P3 0.2382526802442057\n",
      "all_data_P1 14999.724119015935 all_data_P2 14998.84033612521 all_data_P3 15006.455730077092\n",
      "epi_comp_energy 0.3785564001749404\n",
      "epi_comp_freq 2020986400.0\n",
      "epi_comp_latency 0.25571305349757284\n",
      "Episode 2234\tAverage Score: 28.2478\tmeantaskP1: 0.2133\tmeantaskP2: 0.2953\tmeantaskP3: 0.2933\tcomplatencyP1:             0.0996\tcomplatencyP2: 0.0973\tcomplatencyP3: 0.0781\tmeanlatencyP1: 0.0288\tmeanlatencyP2: 0.0278\tmeanlatencyP3:0.0271\tmeanlatreward:0.0140\tmeanengreward:0.2427"
     ]
    }
   ],
   "source": [
    "def egreedy(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-egreedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "    \n",
    "    epi_all_trans_latency=[]\n",
    "    epi_all_trans_latency_P1=[]\n",
    "    epi_all_trans_latency_P2=[]\n",
    "    epi_all_trans_latency_P3=[]\n",
    "    epi_all_comp_latency=[]\n",
    "    epi_all_comp_latency_P1=[]\n",
    "    epi_all_comp_latency_P2=[]\n",
    "    epi_all_comp_latency_P3=[]\n",
    "    \n",
    "    \n",
    "    epi_comp_latency=[]\n",
    "    epi_comp_latency_P1=[]\n",
    "    epi_comp_latency_P2=[]\n",
    "    epi_comp_latency_P3=[]\n",
    "    epi_tran_latency=[]\n",
    "    epi_tran_latency_P1=[]\n",
    "    epi_tran_latency_P2=[]\n",
    "    epi_tran_latency_P3=[]\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "    epi_all_datasize_P1=[]\n",
    "    epi_all_datasize_P2=[]\n",
    "    epi_all_datasize_P3=[]\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "    epi_comp_energy=[]\n",
    "    epi_comp_frequency=[]\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "    mean_tran_latency=[]\n",
    "    mean_comp_latency=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "    mean_tran_latency_P1=[]\n",
    "    mean_tran_latency_P2=[]\n",
    "    mean_tran_latency_P3=[]\n",
    "    mean_comp_latency_P1=[]\n",
    "    mean_comp_latency_P2=[]\n",
    "    mean_comp_latency_P3=[]\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_comp_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_tran_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P3_window=deque(maxlen=window_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    bucket_tasks_mean = {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_task_len= {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_latency_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_energy_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_data_mean= {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    #bucket_energy_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.50*max_dis):{},(0.5*max_dis,0.75*max_dis):{},(0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        comp_latency=[]\n",
    "        comp_latency_P1=[]\n",
    "        comp_latency_P2=[]\n",
    "        comp_latency_P3=[]\n",
    "        tran_latency=[]\n",
    "        tran_latency_P1=[]\n",
    "        tran_latency_P2=[]\n",
    "        tran_latency_P3=[]\n",
    "        compt_energy=[]\n",
    "        compt_freq=[]\n",
    "        all_trans_latency=[]\n",
    "        all_trans_latency_P1=[]\n",
    "        all_trans_latency_P2=[]\n",
    "        all_trans_latency_P3=[]\n",
    "        \n",
    "        all_comp_latency=[]\n",
    "        all_comp_latency_P1=[]\n",
    "        all_comp_latency_P2=[]\n",
    "        all_comp_latency_P3=[]\n",
    "        \n",
    "        all_datasize_P1=[]\n",
    "        all_datasize_P2=[]\n",
    "        all_datasize_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        reward_lat=[]\n",
    "        reward_eng=[]\n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        state = mec_evn.get_state(tasks)\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            max_reward_task,max_reward_server,max_reward_frequency = egreedy_agent.action(tasks,mec_evn)\n",
    "            egreedy_action=[(max_reward_server,max_reward_frequency)]\n",
    "           \n",
    "            rec_mec_idx=max_reward_server\n",
    "            #egreedy_task=mec_evn.priority_queues[max_reward_task].pop(0)\n",
    "\n",
    "#             print(\"action=\",action)\n",
    "            next_state, feedback, done ,action_task,next_task,rec_mec_index = mec_evn.greedy_step(egreedy_action,tasks,max_reward_task)\n",
    "          #  print(rec_mec_idx, rec_mec_index)\n",
    "            score += feedback['reward']\n",
    "            \n",
    "            energy.append(feedback['energy'])\n",
    "            \n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "            #print(user_distance)\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            tran_time=feedback['lat_vec'][0]\n",
    "            comp_time=feedback['lat_vec'][1]+feedback['lat_vec'][2] #comp_time+wait_time\n",
    "            reward_lat.append(feedback['reward_lat'])\n",
    "            reward_eng.append(feedback['reward_eng'])\n",
    "            all_trans_latency.append(tran_time)\n",
    "            all_comp_latency.append(comp_time)\n",
    "            trans_energy=feedback['eng_vector'][0]\n",
    "            comp_energy=feedback['eng_vector'][1]\n",
    "            compt_energy.append(comp_energy)\n",
    "            compt_freq.append(max(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*max_reward_frequency))\n",
    "           # print(egreedy_action, (max(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*max_reward_frequency)), mec_evn.max_freq_server)\n",
    "            \n",
    "           # print(min(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*mec_evn.actions[action][1]))\n",
    "           # print(tran_time,comp_time)\n",
    "            if feedback['task_done']==1:\n",
    "              datasize.append(action_task['data_size'])\n",
    "              latency.append(feedback['latency'])\n",
    "              comp_latency.append(comp_time)\n",
    "              tran_latency.append(tran_time)\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              \n",
    "              if action_task['priority']==1:\n",
    "                  \n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P1.append(tran_time)\n",
    "                  all_comp_latency_P1.append(comp_time)\n",
    "                  all_datasize_P1.append(action_task['data_size'])\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    comp_latency_P1.append(comp_time)\n",
    "                    tran_latency_P1.append(tran_time)\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P1_latency'].append( tran_time)\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  \n",
    "                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P2.append(tran_time)\n",
    "                  all_comp_latency_P2.append(comp_time)\n",
    "                  all_datasize_P2.append(action_task['data_size'])\n",
    "                  \n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    comp_latency_P2.append(comp_time)\n",
    "                    tran_latency_P2.append(tran_time)\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P2_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                 \n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P3.append(tran_time)\n",
    "                  all_comp_latency_P3.append(comp_time)\n",
    "                  all_datasize_P3.append(action_task['data_size'])\n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    comp_latency_P3.append(comp_time)\n",
    "                    tran_latency_P3.append(tran_time)\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P3_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            tasks=next_task\n",
    "            state=next_state\n",
    "            if done:\n",
    "                print(t)\n",
    "                \n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "        \n",
    "        epi_comp_latency.append(np.mean(comp_latency))\n",
    "        epi_comp_latency_P1.append(np.mean(comp_latency_P1))\n",
    "        epi_comp_latency_P2.append(np.mean(comp_latency_P2))\n",
    "        epi_comp_latency_P3.append(np.mean(comp_latency_P3))\n",
    "        \n",
    "        epi_tran_latency.append(np.mean(tran_latency))\n",
    "        epi_tran_latency_P1.append(np.mean(tran_latency_P1))\n",
    "        epi_tran_latency_P2.append(np.mean(tran_latency_P2))\n",
    "        epi_tran_latency_P3.append(np.mean(tran_latency_P3))\n",
    "        \n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "        \n",
    "        epi_all_datasize_P1.append(np.mean(all_datasize_P1))\n",
    "        epi_all_datasize_P2.append(np.mean(all_datasize_P2))\n",
    "        epi_all_datasize_P3.append(np.mean(all_datasize_P3))\n",
    "\n",
    "        \n",
    "        epi_all_trans_latency.append(np.mean(all_trans_latency))\n",
    "        epi_all_trans_latency_P1.append(np.mean(all_trans_latency_P1))\n",
    "        epi_all_trans_latency_P2.append(np.mean(all_trans_latency_P2))\n",
    "        epi_all_trans_latency_P3.append(np.mean(all_trans_latency_P3))\n",
    "        epi_all_comp_latency.append(np.mean(all_comp_latency))\n",
    "        epi_all_comp_latency_P1.append(np.mean(all_comp_latency_P1))\n",
    "        epi_all_comp_latency_P2.append(np.mean(all_comp_latency_P2))\n",
    "        epi_all_comp_latency_P3.append(np.mean(all_comp_latency_P3))\n",
    "       \n",
    "        epi_comp_energy.append(np.mean(compt_energy))\n",
    "        epi_comp_frequency.append(np.mean(compt_freq))\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tcomplatencyP1: \\\n",
    "            {:.4f}\\tcomplatencyP2: {:.4f}\\tcomplatencyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}\\tmeanlatreward:{:.4f}\\tmeanengreward:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(comp_latency_P1), \\\n",
    "            np.mean(comp_latency_P2), np.mean(comp_latency_P3), \\\n",
    "                                    np.mean(tran_latency_P1), np.mean(tran_latency_P2), np.mean(tran_latency_P3),np.mean(reward_lat),np.mean(reward_eng)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "            \n",
    "            mean_comp_latency_P1_window.append(np.mean(comp_latency_P1))\n",
    "            mean_comp_latency_P1.append(np.mean( mean_comp_latency_P1_window))\n",
    "            mean_comp_latency_P2_window.append(np.mean(comp_latency_P2))\n",
    "            mean_comp_latency_P2.append(np.mean( mean_comp_latency_P2_window))\n",
    "            mean_comp_latency_P3_window.append(np.mean(comp_latency_P3))\n",
    "            mean_comp_latency_P3.append(np.mean( mean_comp_latency_P3_window))\n",
    "            \n",
    "            mean_tran_latency_P1_window.append(np.mean(tran_latency_P1))\n",
    "            mean_tran_latency_P1.append(np.mean( mean_tran_latency_P1_window))\n",
    "            mean_tran_latency_P2_window.append(np.mean(tran_latency_P2))\n",
    "            mean_tran_latency_P2.append(np.mean( mean_tran_latency_P2_window))\n",
    "            mean_tran_latency_P3_window.append(np.mean(tran_latency_P3))\n",
    "            mean_tran_latency_P3.append(np.mean( mean_tran_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "                    {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: \\\n",
    "                    {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f} \\tmean_tran_latencyP1: {:.4f}  \\\n",
    "                    \\tmean_tran_latencyP2: {:.4f}  \\tmean_tran_latencyP3: {:.4f}  \\tmean_comp_latencyP1: {:.4f}  \\\n",
    "                    \\tmean_comp_latencyP2: {:.4f} \\tmean_comp_latencyP3: {:.4f}'.format(i_episode, mean_score,mean_tasks_P1[-1],mean_tasks_P2[-1],\\\n",
    "                    mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1] ,mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],\\\n",
    "                    mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], mean_datasize_P2[-1],mean_datasize_P3[-1],\\\n",
    "                        mean_tran_latency_P1[-1], mean_tran_latency_P2[-1],mean_tran_latency_P3[-1],mean_comp_latency_P1[-1],\\\n",
    "                            mean_comp_latency_P2[-1],mean_comp_latency_P3[-1]                                                                                                                                                                                                                   ))\n",
    "\n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P3_latency_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "\n",
    "            print('all_tran',np.mean(epi_all_trans_latency[-window_size:]), 'all_comp',np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            print('all_tran_P1',np.mean(epi_all_trans_latency_P1[-window_size:]),\\\n",
    "                  'all_tran_P2',np.mean(epi_all_trans_latency_P2[-window_size:]),\\\n",
    "                      'all_tran_P3',np.mean(epi_all_trans_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_comp_P1',np.mean(epi_all_comp_latency_P1[-window_size:]),\\\n",
    "                  'all_comp_P2',np.mean(epi_all_comp_latency_P2[-window_size:]),\\\n",
    "                 'all_comp_P3',np.mean(epi_all_comp_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_data_P1',np.mean(epi_all_datasize_P1[-window_size:]),\\\n",
    "                  'all_data_P2',np.mean(epi_all_datasize_P2[-window_size:]),\\\n",
    "                 'all_data_P3',np.mean(epi_all_datasize_P3[-window_size:]))\n",
    "            \n",
    "            \n",
    "            print('epi_comp_energy', np.mean(epi_comp_energy[-window_size:]))\n",
    "            print('epi_comp_freq', np.mean(epi_comp_frequency[-window_size:]))\n",
    "            print('epi_comp_latency', np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), model_path)\n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3,epi_tran_latency_P1,epi_tran_latency_P2,\\\n",
    "                 epi_tran_latency_P3,epi_comp_latency_P1,epi_comp_latency_P2,epi_comp_latency_P3\n",
    "\n",
    "egreedy_epi_scores,egreedy_epi_task,egreedy_epi_energy,egreedy_epi_latency,egreedy_epi_num_task,egreedy_epi_task_P1,egreedy_epi_task_P2,egreedy_epi_task_P3,egreedy_epi_latency_P1,egreedy_epi_latency_P2,egreedy_epi_latency_P3,\\\n",
    "egreedy_epi_energy_P1,egreedy_epi_energy_P2,egreedy_epi_energy_P3,egreedy_epi_num_task_P1,egreedy_epi_num_task_P2,egreedy_epi_num_task_P3,egreedy_epi_task_select_P1,egreedy_epi_task_select_P2,egreedy_epi_task_select_P3,\\\n",
    "egreedy_mean_scores,egreedy_mean_task,egreedy_mean_energy,egreedy_mean_latency,egreedy_win_num_task, egreedy_mean_tasks_P1,egreedy_mean_tasks_P2,egreedy_mean_tasks_P3,\\\n",
    "egreedy_mean_energy_P1,egreedy_mean_energy_P2,egreedy_mean_energy_P3,egreedy_mean_latency_P1,egreedy_mean_latency_P2,egreedy_mean_latency_P3 ,egreedy_win_num_task_P1, egreedy_win_num_task_P2,egreedy_win_num_task_P3,\\\n",
    "egreedy_epi_datasize,egreedy_epi_datasize_P1,egreedy_epi_datasize_P2,egreedy_epi_datasize_P3,egreedy_mean_datasize,egreedy_mean_datasize_P1,egreedy_mean_datasize_P2,egreedy_mean_datasize_P3,\\\n",
    "egreedy_epi_tran_latency_P1,egreedy_epi_tran_latency_P2,egreedy_epi_tran_latency_P3,egreedy_epi_comp_latency_P1,egreedy_epi_comp_latency_P2,\\\n",
    "egreedy_epi_comp_latency_P3= egreedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNcbaKBSXB1O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv4vHu2WdTeh"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(egreedy_epi_scores) + 1), egreedy_epi_scores,egreedy_epi_task,egreedy_epi_energy,egreedy_epi_latency,egreedy_epi_num_task,egreedy_epi_task_P1,egreedy_epi_task_P2,\n",
    "           egreedy_epi_task_P3,egreedy_epi_latency_P1,egreedy_epi_latency_P2,egreedy_epi_latency_P3,\n",
    "           egreedy_epi_energy_P1,egreedy_epi_energy_P2,egreedy_epi_energy_P3,egreedy_epi_num_task_P1,egreedy_epi_num_task_P2,egreedy_epi_num_task_P3,\n",
    "           egreedy_epi_datasize,egreedy_epi_datasize_P1,egreedy_epi_datasize_P2,egreedy_epi_datasize_P3,egreedy_epi_task_select_P1,egreedy_epi_task_select_P2,\\\n",
    "           egreedy_epi_task_select_P3,egreedy_epi_tran_latency_P1,egreedy_epi_tran_latency_P2,egreedy_epi_tran_latency_P3,\\\n",
    "                    egreedy_epi_comp_latency_P1,egreedy_epi_comp_latency_P2,egreedy_epi_comp_latency_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_egreedy.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"egreedy_epi_scores\",\"egreedy_epi_task\",\"egreedy_epi_energy\",\"egreedy_epi_latency\",\"egreedy_epi_num_task\",\"egreedy_epi_task_P1\",\"egreedy_epi_task_P2\",\"egreedy_epi_task_P3\",\n",
    "                     \"egreedy_epi_latency_P1\",\"egreedy_epi_latency_P2\",\"egreedy_epi_latency_P3\",\"egreedy_epi_energy_P1\",\"egreedy_epi_energy_P2\",\"egreedy_epi_energy_P3\",\"egreedy_epi_num_task_P1\",\n",
    "                     \"egreedy_epi_num_task_P2\",\"egreedy_epi_num_task_P3\",\"egreedy_epi_datasize\",\"egreedy_epi_datasize_P1\",\"egreedy_epi_datasize_P2\"\n",
    "                     \"egreedy_epi_datasize_P3\",\"egreedy_epi_task_select_P1\",\"egreedy_epi_task_select_P2\",\"egreedy_epi_task_select_P3\",\\\n",
    "                    \"egreedy_epi_tran_latency_P1\",\"egreedy_epi_tran_latency_P2\",\"egreedy_epi_tran_latency_P3\",\\\n",
    "                    \"egreedy_epi_comp_latency_P1\",\"egreedy_epi_comp_latency_P2\",\"egreedy_epi_comp_latency_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPOR-vhHGnKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0IPp62mG4OL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBbu3Rgm1yrC"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
