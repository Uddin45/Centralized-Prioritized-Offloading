{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_2c3s5mPjSr"
   },
   "source": [
    "+++++[link text](https:// [link text](https://))### 1. Read environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32923,
     "status": "ok",
     "timestamp": 1705362321730,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "jc1n8GcSNWxH",
    "outputId": "abef88a4-81ad-407a-e969-720aa69ed4ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1705362321766,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "4v2mf8TUrIW6",
    "outputId": "edd8159b-c99d-48b5-bcfc-37a584fe662b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\uddin81\\Documents\\Customize_RL_MEC Env\\Test for Journal\\Final Result\\backup\\10k20k_8e9_300m__50_3_170_200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pw1W2pj5R-9H"
   },
   "outputs": [],
   "source": [
    "# ! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1705362324095,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "yDgZsDSYPjSu",
    "outputId": "33fb275d-ff33-4095-d717-846af1fc4bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "{}\n",
      "98\n",
      "70\n",
      "26\n",
      "{'data_size': 18171, 'circle': 8384407, 'user_index': 48, 'priority': 1, 'user_distance': [95.27442286803297, 205.49528914373454, 505.35078120815973], 'delta_max': 0.192}\n",
      "{'data_size': 12371, 'circle': 9482442, 'user_index': 49, 'priority': 2, 'user_distance': [276.4697081413863, 25.733657589615518, 323.86562452056535], 'delta_max': 0.186}\n",
      "{'data_size': 12915, 'circle': 9242029, 'user_index': 29, 'priority': 3, 'user_distance': [528.6595715645917, 228.78363586343124, 72.1315566927862], 'delta_max': 0.179}\n",
      "[<mec_server.MECServer object at 0x00000208D1A24190>, <mec_server.MECServer object at 0x00000208D1E4E290>, <mec_server.MECServer object at 0x00000208D1E4E790>]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=1)\n",
    "print(mec_evn.mec_servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALZLc1DEPjSw"
   },
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1705362324096,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "tLC_64NIPjSx",
    "outputId": "449b79d3-3ec3-41eb-e40f-0841df76c732",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{48: {'speed': array([526451.79595463,   8230.95217677,   1303.74710805])}, 49: {'speed': array([   8503.4226393 , 3558903.9784338 ,    5513.09329017])}, 29: {'speed': array([2.02426928e+02, 5.33731169e+03, 5.81458252e+05])}}\n",
      "Action size: 45\n",
      "Action space: [(0, 0.1, 0), (0, 0.1, 1), (0, 0.1, 2), (0, 0.325, 0), (0, 0.325, 1), (0, 0.325, 2), (0, 0.55, 0), (0, 0.55, 1), (0, 0.55, 2), (0, 0.775, 0), (0, 0.775, 1), (0, 0.775, 2), (0, 1.0, 0), (0, 1.0, 1), (0, 1.0, 2), (1, 0.1, 0), (1, 0.1, 1), (1, 0.1, 2), (1, 0.325, 0), (1, 0.325, 1), (1, 0.325, 2), (1, 0.55, 0), (1, 0.55, 1), (1, 0.55, 2), (1, 0.775, 0), (1, 0.775, 1), (1, 0.775, 2), (1, 1.0, 0), (1, 1.0, 1), (1, 1.0, 2), (2, 0.1, 0), (2, 0.1, 1), (2, 0.1, 2), (2, 0.325, 0), (2, 0.325, 1), (2, 0.325, 2), (2, 0.55, 0), (2, 0.55, 1), (2, 0.55, 2), (2, 0.775, 0), (2, 0.775, 1), (2, 0.775, 2), (2, 1.0, 0), (2, 1.0, 1), (2, 1.0, 2)]\n",
      "Observes a state with length: 27\n",
      "state size: 27\n",
      "The state for the first agent looks like: [1.44457217e-01 2.33332050e-03 5.55455045e-05 2.25855521e-03\n",
      " 9.76555438e-01 1.46454661e-03 3.57745344e-04 1.51278069e-03\n",
      " 1.59550868e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 6.25000000e-02 2.50000000e-01 1.25000000e-01 9.08550000e-01\n",
      " 8.38440700e-01 9.60000000e-01 3.33333333e-01 6.18550000e-01\n",
      " 9.48244200e-01 9.30000000e-01 6.66666667e-01 6.45750000e-01\n",
      " 9.24202900e-01 8.95000000e-01 1.00000000e+00]\n",
      "max_freq [1000000000.0, 4000000000.0, 2000000000.0]\n"
     ]
    }
   ],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "\n",
    "task=mec_evn.get_task()\n",
    "\n",
    "states = mec_evn.get_state(task)\n",
    "print(mec_evn.trans_speed_matrix)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)\n",
    "print('max_freq',mec_evn.max_freq_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vapCU_9PjSy"
   },
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF7ASsRcPjSz"
   },
   "source": [
    "### 6. Take Actions with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dq2lQI0LPjSz"
   },
   "outputs": [],
   "source": [
    "epoch_no =3000\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OmtnPud5PjS0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PSLBUj5oPjS1"
   },
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n",
    "model_path = os.path.join(current_directory, 'model_dqnp_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 45.08324094593227), (45.08324094593227, 80.16648189186454), (80.16648189186454, 115.24972283779681), (115.24972283779681, 150.33296378372907), (150.33296378372907, inf)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "Mec_2_Mec=300\n",
    "Range=(Mec_2_Mec/2)\n",
    "\n",
    "max_dis=math.sqrt(10*10+Range*Range)\n",
    "R_1=(max_dis-10)/4\n",
    "\n",
    "\n",
    "bucket_ranges = [(10, 10+R_1) ,(10+R_1,10+2*R_1),(10+2*R_1,10+3*R_1),(10+3*R_1,10+4*R_1),(10+4*R_1,float('inf'))]\n",
    "\n",
    "print(bucket_ranges)\n",
    "# Function to determine the bucket for a given value\n",
    "def find_bucket(value, ranges):\n",
    "    for start, end in ranges:\n",
    "        if start <= value <= end:\n",
    "            return (start, end)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250\tAverage Score: -582.9342\tmeantaskP1: 0.5148\tmeantaskP2: 0.5114\tmeantaskP3: 0.4548\tmeanenergyP1:     8.1726\tmeanenergyP2: 16.9082\tmeanenergyP3: 12.6859 \tmeanlatencyP1: 0.0550 \tmeanlatencyP2: 0.0581 \tmeanlatencyP3:     0.0493 \tmeandatasize: 14914.9798 \tmeandatasizeP1: 14694.4080 \tmeandatasizeP2: 15054.6611 \tmeandatasizeP3: 15008.8582 \tmean_tran_latencyP1: 0.0309      \tmean_tran_latencyP2: 0.0359  \tmean_tran_latencyP3: 0.0280  \tmean_comp_latencyP1: 0.0241      \tmean_comp_latencyP2: 0.0222 \tmean_comp_latencyP3: 0.0213\n",
      "mean_task_till_this_window 0.386308 T1:: 0.3892731237025264 T2:: 0.38535584599756145 T3:: 0.3835444277713923\n",
      "task_select_P1 330.164 task_select_P2 333.16 task_select_P3 336.676\n",
      "total_task_done_P1:: 128.38 total_task_done_P2:: 128.468 total_task_done_P3:: 129.46\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9946535099579928 0.931198740053743 0.6877779286965044 0.3304658056876857 0.009376432521284638\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9894101505747753 0.9172727289087658 0.663640248392508 0.3126365168980916 0.01590956270447261\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9804247138346237 0.90132885536129 0.64885323308486 0.2886601322889599 0.025769588779530443\n",
      "mean_task_P1_select_by_bucket_51_10_100 56.068 39.48 34.816 30.636 169.164\n",
      "mean_task_P2_select_by_bucket_51_10_100 56.024 39.944 35.732 30.928 170.532\n",
      "mean_task_P3_select_by_bucket_51_10_100 56.768 40.776 35.604 31.76 171.768\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.004039030635732121 0.03104736808533506 0.07052823260871213 0.10698129340179413 0.10304512575835238\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.00432807536461932 0.02997721091133695 0.06795394361496178 0.10013345702236656 0.08040433409997431\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0042605067214092586 0.029902870613173087 0.06499623595713197 0.09564584371742706 0.05450850911737645\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.4363209639048951 0.5505779997386933 0.7899629307850864 4.159618996726098 46.96485756432259\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.5132533403652747 0.946264459190904 1.0150692356914606 2.34271008134537 140.02229943030443\n",
      "mean_task_P3_energy_by_bucket_51_10_100 1.2984993227656523 4.4747949276007395 1.1485987430356404 2.6969729901199946 60.32119854070018\n",
      "mean_data_P1_data_by_bucket_51_10_100 14957.554258418631 14951.573124264352 14721.916857374772 14224.041664892624 10621.115276190476\n",
      "mean_data_P2_data_by_bucket_51_10_100 14998.45221657069 14910.242647289488 14743.545763415255 14393.886855471705 13342.403615873016\n",
      "mean_data_P3_data_by_bucket_51_10_100 14991.970443293456 14958.726402422568 14751.737071165031 14377.3430320447 14002.027840404042\n",
      "all_tran 147.8136030847922 all_comp 0.019916070131021143\n",
      "all_tran_P1 80.79044006407173 all_tran_P2 262.7056683285163 all_tran_P3 104.07840587033044\n",
      "all_comp_P1 0.019859494130606864 all_comp_P2 0.019932584266817325 all_comp_P3 0.019954936564220992\n",
      "all_data_P1 14995.361009806078 all_data_P2 15000.7075737382 all_data_P3 14996.300214161382\n",
      "epi_comp_energy 0.6742961363836503\n",
      "epi_comp_freq 2679636400.0\n",
      "epi_comp_latency 0.019916070131021143\n",
      "Episode 500\tAverage Score: -201.2267\tmeantaskP1: 0.5519\tmeantaskP2: 0.5368\tmeantaskP3: 0.5087\tmeanenergyP1:     7.1332\tmeanenergyP2: 13.6410\tmeanenergyP3: 13.3796 \tmeanlatencyP1: 0.0553 \tmeanlatencyP2: 0.0581 \tmeanlatencyP3:     0.0505 \tmeandatasize: 14898.4995 \tmeandatasizeP1: 14639.8036 \tmeandatasizeP2: 14989.4266 \tmeandatasizeP3: 15054.7448 \tmean_tran_latencyP1: 0.0312      \tmean_tran_latencyP2: 0.0354  \tmean_tran_latencyP3: 0.0283  \tmean_comp_latencyP1: 0.0241      \tmean_comp_latencyP2: 0.0227 \tmean_comp_latencyP3: 0.0222\n",
      "mean_task_till_this_window 0.5703959999999999 T1:: 0.5657843051614594 T2:: 0.5699755793943627 T3:: 0.5733609020841698\n",
      "task_select_P1 320.772 task_select_P2 332.036 task_select_P3 347.192\n",
      "total_task_done_P1:: 181.576 total_task_done_P2:: 189.372 total_task_done_P3:: 199.448\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9971866333776848 0.9450917935183493 0.7447581847155192 0.4001649781727009 0.02039978635425302\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9933071758712794 0.9394894740238904 0.7383927659745798 0.38187072175689557 0.03606040528501158\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9914538361690943 0.9316392058146916 0.7205584462742145 0.3542633005444831 0.061999221496377856\n",
      "mean_task_P1_select_by_bucket_51_10_100 74.76 55.124 49.028 40.852 101.008\n",
      "mean_task_P2_select_by_bucket_51_10_100 77.628 58.16 51.372 41.804 103.072\n",
      "mean_task_P3_select_by_bucket_51_10_100 82.052 61.232 53.952 43.94 106.016\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.004082250673631777 0.02990322958625029 0.0678633240221513 0.10294442902964991 0.11007986657645098\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.004250487720597108 0.029831477916076956 0.06572079852755869 0.09975197272858376 0.07846931535055823\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.004270161197447744 0.028508814469213484 0.06270241405312825 0.0917009989804483 0.057270805444055724\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.20139235482907214 0.25277099782001744 0.3923004596601297 0.5999790568353408 48.355363531443096\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.27646873149649887 0.3317587121523002 0.7032382294122345 0.7017758025971387 47.965254221584175\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.21500466077272853 0.6644274305831179 0.6352441606802196 0.9846318624380865 59.0921397318787\n",
      "mean_data_P1_data_by_bucket_51_10_100 14995.167862915101 14971.410674260855 14783.499707987081 14392.705432711997 11680.4379\n",
      "mean_data_P2_data_by_bucket_51_10_100 14969.077718171053 14913.616027902817 14774.120368019763 14378.869657403202 14197.56822092352\n",
      "mean_data_P3_data_by_bucket_51_10_100 15009.93129551479 14955.171581955055 14744.440824217247 14300.74588352885 14622.472404184702\n",
      "all_tran 53.74203448338199 all_comp 0.022883764832421563\n",
      "all_tran_P1 50.816369080939765 all_tran_P2 50.23712309518215 all_tran_P3 58.63820719452502\n",
      "all_comp_P1 0.022908785191931336 all_comp_P2 0.02286121052449252 all_comp_P3 0.02286626196525661\n",
      "all_data_P1 15014.496138218346 all_data_P2 15000.654356573765 all_data_P3 15023.601576637391\n",
      "epi_comp_energy 0.36614563811737477\n",
      "epi_comp_freq 2312116400.0\n",
      "epi_comp_latency 0.022883764832421563\n",
      "Episode 750\tAverage Score: -0.2644\tmeantaskP1: 0.5801\tmeantaskP2: 0.5683\tmeantaskP3: 0.5436\tmeanenergyP1:     6.4809\tmeanenergyP2: 11.7598\tmeanenergyP3: 12.5351 \tmeanlatencyP1: 0.0564 \tmeanlatencyP2: 0.0587 \tmeanlatencyP3:     0.0521 \tmeandatasize: 14880.0390 \tmeandatasizeP1: 14632.2466 \tmeandatasizeP2: 14963.3762 \tmeandatasizeP3: 15028.9808 \tmean_tran_latencyP1: 0.0322      \tmean_tran_latencyP2: 0.0358  \tmean_tran_latencyP3: 0.0295  \tmean_comp_latencyP1: 0.0241      \tmean_comp_latencyP2: 0.0229 \tmean_comp_latencyP3: 0.0226\n",
      "mean_task_till_this_window 0.6759639999999999 T1:: 0.6774142268455298 T2:: 0.674830985480185 T3:: 0.6746386747230428\n",
      "task_select_P1 311.176 task_select_P2 328.792 task_select_P3 360.032\n",
      "total_task_done_P1:: 210.868 total_task_done_P2:: 222.008 total_task_done_P3:: 243.088\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9973405678687957 0.9578373364612734 0.7876852315629681 0.45072959597172174 0.043965677433518244\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9948848017962372 0.949922097329715 0.7738768214158672 0.426950757912556 0.07349533749723673\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9924686200525102 0.9445585638919721 0.7527591257808786 0.40373730054580864 0.1086621384593021\n",
      "mean_task_P1_select_by_bucket_51_10_100 81.92 63.476 57.564 45.136 63.08\n",
      "mean_task_P2_select_by_bucket_51_10_100 86.34 66.288 60.988 49.472 65.704\n",
      "mean_task_P3_select_by_bucket_51_10_100 94.296 73.892 66.8 53.888 71.156\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.004353749339649912 0.03008409007380748 0.06723347907141908 0.10144324613989274 0.12333994260659852\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.004422781389521111 0.029351165699519285 0.06565170063426706 0.09670175668097185 0.07886287618674462\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.004544820010375668 0.028433477698595496 0.061878612252396596 0.0898507013019639 0.061391563702578804\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.14771350830375035 0.17371565095697575 0.26326123428294407 0.43879480558184203 38.53093705501468\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.18012977167750807 0.22019789029454467 0.2621666610855029 6.6997752923358 38.38462742051917\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.16313122339380215 0.18117028809170532 0.34273935815941886 0.5693305062837701 68.46648684666175\n",
      "mean_data_P1_data_by_bucket_51_10_100 15000.308259562335 14913.074504584534 14830.206944600952 14402.57313118856 13403.572095238093\n",
      "mean_data_P2_data_by_bucket_51_10_100 15001.552675402865 14932.597046641466 14840.034040405451 14426.498840839064 13749.924378643578\n",
      "mean_data_P3_data_by_bucket_51_10_100 15014.168263690657 14922.893367097933 14813.533666302585 14420.112273873807 14508.24028038628\n",
      "all_tran 32.53441167606251 all_comp 0.024312674750853885\n",
      "all_tran_P1 25.624088878089665 all_tran_P2 27.241959610062768 all_tran_P3 46.93868453280528\n",
      "all_comp_P1 0.024249662171770568 all_comp_P2 0.024303252191910915 all_comp_P3 0.024359858578606456\n",
      "all_data_P1 15007.410673333605 all_data_P2 15004.74090619315 all_data_P3 15001.737481975495\n",
      "epi_comp_energy 0.24475879964162853\n",
      "epi_comp_freq 2168158400.0\n",
      "epi_comp_latency 0.024312674750853885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tAverage Score: 108.3071\tmeantaskP1: 0.6007\tmeantaskP2: 0.5921\tmeantaskP3: 0.5703\tmeanenergyP1:     5.8928\tmeanenergyP2: 10.6047\tmeanenergyP3: 11.5106 \tmeanlatencyP1: 0.0573 \tmeanlatencyP2: 0.0592 \tmeanlatencyP3:     0.0533 \tmeandatasize: 14862.4450 \tmeandatasizeP1: 14631.2948 \tmeandatasizeP2: 14940.2189 \tmeandatasizeP3: 14999.7102 \tmean_tran_latencyP1: 0.0331      \tmean_tran_latencyP2: 0.0361  \tmean_tran_latencyP3: 0.0304  \tmean_comp_latencyP1: 0.0242      \tmean_comp_latencyP2: 0.0232 \tmean_comp_latencyP3: 0.0229\n",
      "mean_task_till_this_window 0.734756 T1:: 0.7398112396131076 T2:: 0.7375846417640921 T3:: 0.7271145098271233\n",
      "task_select_P1 308.292 task_select_P2 324.696 task_select_P3 367.012\n",
      "total_task_done_P1:: 228.072 total_task_done_P2:: 239.596 total_task_done_P3:: 267.088\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9972023025453985 0.9598698798572045 0.8055779657371279 0.48436544468212933 0.06835336432695802\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9957638003134164 0.9566541194919435 0.7944150956869596 0.4672048034125691 0.11474112228470232\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9923274965040384 0.9514175605545595 0.7734292331216207 0.4330403366830709 0.1594503331312478\n",
      "mean_task_P1_select_by_bucket_51_10_100 86.012 67.956 61.72 50.856 41.748\n",
      "mean_task_P2_select_by_bucket_51_10_100 90.148 71.04 65.788 52.636 45.084\n",
      "mean_task_P3_select_by_bucket_51_10_100 100.22 80.36 73.7 59.52 53.212\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.004294106114108317 0.029431845543058312 0.06632305531720979 0.10158843820667918 0.12006705578405802\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0044144057976181995 0.028569821297200874 0.06381810060417846 0.09621937129746155 0.08380251512044401\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.004546299530509989 0.028286175802857874 0.06241706643111621 0.09021224637477232 0.06231466356279567\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.12188657101821337 0.16688249776135775 0.21346780719209357 0.37767636573129865 71.86403177639636\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.14082027460449517 0.18214884455791497 0.32929208100939883 0.31280201623957743 30.497313771748157\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.12328646969592766 0.15906012675232717 0.22242857716649703 0.3315070951489619 59.86700012383479\n",
      "mean_data_P1_data_by_bucket_51_10_100 14985.56329285653 15001.813189826273 14851.304082039438 14510.51583289364 13083.317295238096\n",
      "mean_data_P2_data_by_bucket_51_10_100 14991.670014715333 14973.939781772697 14835.837539438937 14508.506107751626 14143.931078066378\n",
      "mean_data_P3_data_by_bucket_51_10_100 15007.040312682439 14952.156899109403 14810.29018957657 14422.382548304346 14548.927126398336\n",
      "all_tran 25.567961812610555 all_comp 0.02537719097944007\n",
      "all_tran_P1 33.47026963648475 all_tran_P2 13.764862049093304 all_tran_P3 29.611311411086508\n",
      "all_comp_P1 0.025371241253939216 all_comp_P2 0.02536861591913261 all_comp_P3 0.02537879275407738\n",
      "all_data_P1 15020.239618957889 all_data_P2 15002.228938249913 all_data_P3 15003.295237306233\n",
      "epi_comp_energy 0.17996311567433051\n",
      "epi_comp_freq 2094604800.0\n",
      "epi_comp_latency 0.02537719097944007\n",
      "Episode 1250\tAverage Score: 169.5968\tmeantaskP1: 0.6188\tmeantaskP2: 0.6121\tmeantaskP3: 0.5917\tmeanenergyP1:     5.4534\tmeanenergyP2: 9.6522\tmeanenergyP3: 10.7260 \tmeanlatencyP1: 0.0580 \tmeanlatencyP2: 0.0595 \tmeanlatencyP3:     0.0541 \tmeandatasize: 14850.6726 \tmeandatasizeP1: 14647.0314 \tmeandatasizeP2: 14916.6362 \tmeandatasizeP3: 14973.3060 \tmean_tran_latencyP1: 0.0336      \tmean_tran_latencyP2: 0.0362  \tmean_tran_latencyP3: 0.0309  \tmean_comp_latencyP1: 0.0244      \tmean_comp_latencyP2: 0.0234 \tmean_comp_latencyP3: 0.0232\n",
      "mean_task_till_this_window 0.7735920000000001 T1:: 0.7778317301867592 T2:: 0.7799588532566055 T3:: 0.7640680515421604\n",
      "task_select_P1 305.8 task_select_P2 319.688 task_select_P3 374.512\n",
      "total_task_done_P1:: 237.972 total_task_done_P2:: 249.46 total_task_done_P3:: 286.16\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9983023265915829 0.966617141222404 0.8243962039847313 0.5087812614598985 0.10074855853002739\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9969884843545994 0.9619571974288721 0.8181912830047294 0.5033460665787423 0.1670092900760286\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9934005726231672 0.9527976326744453 0.7927738083484659 0.4616509911636697 0.21873263047629557\n",
      "mean_task_P1_select_by_bucket_51_10_100 87.576 69.612 65.212 51.94 31.46\n",
      "mean_task_P2_select_by_bucket_51_10_100 90.82 73.256 67.484 55.156 32.972\n",
      "mean_task_P3_select_by_bucket_51_10_100 105.504 83.952 79.432 63.56 42.064\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0042838099672174185 0.029138478054736024 0.0660035759146808 0.09992243280940664 0.11994405157522908\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.004433049225967328 0.02858954537651588 0.06370683792887909 0.09505897168814183 0.08367816264696037\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0045184323575650194 0.028115545078496094 0.06162002601128963 0.09006555268411054 0.06395882702323986\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.11195265109163413 0.12669331975220338 0.15885121967825813 0.24320082954655875 28.389518600690668\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.11330285145146542 0.12986218525920656 0.16118184511935477 0.25980462076387645 85.76311884551694\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.11141552312491004 0.13879811223228428 0.16932581601628927 0.27558643798641264 20.004772771785124\n",
      "mean_data_P1_data_by_bucket_51_10_100 14998.844763847046 14959.950888270349 14853.210145475447 14566.790103266389 13420.510766666666\n",
      "mean_data_P2_data_by_bucket_51_10_100 15006.285331499956 14956.523037841753 14864.131053941886 14486.791466654748 14225.258713708514\n",
      "mean_data_P3_data_by_bucket_51_10_100 15008.254164616887 14996.828580940968 14849.504841904863 14468.598615598918 14554.756913132946\n",
      "all_tran 16.8005389687394 all_comp 0.025783004122890477\n",
      "all_tran_P1 10.548835045139317 all_tran_P2 33.437527428414704 all_tran_P3 7.581537645375782\n",
      "all_comp_P1 0.025766059569693564 all_comp_P2 0.02578772438860955 all_comp_P3 0.025776479441742047\n",
      "all_data_P1 15004.08511060956 all_data_P2 15003.753684255735 all_data_P3 15016.344630957947\n",
      "epi_comp_energy 0.14488676431435488\n",
      "epi_comp_freq 2054516400.0\n",
      "epi_comp_latency 0.025783004122890477\n",
      "Episode 1500\tAverage Score: 203.0882\tmeantaskP1: 0.6349\tmeantaskP2: 0.6288\tmeantaskP3: 0.6094\tmeanenergyP1:     5.0618\tmeanenergyP2: 8.8757\tmeanenergyP3: 10.0032 \tmeanlatencyP1: 0.0585 \tmeanlatencyP2: 0.0597 \tmeanlatencyP3:     0.0548 \tmeandatasize: 14842.9451 \tmeandatasizeP1: 14662.0494 \tmeandatasizeP2: 14895.0837 \tmeandatasizeP3: 14956.7649 \tmean_tran_latencyP1: 0.0341      \tmean_tran_latencyP2: 0.0362  \tmean_tran_latencyP3: 0.0314  \tmean_comp_latencyP1: 0.0244      \tmean_comp_latencyP2: 0.0236 \tmean_comp_latencyP3: 0.0234\n",
      "mean_task_till_this_window 0.796852 T1:: 0.8050979122492606 T2:: 0.802865339811812 T3:: 0.784586146688311\n",
      "task_select_P1 299.12 task_select_P2 325.068 task_select_P3 375.812\n",
      "total_task_done_P1:: 240.928 total_task_done_P2:: 261.04 total_task_done_P3:: 294.884\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.9980923327904532 0.9702205819870345 0.8455424036378993 0.5423781562228491 0.13837677847937932\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.9960178213957486 0.9623418785527501 0.8248772020769788 0.5299465839607459 0.21269238611720534\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.9938814033472829 0.9561645840331894 0.8045393537960787 0.48565664586470825 0.2595911090962023\n",
      "mean_task_P1_select_by_bucket_51_10_100 85.788 69.764 65.084 54.144 24.34\n",
      "mean_task_P2_select_by_bucket_51_10_100 94.66 75.612 70.3 57.144 27.352\n",
      "mean_task_P3_select_by_bucket_51_10_100 106.884 86.716 80.332 65.568 36.312\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.004450260149903062 0.028872872957124592 0.06462202334957365 0.09825589204796747 0.11936795155171329\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.004312849555223503 0.028825719718639613 0.0634994999185298 0.09396635412959373 0.08617164800068934\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.004633358328552901 0.028301637223687007 0.06138108521215442 0.08907958412237046 0.06579927592912486\n",
      "mean_task_P1_energy_by_bucket_51_10_100 0.10595061794594138 0.11693570553176875 0.14608956711290824 0.2408335333872385 14.17674752009258\n",
      "mean_task_P2_energy_by_bucket_51_10_100 0.10463322144305995 0.12032444990709851 0.1670501870753756 0.21131555518289777 841.1710533199614\n",
      "mean_task_P3_energy_by_bucket_51_10_100 0.11994753406801603 0.12353295181163078 0.1597762203350113 0.26836886058972165 8.353034157736435\n",
      "mean_data_P1_data_by_bucket_51_10_100 14982.084539110816 14961.531767281036 14821.820137569843 14476.96912292366 13513.666688888889\n",
      "mean_data_P2_data_by_bucket_51_10_100 15022.169293954044 15019.497288070395 14866.151249779285 14518.721862763883 14240.498577200577\n",
      "mean_data_P3_data_by_bucket_51_10_100 14992.419526460912 14984.177075625046 14819.580620567835 14496.16996872944 14493.852026751098\n",
      "all_tran 58.520690783875004 all_comp 0.026123874143733117\n",
      "all_tran_P1 3.8787830878718115 all_tran_P2 204.2202799361077 all_tran_P3 2.82063581537746\n",
      "all_comp_P1 0.026120220298660592 all_comp_P2 0.02615423834000902 all_comp_P3 0.02609583165260644\n",
      "all_data_P1 14970.605345951006 all_data_P2 15022.030915556692 all_data_P3 14996.611137688655\n",
      "epi_comp_energy 0.12122975303541321\n",
      "epi_comp_freq 2027295200.0\n",
      "epi_comp_latency 0.026123874143733117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1744\tAverage Score: 221.4667\tmeantaskP1: 0.8556\tmeantaskP2: 0.8118\tmeantaskP3: 0.7986\tcomplatencyP1:             0.0255\tcomplatencyP2: 0.0255\tcomplatencyP3: 0.0248\tmeanlatencyP1: 0.0381\tmeanlatencyP2: 0.0363\tmeanlatencyP3:0.0322\tmeanlatreward:0.0796\tmeanengreward:0.1059"
     ]
    }
   ],
   "source": [
    "def dqnp(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.9975,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "    \n",
    "    epi_all_trans_latency=[]\n",
    "    epi_all_trans_latency_P1=[]\n",
    "    epi_all_trans_latency_P2=[]\n",
    "    epi_all_trans_latency_P3=[]\n",
    "    epi_all_comp_latency=[]\n",
    "    epi_all_comp_latency_P1=[]\n",
    "    epi_all_comp_latency_P2=[]\n",
    "    epi_all_comp_latency_P3=[]\n",
    "    \n",
    "    \n",
    "    epi_comp_latency=[]\n",
    "    epi_comp_latency_P1=[]\n",
    "    epi_comp_latency_P2=[]\n",
    "    epi_comp_latency_P3=[]\n",
    "    epi_tran_latency=[]\n",
    "    epi_tran_latency_P1=[]\n",
    "    epi_tran_latency_P2=[]\n",
    "    epi_tran_latency_P3=[]\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "    epi_all_datasize_P1=[]\n",
    "    epi_all_datasize_P2=[]\n",
    "    epi_all_datasize_P3=[]\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "    epi_comp_energy=[]\n",
    "    epi_comp_frequency=[]\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "    mean_tran_latency=[]\n",
    "    mean_comp_latency=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "    mean_tran_latency_P1=[]\n",
    "    mean_tran_latency_P2=[]\n",
    "    mean_tran_latency_P3=[]\n",
    "    mean_comp_latency_P1=[]\n",
    "    mean_comp_latency_P2=[]\n",
    "    mean_comp_latency_P3=[]\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_comp_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_tran_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P3_window=deque(maxlen=window_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    (10, 10+R_1) ,(10+R_1,10+2*R_1),(10+2*R_1,10+3*R_1),(10+3*R_1,10+4*R_1),(10+4*R_1,float('inf'))\n",
    "    \n",
    "    bucket_tasks_mean = {(10, 10+R_1):{},(10+R_1,10+2*R_1):{},(10+2*R_1,10+3*R_1):{},\\\n",
    "                         (10+3*R_1,10+4*R_1):{},(10+4*R_1,float('inf')):{}}\n",
    "    bucket_task_len= {(10, 10+R_1):{},(10+R_1,10+2*R_1):{},(10+2*R_1,10+3*R_1):{},\\\n",
    "                         (10+3*R_1,10+4*R_1):{},(10+4*R_1,float('inf')):{}}\n",
    "    bucket_latency_mean={(10, 10+R_1):{},(10+R_1,10+2*R_1):{},(10+2*R_1,10+3*R_1):{},\\\n",
    "                         (10+3*R_1,10+4*R_1):{},(10+4*R_1,float('inf')):{}}\n",
    "    bucket_energy_mean= {(10, 10+R_1):{},(10+R_1,10+2*R_1):{},(10+2*R_1,10+3*R_1):{},\\\n",
    "                         (10+3*R_1,10+4*R_1):{},(10+4*R_1,float('inf')):{}}\n",
    "    bucket_data_mean= {(10, 10+R_1):{},(10+R_1,10+2*R_1):{},(10+2*R_1,10+3*R_1):{},\\\n",
    "                         (10+3*R_1,10+4*R_1):{},(10+4*R_1,float('inf')):{}}\n",
    "    #bucket_energy_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.50*max_dis):{},(0.5*max_dis,0.75*max_dis):{},(0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "        #mec_evn.max_freq_server= [np.random.choice([2,4,8,16])*1e9 for _ in range (3)]\n",
    "       # print(mec_evn.max_freq_server)\n",
    "     #   print(mec_evn.mec_servers)\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        comp_latency=[]\n",
    "        comp_latency_P1=[]\n",
    "        comp_latency_P2=[]\n",
    "        comp_latency_P3=[]\n",
    "        tran_latency=[]\n",
    "        tran_latency_P1=[]\n",
    "        tran_latency_P2=[]\n",
    "        tran_latency_P3=[]\n",
    "        compt_energy=[]\n",
    "        compt_freq=[]\n",
    "        all_trans_latency=[]\n",
    "        all_trans_latency_P1=[]\n",
    "        all_trans_latency_P2=[]\n",
    "        all_trans_latency_P3=[]\n",
    "        \n",
    "        all_comp_latency=[]\n",
    "        all_comp_latency_P1=[]\n",
    "        all_comp_latency_P2=[]\n",
    "        all_comp_latency_P3=[]\n",
    "        \n",
    "        all_datasize_P1=[]\n",
    "        all_datasize_P2=[]\n",
    "        all_datasize_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        reward_lat=[]\n",
    "        reward_eng=[]\n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        state = mec_evn.get_state(tasks)\n",
    "        for t in range(max_t):\n",
    "\n",
    "            \n",
    "            action = agent.act(state, eps)\n",
    "            next_state, feedback,done,action_task,next_task,rec_mec_idx = mec_evn.step(action,tasks)\n",
    "            agent.step(state, action, feedback['reward'], next_state, done)\n",
    "           \n",
    "            #print(mec_evn.max_freq_server)\n",
    "\n",
    "            score += feedback['reward']\n",
    "            energy.append(feedback['energy'])\n",
    "            \n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "            #print(user_distance)\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            tran_time=feedback['lat_vec'][0]\n",
    "            comp_time=feedback['lat_vec'][1]+feedback['lat_vec'][2] #comp_time+wait_time\n",
    "            reward_lat.append(feedback['reward_lat'])\n",
    "            reward_eng.append(feedback['reward_eng'])\n",
    "            all_trans_latency.append(tran_time)\n",
    "            all_comp_latency.append(comp_time)\n",
    "            trans_energy=feedback['eng_vector'][0]\n",
    "            comp_energy=feedback['eng_vector'][1]\n",
    "            compt_energy.append(comp_energy)\n",
    "            compt_freq.append(max(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*mec_evn.actions[action][1]))\n",
    "            \n",
    "           # print(min(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*mec_evn.actions[action][1]))\n",
    "           # print(tran_time,comp_time)\n",
    "            if feedback['task_done']==1:\n",
    "              datasize.append(action_task['data_size'])\n",
    "              latency.append(feedback['latency'])\n",
    "              comp_latency.append(comp_time)\n",
    "              tran_latency.append(tran_time)\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              \n",
    "              if action_task['priority']==1:\n",
    "                  \n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  all_datasize_P1.append(action_task['data_size'])\n",
    "                  \n",
    "                  all_trans_latency_P1.append(tran_time)\n",
    "                  all_comp_latency_P1.append(comp_time)\n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    comp_latency_P1.append(comp_time)\n",
    "                    tran_latency_P1.append(tran_time)\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    \n",
    "                    bucket_latency[bucket]['P1_latency'].append( tran_time)\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                  \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  \n",
    "                  task_done_P2.append(feedback['task_done'])\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                  \n",
    "                  all_datasize_P2.append(action_task['data_size'])\n",
    "                  all_trans_latency_P2.append(tran_time)\n",
    "                  all_comp_latency_P2.append(comp_time)\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    comp_latency_P2.append(comp_time)\n",
    "                    tran_latency_P2.append(tran_time)\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    \n",
    "                    bucket_latency[bucket]['P2_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                 \n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                  all_datasize_P3.append(action_task['data_size'])\n",
    "                  all_trans_latency_P3.append(tran_time)\n",
    "                  all_comp_latency_P3.append(comp_time)\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    comp_latency_P3.append(comp_time)\n",
    "                    tran_latency_P3.append(tran_time)\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    \n",
    "                    bucket_latency[bucket]['P3_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                   \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            tasks=next_task\n",
    "            state=next_state\n",
    "            if done:\n",
    "                print(t)\n",
    "                \n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "        \n",
    "        epi_comp_latency.append(np.mean(comp_latency))\n",
    "        epi_comp_latency_P1.append(np.mean(comp_latency_P1))\n",
    "        epi_comp_latency_P2.append(np.mean(comp_latency_P2))\n",
    "        epi_comp_latency_P3.append(np.mean(comp_latency_P3))\n",
    "        \n",
    "        epi_tran_latency.append(np.mean(tran_latency))\n",
    "        epi_tran_latency_P1.append(np.mean(tran_latency_P1))\n",
    "        epi_tran_latency_P2.append(np.mean(tran_latency_P2))\n",
    "        epi_tran_latency_P3.append(np.mean(tran_latency_P3))\n",
    "        \n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "        \n",
    "        epi_all_datasize_P1.append(np.mean(all_datasize_P1))\n",
    "        epi_all_datasize_P2.append(np.mean(all_datasize_P2))\n",
    "        epi_all_datasize_P3.append(np.mean(all_datasize_P3))\n",
    "\n",
    "        \n",
    "        epi_all_trans_latency.append(np.mean(all_trans_latency))\n",
    "        epi_all_trans_latency_P1.append(np.mean(all_trans_latency_P1))\n",
    "        epi_all_trans_latency_P2.append(np.mean(all_trans_latency_P2))\n",
    "        epi_all_trans_latency_P3.append(np.mean(all_trans_latency_P3))\n",
    "        epi_all_comp_latency.append(np.mean(all_comp_latency))\n",
    "        epi_all_comp_latency_P1.append(np.mean(all_comp_latency_P1))\n",
    "        epi_all_comp_latency_P2.append(np.mean(all_comp_latency_P2))\n",
    "        epi_all_comp_latency_P3.append(np.mean(all_comp_latency_P3))\n",
    "       \n",
    "        epi_comp_energy.append(np.mean(compt_energy))\n",
    "        epi_comp_frequency.append(np.mean(compt_freq))\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tcomplatencyP1: \\\n",
    "            {:.4f}\\tcomplatencyP2: {:.4f}\\tcomplatencyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}\\tmeanlatreward:{:.4f}\\tmeanengreward:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(comp_latency_P1), \\\n",
    "            np.mean(comp_latency_P2), np.mean(comp_latency_P3), \\\n",
    "                                    np.mean(tran_latency_P1), np.mean(tran_latency_P2), np.mean(tran_latency_P3),np.mean(reward_lat),np.mean(reward_eng)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "            \n",
    "            mean_comp_latency_P1_window.append(np.mean(comp_latency_P1))\n",
    "            mean_comp_latency_P1.append(np.mean( mean_comp_latency_P1_window))\n",
    "            mean_comp_latency_P2_window.append(np.mean(comp_latency_P2))\n",
    "            mean_comp_latency_P2.append(np.mean( mean_comp_latency_P2_window))\n",
    "            mean_comp_latency_P3_window.append(np.mean(comp_latency_P3))\n",
    "            mean_comp_latency_P3.append(np.mean( mean_comp_latency_P3_window))\n",
    "            \n",
    "            mean_tran_latency_P1_window.append(np.mean(tran_latency_P1))\n",
    "            mean_tran_latency_P1.append(np.mean( mean_tran_latency_P1_window))\n",
    "            mean_tran_latency_P2_window.append(np.mean(tran_latency_P2))\n",
    "            mean_tran_latency_P2.append(np.mean( mean_tran_latency_P2_window))\n",
    "            mean_tran_latency_P3_window.append(np.mean(tran_latency_P3))\n",
    "            mean_tran_latency_P3.append(np.mean( mean_tran_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "    {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: \\\n",
    "    {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f} \\tmean_tran_latencyP1: {:.4f}  \\\n",
    "    \\tmean_tran_latencyP2: {:.4f}  \\tmean_tran_latencyP3: {:.4f}  \\tmean_comp_latencyP1: {:.4f}  \\\n",
    "    \\tmean_comp_latencyP2: {:.4f} \\tmean_comp_latencyP3: {:.4f}'.format(\n",
    "        i_episode, mean_score, np.mean(mean_tasks_P1[-window_size:]), np.mean(mean_tasks_P2[-window_size:]),\n",
    "        np.mean(mean_tasks_P3[-window_size:]), np.mean(mean_energy_P1[-window_size:]), np.mean(mean_energy_P2[-window_size:]),\n",
    "        np.mean(mean_energy_P3[-window_size:]), np.mean(mean_latency_P1[-window_size:]), np.mean(mean_latency_P2[-window_size:]),\n",
    "        np.mean(mean_latency_P3[-window_size:]), np.mean(mean_datasize[-window_size:]), np.mean(mean_datasize_P1[-window_size:]),\n",
    "        np.mean(mean_datasize_P2[-window_size:]), np.mean(mean_datasize_P3[-window_size:]), np.mean(mean_tran_latency_P1[-window_size:]),\n",
    "        np.mean(mean_tran_latency_P2[-window_size:]), np.mean(mean_tran_latency_P3[-window_size:]), np.mean(mean_comp_latency_P1[-window_size:]),\n",
    "        np.mean(mean_comp_latency_P2[-window_size:]), np.mean(mean_comp_latency_P3[-window_size:]))\n",
    ")\n",
    "                                                                                           \n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10,10+R_1)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(10+R_1,10+2*R_1)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(10+2*R_1,10+3*R_1)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(10+3*R_1,10+4*R_1)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(10+4*R_1,float('inf'))]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10,10+R_1)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(10+R_1,10+2*R_1)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(10+2*R_1,10+3*R_1)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(10+3*R_1,10+4*R_1)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(10+4*R_1,float('inf'))]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10,10+R_1)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(10+R_1,10+2*R_1)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(10+2*R_1,10+3*R_1)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(10+3*R_1,10+4*R_1)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(10+4*R_1,float('inf'))]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10,10+R_1)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(10+R_1,10+2*R_1)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(10+2*R_1,10+3*R_1)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(10+3*R_1,10+4*R_1)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(10+4*R_1,float('inf'))]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10,10+R_1)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(10+R_1,10+2*R_1)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(10+2*R_1,10+3*R_1)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(10+3*R_1,10+4*R_1)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(10+4*R_1,float('inf'))]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10,10+R_1)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(10+R_1,10+2*R_1)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(10+2*R_1,10+3*R_1)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(10+3*R_1,10+4*R_1)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(10+4*R_1,float('inf'))]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10,10+R_1)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(10+R_1,10+2*R_1)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(10+2*R_1,10+3*R_1)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(10+3*R_1,10+4*R_1)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(10+4*R_1,float('inf'))]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10,10+R_1)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(10+R_1,10+2*R_1)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(10+2*R_1,10+3*R_1)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(10+3*R_1,10+4*R_1)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(10+4*R_1,float('inf'))]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10,10+R_1)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(10+R_1,10+2*R_1)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(10+2*R_1,10+3*R_1)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(10+3*R_1,10+4*R_1)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(10+4*R_1,float('inf'))]['P3_latency_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10,10+R_1)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(10+R_1,10+2*R_1)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(10+2*R_1,10+3*R_1)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(10+3*R_1,10+4*R_1)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(10+4*R_1,float('inf'))]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10,10+R_1)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(10+R_1,10+2*R_1)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(10+2*R_1,10+3*R_1)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(10+3*R_1,10+4*R_1)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(10+4*R_1,float('inf'))]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10,10+R_1)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(10+R_1,10+2*R_1)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(10+2*R_1,10+3*R_1)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(10+3*R_1,10+4*R_1)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(10+4*R_1,float('inf'))]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10,10+R_1)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(10+R_1,10+2*R_1)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(10+2*R_1,10+3*R_1)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(10+3*R_1,10+4*R_1)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(10+4*R_1,float('inf'))]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10,10+R_1)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(10+R_1,10+2*R_1)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(10+2*R_1,10+3*R_1)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(10+3*R_1,10+4*R_1)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(10+4*R_1,float('inf'))]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10,10+R_1)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(10+R_1,10+2*R_1)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(10+2*R_1,10+3*R_1)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(10+3*R_1,10+4*R_1)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(10+4*R_1,float('inf'))]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "\n",
    "            print('all_tran',np.mean(epi_all_trans_latency[-window_size:]), 'all_comp',np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            print('all_tran_P1',np.mean(epi_all_trans_latency_P1[-window_size:]),\\\n",
    "                  'all_tran_P2',np.mean(epi_all_trans_latency_P2[-window_size:]),\\\n",
    "                      'all_tran_P3',np.mean(epi_all_trans_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_comp_P1',np.mean(epi_all_comp_latency_P1[-window_size:]),\\\n",
    "                  'all_comp_P2',np.mean(epi_all_comp_latency_P2[-window_size:]),\\\n",
    "                 'all_comp_P3',np.mean(epi_all_comp_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_data_P1',np.mean(epi_all_datasize_P1[-window_size:]),\\\n",
    "                  'all_data_P2',np.mean(epi_all_datasize_P2[-window_size:]),\\\n",
    "                 'all_data_P3',np.mean(epi_all_datasize_P3[-window_size:]))\n",
    "            \n",
    "            \n",
    "            print('epi_comp_energy', np.mean(epi_comp_energy[-window_size:]))\n",
    "            print('epi_comp_freq', np.mean(epi_comp_frequency[-window_size:]))\n",
    "            print('epi_comp_latency', np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), model_path)\n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3,epi_tran_latency_P1,epi_tran_latency_P2,\\\n",
    "                 epi_tran_latency_P3,epi_comp_latency_P1,epi_comp_latency_P2,epi_comp_latency_P3\n",
    "\n",
    "dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\\\n",
    "dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,dqnp_epi_task_select_P3,\\\n",
    "dqnp_mean_scores,dqnp_mean_task,dqnp_mean_energy,dqnp_mean_latency,dqnp_win_num_task, dqnp_mean_tasks_P1,dqnp_mean_tasks_P2,dqnp_mean_tasks_P3,\\\n",
    "dqnp_mean_energy_P1,dqnp_mean_energy_P2,dqnp_mean_energy_P3,dqnp_mean_latency_P1,dqnp_mean_latency_P2,dqnp_mean_latency_P3 ,dqnp_win_num_task_P1, dqnp_win_num_task_P2,dqnp_win_num_task_P3,\\\n",
    "dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_mean_datasize,dqnp_mean_datasize_P1,dqnp_mean_datasize_P2,dqnp_mean_datasize_P3,\\\n",
    "dqnp_epi_tran_latency_P1,dqnp_epi_tran_latency_P2,dqnp_epi_tran_latency_P3,dqnp_epi_comp_latency_P1,dqnp_epi_comp_latency_P2,\\\n",
    "dqnp_epi_comp_latency_P3= dqnp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Episode 75\tAverage Score: -942.6496\tmeantaskP1: 0.2643\tmeantaskP2: 0.2371\tmeantaskP3: 0.1686\tcomplatencyP1:             0.0069\tcomplatencyP2: 0.0070\tcomplatencyP3: 0.0070\tmeanlatencyP1: 0.0404\tmeanlatencyP2: 0.0429\tmeanlatencyP3:0.0300\tmeanlatreward:0.1205\tmeanengreward:1.5462"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Episode 117\tAverage Score: 223.9963\tmeantaskP1: 0.5197\tmeantaskP2: 0.5284\tmeantaskP3: 0.5145\tcomplatencyP1:             0.0104\tcomplatencyP2: 0.0110\tcomplatencyP3: 0.0104\tmeanlatencyP1: 0.0287\tmeanlatencyP2: 0.0322\tmeanlatencyP3:0.0352\tmeanlatreward:0.0318\tmeanengreward:0.0419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv4vHu2WdTeh"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(dqnp_epi_scores) + 1), dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,\n",
    "           dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\n",
    "           dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,\n",
    "           dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,\\\n",
    "           dqnp_epi_task_select_P3,dqnp_epi_tran_latency_P1,dqnp_epi_tran_latency_P2,dqnp_epi_tran_latency_P3,\\\n",
    "                    dqnp_epi_comp_latency_P1,dqnp_epi_comp_latency_P2,dqnp_epi_comp_latency_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_dqnp.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"dqnp_epi_scores\",\"dqnp_epi_task\",\"dqnp_epi_energy\",\"dqnp_epi_latency\",\"dqnp_epi_num_task\",\"dqnp_epi_task_P1\",\"dqnp_epi_task_P2\",\"dqnp_epi_task_P3\",\n",
    "                     \"dqnp_epi_latency_P1\",\"dqnp_epi_latency_P2\",\"dqnp_epi_latency_P3\",\"dqnp_epi_energy_P1\",\"dqnp_epi_energy_P2\",\"dqnp_epi_energy_P3\",\"dqnp_epi_num_task_P1\",\n",
    "                     \"dqnp_epi_num_task_P2\",\"dqnp_epi_num_task_P3\",\"dqnp_epi_datasize\",\"dqnp_epi_datasize_P1\",\"dqnp_epi_datasize_P2\"\n",
    "                     \"dqnp_epi_datasize_P3\",\"dqnp_epi_task_select_P1\",\"dqnp_epi_task_select_P2\",\"dqnp_epi_task_select_P3\",\\\n",
    "                    \"dqnp_epi_tran_latency_P1\",\"dqnp_epi_tran_latency_P2\",\"dqnp_epi_tran_latency_P3\",\\\n",
    "                    \"dqnp_epi_comp_latency_P1\",\"dqnp_epi_comp_latency_P2\",\"dqnp_epi_comp_latency_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPOR-vhHGnKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0IPp62mG4OL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBbu3Rgm1yrC"
   },
   "source": [
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
