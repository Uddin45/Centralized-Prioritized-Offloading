{"cells":[{"cell_type":"markdown","metadata":{"id":"-_2c3s5mPjSr"},"source":["+++++[link text](https:// [link text](https://))### 1. Read environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1416,"status":"ok","timestamp":1708748582130,"user":{"displayName":"Ashab Uddin","userId":"01269056925752111948"},"user_tz":300},"id":"jc1n8GcSNWxH","outputId":"1d018d8d-66e6-40f4-fe14-6f4330401ab5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Work/Original/V2_diff_weight_diff_deadline_60_90\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Work\"/\"Original\"/\"V2_diff_weight_diff_deadline_60_90\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708748582131,"user":{"displayName":"Ashab Uddin","userId":"01269056925752111948"},"user_tz":300},"id":"4v2mf8TUrIW6","outputId":"1da620b0-2de6-4bf0-d340-df0aefb70634"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Directory: /content/drive/MyDrive/Work/Original/V2_diff_weight_diff_deadline_60_90\n"]}],"source":["import os\n","\n","current_directory = os.getcwd()\n","print(\"Current Directory:\", current_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pw1W2pj5R-9H"},"outputs":[],"source":["# ! pip install fastai"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1708748582462,"user":{"displayName":"Ashab Uddin","userId":"01269056925752111948"},"user_tz":300},"id":"yDgZsDSYPjSu","outputId":"8af7aefd-e7d9-47e6-d51c-89264f97672b"},"outputs":[{"name":"stdout","output_type":"stream","text":["47\n","{}\n","26\n","20\n","1\n","{'data_size': 38538, 'circle': 34333, 'user_index': 45, 'priority': 1, 'user_distance': [73.24432832803505, 27.37550383503425, 94.52039350435943], 'delta_max': 0.081}\n","{'data_size': 7786, 'circle': 126858, 'user_index': 49, 'priority': 2, 'user_distance': [25.21856312829912, 80.65914057569017, 158.66889421232472], 'delta_max': 0.07100000000000001}\n","{'data_size': 27998, 'circle': 160798, 'user_index': 27, 'priority': 3, 'user_distance': [94.85005783033178, 27.516539712943118, 72.92315438275192], 'delta_max': 0.062}\n"]}],"source":["import numpy as np\n","from mec_environment import MECEnvironment\n","from random_agent import RandomAgent\n","\n","mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=1)"]},{"cell_type":"markdown","metadata":{"id":"ALZLc1DEPjSw"},"source":["### 2. Examine the State and Action Spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708748582463,"user":{"displayName":"Ashab Uddin","userId":"01269056925752111948"},"user_tz":300},"id":"tLC_64NIPjSx","outputId":"c3fc45f0-04b7-461e-c540-41d930a8f6bb","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{45: {'speed': array([1.01584111e+05, 2.74989327e+06, 1.99971925e+03])}, 49: {'speed': array([5.51497940e+06, 2.74334686e+05, 1.28396155e+03])}, 27: {'speed': array([  11566.21382718, 6750667.92829696,  194976.75391462])}}\n","Action size: 45\n","Action space: [(0, 0.1, 0), (0, 0.1, 1), (0, 0.1, 2), (0, 0.325, 0), (0, 0.325, 1), (0, 0.325, 2), (0, 0.55, 0), (0, 0.55, 1), (0, 0.55, 2), (0, 0.775, 0), (0, 0.775, 1), (0, 0.775, 2), (0, 1.0, 0), (0, 1.0, 1), (0, 1.0, 2), (1, 0.1, 0), (1, 0.1, 1), (1, 0.1, 2), (1, 0.325, 0), (1, 0.325, 1), (1, 0.325, 2), (1, 0.55, 0), (1, 0.55, 1), (1, 0.55, 2), (1, 0.775, 0), (1, 0.775, 1), (1, 0.775, 2), (1, 1.0, 0), (1, 1.0, 1), (1, 1.0, 2), (2, 0.1, 0), (2, 0.1, 1), (2, 0.1, 2), (2, 0.325, 0), (2, 0.325, 1), (2, 0.325, 2), (2, 0.55, 0), (2, 0.55, 1), (2, 0.55, 2), (2, 0.775, 0), (2, 0.775, 1), (2, 0.775, 2), (2, 1.0, 0), (2, 1.0, 1), (2, 1.0, 2)]\n","Observes a state with length: 30\n","state size: 30\n","The state for the first agent looks like: [1.11054277e-02 6.02911264e-01 1.26444726e-03 3.00625172e-01\n"," 2.99909502e-02 7.37999808e-01 2.18614282e-04 1.40365870e-04\n"," 2.13153437e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 8.00000000e+00 2.00000000e+00 4.00000000e+00 3.85380000e-01\n"," 3.43330000e-01 8.10000000e-02 1.00000000e+00 4.60000000e+01\n"," 7.78600000e-02 1.26858000e+00 7.10000000e-02 2.00000000e+00\n"," 5.00000000e+01 2.79980000e-01 1.60798000e+00 6.20000000e-02\n"," 3.00000000e+00 2.80000000e+01]\n"]}],"source":["action_size = mec_evn.action_size()\n","\n","task=mec_evn.get_task()\n","\n","states = mec_evn.get_state(task)\n","print(mec_evn.trans_speed_matrix)\n","state_size = mec_evn.state_size()\n","action_space = mec_evn.actions\n","print('Action size: {}'.format(action_size))\n","print('Action space: {}'.format(action_space))\n","print('Observes a state with length: {}'.format(state_size))\n","print('state size: {}'.format(len(states)))\n","print('The state for the first agent looks like:', states)"]},{"cell_type":"markdown","metadata":{"id":"-vapCU_9PjSy"},"source":["### 3. Take Random Actions in the Environment"]},{"cell_type":"markdown","metadata":{"id":"OF7ASsRcPjSz"},"source":["### 6. Take Actions with DQN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq2lQI0LPjSz"},"outputs":[],"source":["epoch_no =2500\n","window_size =250"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmtnPud5PjS0"},"outputs":[],"source":["import torch\n","from collections import deque\n","from greedy_agent import GreedyAgent\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PSLBUj5oPjS1"},"outputs":[],"source":["from dqn_agent import Agent\n","agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n","model_path = os.path.join(current_directory, 'model_dqnp_checkpoint.pth')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"4FCat57h05aF","outputId":"2dbbb747-7816-4596-f96b-0a8028b1170c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 250\tAverage Score: 329.4058\tmeantaskP1: 0.7645\tmeantaskP2: 0.7794\tmeantaskP3: 0.8763\tmeanenergyP1:             0.1938\tmeanenergyP2: 0.1693\tmeanenergyP3: 0.6793 \tmeanlatencyP1: 0.0150 \tmeanlatencyP2: 0.0140 \tmeanlatencyP3: 0.0113 \tmeandatasize: 22100.6380 \tmeandatasizeP1: 24995.1240 \tmeandatasizeP2: 23455.5302 \tmeandatasizeP3: 19833.9916\n","mean_task_till_this_window 0.6169831108442679 T1:: 0.5810660514504425 T2:: 0.59623054523287 T3:: 0.6566013296512307\n","task_select_P1 284.452 task_select_P2 304.324 task_select_P3 393.888\n","total_task_done_P1:: 163.08 total_task_done_P2:: 180.632 total_task_done_P3:: 263.376\n","Episode 500\tAverage Score: 474.1415\tmeantaskP1: 0.8358\tmeantaskP2: 0.8373\tmeantaskP3: 0.9122\tmeanenergyP1:             0.1614\tmeanenergyP2: 0.1142\tmeanenergyP3: 0.3526 \tmeanlatencyP1: 0.0137 \tmeanlatencyP2: 0.0122 \tmeanlatencyP3: 0.0112 \tmeandatasize: 21956.8610 \tmeandatasizeP1: 24525.0053 \tmeandatasizeP2: 23400.1260 \tmeandatasizeP3: 20093.4698\n","mean_task_till_this_window 0.880413991960575 T1:: 0.8348846440779216 T2:: 0.8669301950947254 T3:: 0.9096757832285154\n","task_select_P1 223.176 task_select_P2 287.084 task_select_P3 479.92\n","total_task_done_P1:: 185.772 total_task_done_P2:: 248.796 total_task_done_P3:: 436.868\n","Episode 750\tAverage Score: 500.6527\tmeantaskP1: 0.8855\tmeantaskP2: 0.8828\tmeantaskP3: 0.9349\tmeanenergyP1:             0.1178\tmeanenergyP2: 0.0814\tmeanenergyP3: 0.2411 \tmeanlatencyP1: 0.0132 \tmeanlatencyP2: 0.0118 \tmeanlatencyP3: 0.0109 \tmeandatasize: 21899.7447 \tmeandatasizeP1: 25001.1238 \tmeandatasizeP2: 23372.7659 \tmeandatasizeP3: 20049.4748\n","mean_task_till_this_window 0.9535734831576853 T1:: 0.9313026489202321 T2:: 0.9524765717886983 T3:: 0.9619938564221638\n","task_select_P1 169.784 task_select_P2 282.88 task_select_P3 504.9\n","total_task_done_P1:: 157.948 total_task_done_P2:: 269.524 total_task_done_P3:: 485.872\n","Episode 863\tAverage Score: 510.4653\tmeantaskP1: 0.9545\tmeantaskP2: 0.9593\tmeantaskP3: 0.9750\tmeanenergyP1:             0.0171\tmeanenergyP2: 0.0171\tmeanenergyP3: 0.0179\tmeanlatencyP1: 0.0118\tmeanlatencyP2: 0.0115\tmeanlatencyP3:0.0113"]}],"source":["def dqnp(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n","    \"\"\"Deep Q-Learning.\n","\n","    Params\n","    ======\n","        n_episodes (int): maximum number of training episodes\n","        max_t (int): maximum number of atimesteps per episode\n","        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n","        eps_end (float): minimum value of epsilon\n","        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n","    \"\"\"\n","    epi_scores = []                        # list containing scores from each episode\n","    epi_task=[]\n","    epi_task_P1=[]\n","    epi_task_P2=[]\n","    epi_task_P3=[]\n","\n","\n","    epi_latency=[]\n","    epi_latency_P1=[]\n","    epi_latency_P2=[]\n","    epi_latency_P3=[]\n","    epi_task_select_P1=[]\n","    epi_task_select_P2=[]\n","    epi_task_select_P3=[]\n","    epi_datasize=[]\n","    epi_datasize_P1=[]\n","    epi_datasize_P2=[]\n","    epi_datasize_P3=[]\n","\n","    epi_energy=[]\n","    epi_energy_P1=[]\n","    epi_energy_P2=[]\n","    epi_energy_P3=[]\n","\n","    epi_num_task=[]\n","    epi_num_task_P1=[]\n","    epi_num_task_P2=[]\n","    epi_num_task_P3=[]\n","\n","    mean_scores = [] # average score by the windos size\n","    mean_task=[] # average task ratio by window size\n","    mean_energy = [] # average energy cost by window size\n","    mean_latency=[]\n","    mean_datasize=[]\n","\n","    mean_tasks_P1=[]\n","    mean_tasks_P2=[]\n","    mean_tasks_P3=[]\n","\n","    mean_energy_P1=[]\n","    mean_energy_P2=[]\n","    mean_energy_P3=[]\n","\n","    mean_latency_P1=[]\n","    mean_latency_P2=[]\n","    mean_latency_P3=[]\n","\n","\n","    mean_datasize_P1=[]\n","    mean_datasize_P2=[]\n","    mean_datasize_P3=[]\n","    reward_list_P1=[]\n","    reward_list_P2=[]\n","    reward_list_P3=[]\n","\n","    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n","    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n","    energy_window = deque(maxlen=window_size)  # last  engery cost\n","    latency_window = deque(maxlen=window_size)  # last  engery cost\n","    datasize_window= deque(maxlen=window_size)\n","\n","\n","    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    win_num_task = deque(maxlen=window_size)\n","    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_datasize_window=deque(maxlen=window_size)\n","    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_latency_P1_window=deque(maxlen=window_size)\n","    mean_latency_P2_window=deque(maxlen=window_size)\n","    mean_latency_P3_window=deque(maxlen=window_size)\n","\n","\n","\n","    eps = eps_start                    # initialize epsilon\n","    for i_episode in range(1, n_episodes+1):\n","        mec_evn.reset() # reset the environment\n","\n","        score = 0\n","        energy = []\n","        latency=[]\n","        task_done = []\n","        energy_P1=[]\n","        energy_P2=[]\n","        energy_P3=[]\n","        task_done_P1=[]\n","        task_done_P2=[]\n","        task_done_P3=[]\n","        latency_P1=[]\n","        latency_P2=[]\n","        latency_P3=[]\n","        datasize=[]\n","        datasize_P1=[]\n","        datasize_P2=[]\n","        datasize_P3=[]\n","\n","\n","\n","        tasks = mec_evn.get_task()\n","        for t in range(max_t):\n","\n","            state = mec_evn.get_state(tasks)\n","            action = agent.act(state, eps)\n","            next_state, feedback,done,action_task,next_task,rec_mec_idx = mec_evn.step(action,tasks)\n","            agent.step(state, action, feedback['reward'], next_state, done)\n","\n","            score += feedback['reward']\n","            energy.append(feedback['energy'])\n","            datasize.append(action_task['data_size'])\n","\n","            if feedback['task_done']==1:\n","\n","              latency.append(feedback['latency'])\n","\n","\n","            if action_task['data_size'] != 0:\n","              task_done.append(feedback['task_done'])\n","              if action_task['priority']==1:\n","                  energy_P1.append(feedback['energy'])\n","                  task_done_P1.append(feedback['task_done'])\n","                  datasize_P1.append(action_task['data_size'])\n","                  reward_list_P1.append(feedback['reward'])\n","\n","                  if feedback['task_done']:\n","                    latency_P1.append(feedback['latency'])\n","\n","              if action_task['priority']==2:\n","                  energy_P2.append(feedback['energy'])\n","                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n","                  datasize_P2.append(action_task['data_size'])\n","                  reward_list_P2.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P2.append(feedback['latency'])\n","\n","              if action_task['priority']==3:\n","                  energy_P3.append(feedback['energy'])\n","                  task_done_P3.append(feedback['task_done'])\n","                  datasize_P3.append(action_task['data_size'])\n","                  reward_list_P3.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P3.append(feedback['latency'])\n","\n","\n","\n","            tasks=next_task\n","            if done:\n","                break\n","        scores_window.append(score)       # save most recent score\n","        epi_scores.append(score)              # save most recent score\n","        mean_score = np.mean(scores_window)\n","        epi_task.append(np.mean(task_done))\n","        epi_task_P1.append(np.mean(task_done_P1))\n","        epi_task_P2.append(np.mean(task_done_P2))\n","        epi_task_P3.append(np.mean(task_done_P3))\n","\n","        epi_task_select_P1.append(len(task_done_P1))\n","        epi_task_select_P2.append(len(task_done_P2))\n","        epi_task_select_P3.append(len(task_done_P3))\n","\n","        epi_latency.append(np.mean(latency))\n","        epi_latency_P1.append(np.mean(latency_P1))\n","        epi_latency_P2.append(np.mean(latency_P2))\n","        epi_latency_P3.append(np.mean(latency_P3))\n","\n","        epi_energy.append(np.mean(energy))\n","        epi_energy_P1.append(np.mean(energy_P1))\n","        epi_energy_P2.append(np.mean(energy_P2))\n","        epi_energy_P3.append(np.mean(energy_P3))\n","\n","        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","        epi_num_task_P1.append(sum(task_done_P1))\n","        epi_num_task_P2.append(sum(task_done_P2))\n","        epi_num_task_P3.append(sum(task_done_P3))\n","\n","        epi_datasize.append(np.mean(datasize))\n","        epi_datasize_P1.append(np.mean(datasize_P1))\n","        epi_datasize_P2.append(np.mean(datasize_P2))\n","        epi_datasize_P3.append(np.mean(datasize_P3))\n","\n","\n","\n","\n","\n","        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n","\n","        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n","            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n","                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n","\n","\n","\n","\n","\n","        if i_episode % window_size == 0:\n","\n","\n","            mean_scores.append(mean_score)\n","            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n","            mean_task.append(np.mean(task_done_ratio_window))\n","            energy_window.append(np.mean(energy))\n","            latency_window.append(np.mean(latency))\n","\n","            mean_energy.append(np.mean(energy_window))\n","            mean_latency.append(np.mean(latency_window))\n","\n","\n","            mean_datasize_window.append(np.mean(datasize))\n","            mean_datasize.append(np.mean(mean_datasize_window))\n","\n","            mean_tasks_P1_window.append(np.mean(task_done_P1))\n","            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n","\n","            mean_tasks_P2_window.append(np.mean(task_done_P2))\n","            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n","\n","            mean_tasks_P3_window.append(np.mean(task_done_P3))\n","            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n","\n","            mean_energy_window_P1.append(np.mean(energy_P1))\n","            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n","\n","            mean_energy_window_P2.append(np.mean(energy_P2))\n","            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n","\n","            mean_energy_window_P3.append(np.mean(energy_P3))\n","            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n","\n","\n","            mean_latency_P1_window.append(np.mean(latency_P1))\n","            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n","\n","            mean_latency_P2_window.append(np.mean(latency_P2))\n","            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n","\n","            mean_latency_P3_window.append(np.mean(latency_P3))\n","            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n","\n","            mean_datasize_P1_window.append(np.mean(datasize_P1))\n","            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n","\n","            mean_datasize_P2_window.append(np.mean(datasize_P2))\n","            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n","\n","            mean_datasize_P3_window.append(np.mean(datasize_P3))\n","            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n","\n","\n","            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","            win_num_task_P1.append(sum(task_done_P1))\n","            win_num_task_P2.append(sum(task_done_P2))\n","            win_num_task_P3.append(sum(task_done_P3))\n","\n","\n","            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n","            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n","                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n","\n","\n","\n","                                                                                                                                                                                                                                                       ))\n","\n","\n","            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n","           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n","            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n","            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n","           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n","           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n","            #print('mean_datasize', mean_datasize[-1])\n","            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n","            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n","\n","            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n","            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n","           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n","\n","\n","            #print(mean_tasks_P1)\n","           # print(epi_task_P1)\n","\n","\n","\n","        if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n","            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n","            torch.save(agent.qnetwork_local.state_dict(), model_path)\n","            break\n","\n","    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n","    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n","                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n","                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n","\n","dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\\\n","dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,dqnp_epi_task_select_P3,\\\n","dqnp_mean_scores,dqnp_mean_task,dqnp_mean_energy,dqnp_mean_latency,dqnp_win_num_task, dqnp_mean_tasks_P1,dqnp_mean_tasks_P2,dqnp_mean_tasks_P3,\\\n","dqnp_mean_energy_P1,dqnp_mean_energy_P2,dqnp_mean_energy_P3,dqnp_mean_latency_P1,dqnp_mean_latency_P2,dqnp_mean_latency_P3 ,dqnp_win_num_task_P1, dqnp_win_num_task_P2,dqnp_win_num_task_P3,\\\n","dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_mean_datasize,dqnp_mean_datasize_P1,dqnp_mean_datasize_P2,dqnp_mean_datasize_P3 = dqnp()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53xoR59lZevt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNcbaKBSXB1O"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv4vHu2WdTeh"},"outputs":[],"source":["import csv\n","\n","\n","# Combining data into a list of tuples\n","data = zip(range(1, len(dqnp_epi_scores) + 1), dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,\n","           dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\n","           dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,\n","           dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,dqnp_epi_task_select_P3)\n","\n","# Writing data to a CSV file\n","with open(\"data_dqnp.csv\", mode=\"w\", newline=\"\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Index\",\"dqnp_epi_scores\",\"dqnp_epi_task\",\"dqnp_epi_energy\",\"dqnp_epi_latency\",\"dqnp_epi_num_task\",\"dqnp_epi_task_P1\",\"dqnp_epi_task_P2\",\"dqnp_epi_task_P3\",\n","                     \"dqnp_epi_latency_P1\",\"dqnp_epi_latency_P2\",\"dqnp_epi_latency_P3\",\"dqnp_epi_energy_P1\",\"dqnp_epi_energy_P2\",\"dqnp_epi_energy_P3\",\"dqnp_epi_num_task_P1\",\n","                     \"dqnp_epi_num_task_P2\",\"dqnp_epi_num_task_P3\",\"dqnp_epi_datasize\",\"dqnp_epi_datasize_P1\",\"dqnp_epi_datasize_P2\"\n","                     \"dqnp_epi_datasize_P3\",\"dqnp_epi_task_select_P1\",\"dqnp_epi_task_select_P2\",\"dqnp_epi_task_select_P3\"])  # Writing header\n","    writer.writerows(data)  # Writing data rows\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8dj2oNedTej"},"outputs":[],"source":["import os\n","\n","current_directory = os.getcwd()\n","print(\"Current Directory:\", current_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyrrgUOrP78d"},"outputs":[],"source":["import numpy as np\n","from mec_environment import MECEnvironment\n","from random_agent import RandomAgent\n","\n","mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KE4R2jl-P78e"},"outputs":[],"source":["action_size = mec_evn.action_size()\n","Task=mec_evn.get_task()\n","states = mec_evn.get_state(Task)\n","state_size = mec_evn.state_size()\n","action_space = mec_evn.actions\n","print('Action size: {}'.format(action_size))\n","print('Action space: {}'.format(action_space))\n","print('Observes a state with length: {}'.format(state_size))\n","print('state size: {}'.format(len(states)))\n","print('The state for the first agent looks like:', states)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBtx8tG1MEGO"},"outputs":[],"source":["epoch_no =2500\n","window_size =250"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRB1DlbNP78e"},"outputs":[],"source":["import torch\n","from collections import deque\n","from greedy_agent import GreedyAgent\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHi0hSOaP78f"},"outputs":[],"source":["from dqn_agent import Agent\n","agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n","model_path = os.path.join(current_directory, 'model_dqnb_checkpoint.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7k4M5QjPjS1","scrolled":false},"outputs":[],"source":["def dqnb(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n","    \"\"\"Deep Q-Learning.\n","\n","    Params\n","    ======\n","        n_episodes (int): maximum number of training episodes\n","        max_t (int): maximum number of atimesteps per episode\n","        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n","        eps_end (float): minimum value of epsilon\n","        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n","    \"\"\"\n","    epi_scores = []                        # list containing scores from each episode\n","    epi_task=[]\n","    epi_task_P1=[]\n","    epi_task_P2=[]\n","    epi_task_P3=[]\n","\n","\n","    epi_latency=[]\n","    epi_latency_P1=[]\n","    epi_latency_P2=[]\n","    epi_latency_P3=[]\n","    epi_task_select_P1=[]\n","    epi_task_select_P2=[]\n","    epi_task_select_P3=[]\n","    epi_datasize=[]\n","    epi_datasize_P1=[]\n","    epi_datasize_P2=[]\n","    epi_datasize_P3=[]\n","\n","    epi_energy=[]\n","    epi_energy_P1=[]\n","    epi_energy_P2=[]\n","    epi_energy_P3=[]\n","\n","    epi_num_task=[]\n","    epi_num_task_P1=[]\n","    epi_num_task_P2=[]\n","    epi_num_task_P3=[]\n","\n","    mean_scores = [] # average score by the windos size\n","    mean_task=[] # average task ratio by window size\n","    mean_energy = [] # average energy cost by window size\n","    mean_latency=[]\n","    mean_datasize=[]\n","\n","    mean_tasks_P1=[]\n","    mean_tasks_P2=[]\n","    mean_tasks_P3=[]\n","\n","    mean_energy_P1=[]\n","    mean_energy_P2=[]\n","    mean_energy_P3=[]\n","\n","    mean_latency_P1=[]\n","    mean_latency_P2=[]\n","    mean_latency_P3=[]\n","\n","\n","    mean_datasize_P1=[]\n","    mean_datasize_P2=[]\n","    mean_datasize_P3=[]\n","    reward_list_P1=[]\n","    reward_list_P2=[]\n","    reward_list_P3=[]\n","\n","    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n","    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n","    energy_window = deque(maxlen=window_size)  # last  engery cost\n","    latency_window = deque(maxlen=window_size)  # last  engery cost\n","    datasize_window= deque(maxlen=window_size)\n","\n","\n","    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    win_num_task = deque(maxlen=window_size)\n","    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_datasize_window=deque(maxlen=window_size)\n","    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_latency_P1_window=deque(maxlen=window_size)\n","    mean_latency_P2_window=deque(maxlen=window_size)\n","    mean_latency_P3_window=deque(maxlen=window_size)\n","\n","\n","\n","    eps = eps_start                    # initialize epsilon\n","    for i_episode in range(1, n_episodes+1):\n","        mec_evn.reset() # reset the environment\n","\n","        score = 0\n","        energy = []\n","        latency=[]\n","        task_done = []\n","        energy_P1=[]\n","        energy_P2=[]\n","        energy_P3=[]\n","        task_done_P1=[]\n","        task_done_P2=[]\n","        task_done_P3=[]\n","        latency_P1=[]\n","        latency_P2=[]\n","        latency_P3=[]\n","        datasize=[]\n","        datasize_P1=[]\n","        datasize_P2=[]\n","        datasize_P3=[]\n","\n","\n","\n","        tasks = mec_evn.get_task()\n","        for t in range(max_t):\n","\n","            state = mec_evn.get_state(tasks)\n","            action = agent.act(state, eps)\n","            next_state, feedback,done,action_task,next_task = mec_evn.step(action,tasks)\n","            agent.step(state, action, feedback['reward'], next_state, done)\n","\n","            score += feedback['reward']\n","            energy.append(feedback['energy'])\n","            datasize.append(action_task['data_size'])\n","\n","            if feedback['task_done']==1:\n","\n","              latency.append(feedback['latency'])\n","\n","\n","            if action_task['data_size'] != 0:\n","              task_done.append(feedback['task_done'])\n","              if action_task['priority']==1:\n","                  energy_P1.append(feedback['energy'])\n","                  task_done_P1.append(feedback['task_done'])\n","                  datasize_P1.append(action_task['data_size'])\n","                  reward_list_P1.append(feedback['reward'])\n","\n","                  if feedback['task_done']:\n","                    latency_P1.append(feedback['latency'])\n","\n","              if action_task['priority']==2:\n","                  energy_P2.append(feedback['energy'])\n","                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n","                  datasize_P2.append(action_task['data_size'])\n","                  reward_list_P2.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P2.append(feedback['latency'])\n","\n","              if action_task['priority']==3:\n","                  energy_P3.append(feedback['energy'])\n","                  task_done_P3.append(feedback['task_done'])\n","                  datasize_P3.append(action_task['data_size'])\n","                  reward_list_P3.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P3.append(feedback['latency'])\n","\n","\n","\n","            tasks=next_task\n","            if done:\n","                break\n","        scores_window.append(score)       # save most recent score\n","        epi_scores.append(score)              # save most recent score\n","        mean_score = np.mean(scores_window)\n","        epi_task.append(np.mean(task_done))\n","        epi_task_P1.append(np.mean(task_done_P1))\n","        epi_task_P2.append(np.mean(task_done_P2))\n","        epi_task_P3.append(np.mean(task_done_P3))\n","\n","        epi_task_select_P1.append(len(task_done_P1))\n","        epi_task_select_P2.append(len(task_done_P2))\n","        epi_task_select_P3.append(len(task_done_P3))\n","\n","        epi_latency.append(np.mean(latency))\n","        epi_latency_P1.append(np.mean(latency_P1))\n","        epi_latency_P2.append(np.mean(latency_P2))\n","        epi_latency_P3.append(np.mean(latency_P3))\n","\n","        epi_energy.append(np.mean(energy))\n","        epi_energy_P1.append(np.mean(energy_P1))\n","        epi_energy_P2.append(np.mean(energy_P2))\n","        epi_energy_P3.append(np.mean(energy_P3))\n","\n","        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","        epi_num_task_P1.append(sum(task_done_P1))\n","        epi_num_task_P2.append(sum(task_done_P2))\n","        epi_num_task_P3.append(sum(task_done_P3))\n","\n","        epi_datasize.append(np.mean(datasize))\n","        epi_datasize_P1.append(np.mean(datasize_P1))\n","        epi_datasize_P2.append(np.mean(datasize_P2))\n","        epi_datasize_P3.append(np.mean(datasize_P3))\n","\n","\n","\n","\n","\n","        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n","\n","        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n","            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n","                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n","\n","\n","\n","\n","\n","        if i_episode % window_size == 0:\n","\n","\n","            mean_scores.append(mean_score)\n","            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n","            mean_task.append(np.mean(task_done_ratio_window))\n","            energy_window.append(np.mean(energy))\n","            latency_window.append(np.mean(latency))\n","\n","            mean_energy.append(np.mean(energy_window))\n","            mean_latency.append(np.mean(latency_window))\n","\n","\n","            mean_datasize_window.append(np.mean(datasize))\n","            mean_datasize.append(np.mean(mean_datasize_window))\n","\n","            mean_tasks_P1_window.append(np.mean(task_done_P1))\n","            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n","\n","            mean_tasks_P2_window.append(np.mean(task_done_P2))\n","            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n","\n","            mean_tasks_P3_window.append(np.mean(task_done_P3))\n","            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n","\n","            mean_energy_window_P1.append(np.mean(energy_P1))\n","            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n","\n","            mean_energy_window_P2.append(np.mean(energy_P2))\n","            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n","\n","            mean_energy_window_P3.append(np.mean(energy_P3))\n","            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n","\n","\n","            mean_latency_P1_window.append(np.mean(latency_P1))\n","            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n","\n","            mean_latency_P2_window.append(np.mean(latency_P2))\n","            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n","\n","            mean_latency_P3_window.append(np.mean(latency_P3))\n","            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n","\n","            mean_datasize_P1_window.append(np.mean(datasize_P1))\n","            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n","\n","            mean_datasize_P2_window.append(np.mean(datasize_P2))\n","            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n","\n","            mean_datasize_P3_window.append(np.mean(datasize_P3))\n","            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n","\n","\n","            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","            win_num_task_P1.append(sum(task_done_P1))\n","            win_num_task_P2.append(sum(task_done_P2))\n","            win_num_task_P3.append(sum(task_done_P3))\n","\n","\n","            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n","            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n","                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n","\n","\n","\n","                                                                                                                                                                                                                                                       ))\n","\n","\n","            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n","           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n","            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n","            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n","           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n","           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n","            #print('mean_datasize', mean_datasize[-1])\n","            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n","            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n","\n","            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n","            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n","           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n","\n","\n","            #print(mean_tasks_P1)\n","           # print(epi_task_P1)\n","\n","\n","\n","        if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n","            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n","            torch.save(agent.qnetwork_local.state_dict(), model_path)\n","            break\n","\n","    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n","    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n","                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n","                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n","\n","dqnb_epi_scores,dqnb_epi_task,dqnb_epi_energy,dqnb_epi_latency,dqnb_epi_num_task,dqnb_epi_task_P1,dqnb_epi_task_P2,dqnb_epi_task_P3,dqnb_epi_latency_P1,dqnb_epi_latency_P2,dqnb_epi_latency_P3,\\\n","dqnb_epi_energy_P1,dqnb_epi_energy_P2,dqnb_epi_energy_P3,dqnb_epi_num_task_P1,dqnb_epi_num_task_P2,dqnb_epi_num_task_P3,dqnb_epi_task_select_P1,dqnb_epi_task_select_P2,dqnb_epi_task_select_P3,\\\n","dqnb_mean_scores,dqnb_mean_task,dqnb_mean_energy,dqnb_mean_latency,dqnb_win_num_task, dqnb_mean_tasks_P1,dqnb_mean_tasks_P2,dqnb_mean_tasks_P3,\\\n","dqnb_mean_energy_P1,dqnb_mean_energy_P2,dqnb_mean_energy_P3,dqnb_mean_latency_P1,dqnb_mean_latency_P2,dqnb_mean_latency_P3 ,dqnb_win_num_task_P1, dqnb_win_num_task_P2,dqnb_win_num_task_P3,\\\n","dqnb_epi_datasize,dqnb_epi_datasize_P1,dqnb_epi_datasize_P2,dqnb_epi_datasize_P3,dqnb_mean_datasize,dqnb_mean_datasize_P1,dqnb_mean_datasize_P2,dqnb_mean_datasize_P3 = dqnb()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDA-woQuUyGS"},"outputs":[],"source":["import csv\n","\n","\n","# Combining data into a list of tuples\n","data = zip(range(1, len(dqnb_epi_scores) + 1), dqnb_epi_scores,dqnb_epi_task,dqnb_epi_energy,dqnb_epi_latency,dqnb_epi_num_task,dqnb_epi_task_P1,dqnb_epi_task_P2,\n","           dqnb_epi_task_P3,dqnb_epi_latency_P1,dqnb_epi_latency_P2,dqnb_epi_latency_P3,\n","           dqnb_epi_energy_P1,dqnb_epi_energy_P2,dqnb_epi_energy_P3,dqnb_epi_num_task_P1,dqnb_epi_num_task_P2,dqnb_epi_num_task_P3,\n","           dqnb_epi_datasize,dqnb_epi_datasize_P1,dqnb_epi_datasize_P2,dqnb_epi_datasize_P3,dqnb_epi_task_select_P1,dqnb_epi_task_select_P2,dqnb_epi_task_select_P3)\n","\n","# Writing data to a CSV file\n","with open(\"data_dqnb.csv\", mode=\"w\", newline=\"\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Index\",\"dqnb_epi_scores\",\"dqnb_epi_task\",\"dqnb_epi_energy\",\"dqnb_epi_latency\",\"dqnb_epi_num_task\",\"dqnb_epi_task_P1\",\"dqnb_epi_task_P2\",\"dqnb_epi_task_P3\",\n","                     \"dqnb_epi_latency_P1\",\"dqnb_epi_latency_P2\",\"dqnb_epi_latency_P3\",\"dqnb_epi_energy_P1\",\"dqnb_epi_energy_P2\",\"dqnb_epi_energy_P3\",\"dqnb_epi_num_task_P1\",\n","                     \"dqnb_epi_num_task_P2\",\"dqnb_epi_num_task_P3\",\"dqnb_epi_datasize\",\"dqnb_epi_datasize_P1\",\"dqnb_epi_datasize_P2\"\n","                     \"dqnb_epi_datasize_P3\",\"dqnb_epi_task_select_P1\",\"dqnb_epi_task_select_P2\",\"dqnb_epi_task_select_P3\"])  # Writing header\n","    writer.writerows(data)  # Writing data rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NV5UdDQqNc2o"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQsAqZ2tNdDV"},"outputs":[],"source":["import numpy as np\n","from mec_environment import MECEnvironment\n","from random_agent import RandomAgent\n","\n","mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMFP_jFzT2Dt"},"outputs":[],"source":["action_size = mec_evn.action_size()\n","Task=mec_evn.get_task()\n","states = mec_evn.get_state(Task)\n","state_size = mec_evn.state_size()\n","action_space = mec_evn.actions\n","print('Action size: {}'.format(action_size))\n","print('Action space: {}'.format(action_space))\n","print('Observes a state with length: {}'.format(state_size))\n","print('state size: {}'.format(len(states)))\n","print('The state for the first agent looks like:', states)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUrKDDq1T9gV"},"outputs":[],"source":["epoch_no =2500\n","window_size =250"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIRVmp4ZNdNf"},"outputs":[],"source":["import torch\n","from collections import deque\n","from greedy_agent import GreedyAgent\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2x4kT8pTjQ-"},"outputs":[],"source":["greedy_agent = GreedyAgent(action_size=action_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKGDzVFENdO7"},"outputs":[],"source":["def greedy(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n","    \"\"\"Deep Q-Learning.\n","\n","    Params\n","    ======\n","        n_episodes (int): maximum number of training episodes\n","        max_t (int): maximum number of atimesteps per episode\n","        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n","        eps_end (float): minimum value of epsilon\n","        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n","    \"\"\"\n","    epi_scores = []                        # list containing scores from each episode\n","    epi_task=[]\n","    epi_task_P1=[]\n","    epi_task_P2=[]\n","    epi_task_P3=[]\n","\n","\n","    epi_latency=[]\n","    epi_latency_P1=[]\n","    epi_latency_P2=[]\n","    epi_latency_P3=[]\n","    epi_task_select_P1=[]\n","    epi_task_select_P2=[]\n","    epi_task_select_P3=[]\n","    epi_datasize=[]\n","    epi_datasize_P1=[]\n","    epi_datasize_P2=[]\n","    epi_datasize_P3=[]\n","\n","    epi_energy=[]\n","    epi_energy_P1=[]\n","    epi_energy_P2=[]\n","    epi_energy_P3=[]\n","\n","    epi_num_task=[]\n","    epi_num_task_P1=[]\n","    epi_num_task_P2=[]\n","    epi_num_task_P3=[]\n","\n","    mean_scores = [] # average score by the windos size\n","    mean_task=[] # average task ratio by window size\n","    mean_energy = [] # average energy cost by window size\n","    mean_latency=[]\n","    mean_datasize=[]\n","\n","    mean_tasks_P1=[]\n","    mean_tasks_P2=[]\n","    mean_tasks_P3=[]\n","\n","    mean_energy_P1=[]\n","    mean_energy_P2=[]\n","    mean_energy_P3=[]\n","\n","    mean_latency_P1=[]\n","    mean_latency_P2=[]\n","    mean_latency_P3=[]\n","\n","\n","    mean_datasize_P1=[]\n","    mean_datasize_P2=[]\n","    mean_datasize_P3=[]\n","    reward_list_P1=[]\n","    reward_list_P2=[]\n","    reward_list_P3=[]\n","\n","    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n","    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n","    energy_window = deque(maxlen=window_size)  # last  engery cost\n","    latency_window = deque(maxlen=window_size)  # last  engery cost\n","    datasize_window= deque(maxlen=window_size)\n","\n","\n","    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    win_num_task = deque(maxlen=window_size)\n","    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n","    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_datasize_window=deque(maxlen=window_size)\n","    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n","    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n","    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n","\n","    mean_latency_P1_window=deque(maxlen=window_size)\n","    mean_latency_P2_window=deque(maxlen=window_size)\n","    mean_latency_P3_window=deque(maxlen=window_size)\n","\n","\n","\n","    eps = eps_start                    # initialize epsilon\n","    for i_episode in range(1, n_episodes+1):\n","        mec_evn.reset() # reset the environment\n","\n","        score = 0\n","        energy = []\n","        latency=[]\n","        task_done = []\n","        energy_P1=[]\n","        energy_P2=[]\n","        energy_P3=[]\n","        task_done_P1=[]\n","        task_done_P2=[]\n","        task_done_P3=[]\n","        latency_P1=[]\n","        latency_P2=[]\n","        latency_P3=[]\n","        datasize=[]\n","        datasize_P1=[]\n","        datasize_P2=[]\n","        datasize_P3=[]\n","\n","\n","\n","        tasks = mec_evn.get_task()\n","        for t in range(max_t):\n","\n","            state = mec_evn.get_state(tasks)\n","            max_reward_task,max_reward_server,max_reward_frequency = greedy_agent.action(tasks,mec_evn)\n","            greedy_action=[(max_reward_server,max_reward_frequency)]\n","            #greedy_task=mec_evn.priority_queues[max_reward_task].pop(0)\n","\n","#             print(\"action=\",action)\n","            next_state, feedback,done,action_task = mec_evn.greedy_step(greedy_action,tasks,max_reward_task)\n","\n","\n","\n","\n","            score += feedback['reward']\n","            energy.append(feedback['energy'])\n","            datasize.append(action_task['data_size'])\n","            if feedback['task_done']==1:\n","\n","              latency.append(feedback['latency'])\n","\n","\n","            if action_task['data_size'] != 0:\n","              task_done.append(feedback['task_done'])\n","              if action_task['priority']==1:\n","                  energy_P1.append(feedback['energy'])\n","                  task_done_P1.append(feedback['task_done'])\n","                  datasize_P1.append(action_task['data_size'])\n","                  reward_list_P1.append(feedback['reward'])\n","\n","                  if feedback['task_done']:\n","                    latency_P1.append(feedback['latency'])\n","\n","              if action_task['priority']==2:\n","                  energy_P2.append(feedback['energy'])\n","                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n","                  datasize_P2.append(action_task['data_size'])\n","                  reward_list_P2.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P2.append(feedback['latency'])\n","\n","              if action_task['priority']==3:\n","                  energy_P3.append(feedback['energy'])\n","                  task_done_P3.append(feedback['task_done'])\n","                  datasize_P3.append(action_task['data_size'])\n","                  reward_list_P3.append(feedback['reward'])\n","                  if feedback['task_done']:\n","                    latency_P3.append(feedback['latency'])\n","\n","\n","            tasks = mec_evn.get_task()\n","\n","            if done:\n","                break\n","        scores_window.append(score)       # save most recent score\n","        epi_scores.append(score)              # save most recent score\n","        mean_score = np.mean(scores_window)\n","        epi_task.append(np.mean(task_done))\n","        epi_task_P1.append(np.mean(task_done_P1))\n","        epi_task_P2.append(np.mean(task_done_P2))\n","        epi_task_P3.append(np.mean(task_done_P3))\n","\n","        epi_task_select_P1.append(len(task_done_P1))\n","        epi_task_select_P2.append(len(task_done_P2))\n","        epi_task_select_P3.append(len(task_done_P3))\n","\n","        epi_latency.append(np.mean(latency))\n","        epi_latency_P1.append(np.mean(latency_P1))\n","        epi_latency_P2.append(np.mean(latency_P2))\n","        epi_latency_P3.append(np.mean(latency_P3))\n","\n","        epi_energy.append(np.mean(energy))\n","        epi_energy_P1.append(np.mean(energy_P1))\n","        epi_energy_P2.append(np.mean(energy_P2))\n","        epi_energy_P3.append(np.mean(energy_P3))\n","\n","        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","        epi_num_task_P1.append(sum(task_done_P1))\n","        epi_num_task_P2.append(sum(task_done_P2))\n","        epi_num_task_P3.append(sum(task_done_P3))\n","\n","        epi_datasize.append(np.mean(datasize))\n","        epi_datasize_P1.append(np.mean(datasize_P1))\n","        epi_datasize_P2.append(np.mean(datasize_P2))\n","        epi_datasize_P3.append(np.mean(datasize_P3))\n","\n","\n","\n","\n","\n","        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n","\n","        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n","            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n","                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n","\n","\n","\n","\n","\n","        if i_episode % window_size == 0:\n","\n","\n","            mean_scores.append(mean_score)\n","            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n","            mean_task.append(np.mean(task_done_ratio_window))\n","            energy_window.append(np.mean(energy))\n","            latency_window.append(np.mean(latency))\n","\n","            mean_energy.append(np.mean(energy_window))\n","            mean_latency.append(np.mean(latency_window))\n","\n","\n","            mean_datasize_window.append(np.mean(datasize))\n","            mean_datasize.append(np.mean(mean_datasize_window))\n","\n","            mean_tasks_P1_window.append(np.mean(task_done_P1))\n","            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n","\n","            mean_tasks_P2_window.append(np.mean(task_done_P2))\n","            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n","\n","            mean_tasks_P3_window.append(np.mean(task_done_P3))\n","            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n","\n","            mean_energy_window_P1.append(np.mean(energy_P1))\n","            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n","\n","            mean_energy_window_P2.append(np.mean(energy_P2))\n","            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n","\n","            mean_energy_window_P3.append(np.mean(energy_P3))\n","            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n","\n","\n","            mean_latency_P1_window.append(np.mean(latency_P1))\n","            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n","\n","            mean_latency_P2_window.append(np.mean(latency_P2))\n","            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n","\n","            mean_latency_P3_window.append(np.mean(latency_P3))\n","            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n","\n","            mean_datasize_P1_window.append(np.mean(datasize_P1))\n","            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n","\n","            mean_datasize_P2_window.append(np.mean(datasize_P2))\n","            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n","\n","            mean_datasize_P3_window.append(np.mean(datasize_P3))\n","            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n","\n","\n","            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n","            win_num_task_P1.append(sum(task_done_P1))\n","            win_num_task_P2.append(sum(task_done_P2))\n","            win_num_task_P3.append(sum(task_done_P3))\n","\n","\n","            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n","            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n","            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n","                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n","\n","\n","\n","                                                                                                                                                                                                                                                       ))\n","\n","\n","            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n","           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n","            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n","            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n","           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n","           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n","            #print('mean_datasize', mean_datasize[-1])\n","            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n","            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n","\n","            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n","            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n","           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n","\n","\n","            #print(mean_tasks_P1)\n","           # print(epi_task_P1)\n","\n","\n","\n","\n","\n","    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n","    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n","                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n","                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n","\n","greedy_epi_scores,greedy_epi_task,greedy_epi_energy,greedy_epi_latency,greedy_epi_num_task,greedy_epi_task_P1,greedy_epi_task_P2,greedy_epi_task_P3,greedy_epi_latency_P1,greedy_epi_latency_P2,greedy_epi_latency_P3,\\\n","greedy_epi_energy_P1,greedy_epi_energy_P2,greedy_epi_energy_P3,greedy_epi_num_task_P1,greedy_epi_num_task_P2,greedy_epi_num_task_P3,greedy_epi_task_select_P1,greedy_epi_task_select_P2,greedy_epi_task_select_P3,\\\n","greedy_mean_scores,greedy_mean_task,greedy_mean_energy,greedy_mean_latency,greedy_win_num_task, greedy_mean_tasks_P1,greedy_mean_tasks_P2,greedy_mean_tasks_P3,\\\n","greedy_mean_energy_P1,greedy_mean_energy_P2,greedy_mean_energy_P3,greedy_mean_latency_P1,greedy_mean_latency_P2,greedy_mean_latency_P3 ,greedy_win_num_task_P1, greedy_win_num_task_P2,greedy_win_num_task_P3,\\\n","greedy_epi_datasize,greedy_epi_datasize_P1,greedy_epi_datasize_P2,greedy_epi_datasize_P3,greedy_mean_datasize,greedy_mean_datasize_P1,greedy_mean_datasize_P2,greedy_mean_datasize_P3 = greedy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mc6fuYIU7Tjq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UC3nT7Zt72LN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJ6s19MnrFbK"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mp_DO8LLrFbK"},"outputs":[],"source":["import csv\n","\n","\n","# Combining data into a list of tuples\n","data = zip(range(1, len(greedy_epi_scores) + 1), greedy_epi_scores,greedy_epi_task,greedy_epi_energy,greedy_epi_latency,greedy_epi_num_task,greedy_epi_task_P1,greedy_epi_task_P2,\n","           greedy_epi_task_P3,greedy_epi_latency_P1,greedy_epi_latency_P2,greedy_epi_latency_P3,\n","           greedy_epi_energy_P1,greedy_epi_energy_P2,greedy_epi_energy_P3,greedy_epi_num_task_P1,greedy_epi_num_task_P2,greedy_epi_num_task_P3,\n","           greedy_epi_datasize,greedy_epi_datasize_P1,greedy_epi_datasize_P2,greedy_epi_datasize_P3,greedy_epi_task_select_P1,greedy_epi_task_select_P2,greedy_epi_task_select_P3)\n","\n","# Writing data to a CSV file\n","with open(\"data_greedy.csv\", mode=\"w\", newline=\"\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Index\",\"greedy_epi_scores\",\"greedy_epi_task\",\"greedy_epi_energy\",\"greedy_epi_latency\",\"greedy_epi_num_task\",\"greedy_epi_task_P1\",\"greedy_epi_task_P2\",\"greedy_epi_task_P3\",\n","                     \"greedy_epi_latency_P1\",\"greedy_epi_latency_P2\",\"greedy_epi_latency_P3\",\"greedy_epi_energy_P1\",\"greedy_epi_energy_P2\",\"greedy_epi_energy_P3\",\"greedy_epi_num_task_P1\",\n","                     \"greedy_epi_num_task_P2\",\"greedy_epi_num_task_P3\",\"greedy_epi_datasize\",\"greedy_epi_datasize_P1\",\"greedy_epi_datasize_P2\"\n","                     \"greedy_epi_datasize_P3\",\"greedy_epi_task_select_P1\",\"greedy_epi_task_select_P2\",\"greedy_epi_task_select_P3\"])  # Writing header\n","    writer.writerows(data)  # Writing data rows\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPOR-vhHGnKp"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0IPp62mG4OL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBbu3Rgm1yrC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}