{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_2c3s5mPjSr"
   },
   "source": [
    "+++++[link text](https:// [link text](https://))### 1. Read environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32923,
     "status": "ok",
     "timestamp": 1705362321730,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "jc1n8GcSNWxH",
    "outputId": "abef88a4-81ad-407a-e969-720aa69ed4ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1705362321766,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "4v2mf8TUrIW6",
    "outputId": "edd8159b-c99d-48b5-bcfc-37a584fe662b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\Lenovo\\Documents\\Customize_MEC_ENV\\Distance_Result\\Dis_Test_25_75_test_test_dif_dis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pw1W2pj5R-9H"
   },
   "outputs": [],
   "source": [
    "# ! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1705362324095,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "yDgZsDSYPjSu",
    "outputId": "33fb275d-ff33-4095-d717-846af1fc4bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "{}\n",
      "23\n",
      "18\n",
      "1\n",
      "{'data_size': 38801, 'circle': 143466, 'user_index': 35, 'priority': 1, 'user_distance': [64.51988684772745, 26.736897684165697, 47.61205306121062], 'delta_max': 0.081}\n",
      "{'data_size': 3582, 'circle': 87503, 'user_index': 31, 'priority': 2, 'user_distance': [49.25873999286083, 26.117150298198137, 62.75179370912895], 'delta_max': 0.073}\n",
      "{'data_size': 3790, 'circle': 73893, 'user_index': 34, 'priority': 3, 'user_distance': [25.531431008958336, 60.58103767720908, 108.11230403025205], 'delta_max': 0.06}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALZLc1DEPjSw"
   },
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1705362324096,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "tLC_64NIPjSx",
    "outputId": "449b79d3-3ec3-41eb-e40f-0841df76c732",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35: {'speed': array([ 962558.3349199 , 3595027.34167259,   40207.7176604 ])}, 31: {'speed': array([629422.91810081,  55571.28926657,  83446.81248087])}, 34: {'speed': array([8.23185023e+06, 7.39082850e+03, 2.42303687e+04])}}\n",
      "Action size: 45\n",
      "Action space: [(0, 0.1, 0), (0, 0.1, 1), (0, 0.1, 2), (0, 0.325, 0), (0, 0.325, 1), (0, 0.325, 2), (0, 0.55, 0), (0, 0.55, 1), (0, 0.55, 2), (0, 0.775, 0), (0, 0.775, 1), (0, 0.775, 2), (0, 1.0, 0), (0, 1.0, 1), (0, 1.0, 2), (1, 0.1, 0), (1, 0.1, 1), (1, 0.1, 2), (1, 0.325, 0), (1, 0.325, 1), (1, 0.325, 2), (1, 0.55, 0), (1, 0.55, 1), (1, 0.55, 2), (1, 0.775, 0), (1, 0.775, 1), (1, 0.775, 2), (1, 1.0, 0), (1, 1.0, 1), (1, 1.0, 2), (2, 0.1, 0), (2, 0.1, 1), (2, 0.1, 2), (2, 0.325, 0), (2, 0.325, 1), (2, 0.325, 2), (2, 0.55, 0), (2, 0.55, 1), (2, 0.55, 2), (2, 0.775, 0), (2, 0.775, 1), (2, 0.775, 2), (2, 1.0, 0), (2, 1.0, 1), (2, 1.0, 2)]\n",
      "Observes a state with length: 30\n",
      "state size: 30\n",
      "The state for the first agent looks like: [1.06282153e-01 6.94985646e-02 9.08930639e-01 3.96949703e-01\n",
      " 6.13597746e-03 8.16068112e-04 4.43958837e-03 9.21389026e-03\n",
      " 2.67542823e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 4.00000000e+00 1.60000000e+01 1.60000000e+01 3.88010000e-01\n",
      " 1.43466000e+00 8.10000000e-02 1.00000000e+00 3.60000000e+01\n",
      " 3.58200000e-02 8.75030000e-01 7.30000000e-02 2.00000000e+00\n",
      " 3.20000000e+01 3.79000000e-02 7.38930000e-01 6.00000000e-02\n",
      " 3.00000000e+00 3.50000000e+01]\n"
     ]
    }
   ],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "\n",
    "task=mec_evn.get_task()\n",
    "\n",
    "states = mec_evn.get_state(task)\n",
    "print(mec_evn.trans_speed_matrix)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vapCU_9PjSy"
   },
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF7ASsRcPjSz"
   },
   "source": [
    "### 6. Take Actions with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dq2lQI0LPjSz"
   },
   "outputs": [],
   "source": [
    "epoch_no =2500\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OmtnPud5PjS0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from greedy_agent import GreedyAgent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PSLBUj5oPjS1"
   },
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n",
    "model_path = os.path.join(current_directory, 'model_dqnp_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_ranges = [(25,45), (45, 65), (65, 85), (85,105), (105, 128)]\n",
    "\n",
    "# Function to determine the bucket for a given value\n",
    "def find_bucket(value, ranges):\n",
    "    for start, end in ranges:\n",
    "        if start <= value <= end:\n",
    "            return (start, end)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3\tAverage Score: 211.9867\tmeantaskP1: 0.4776\tmeantaskP2: 0.4937\tmeantaskP3: 0.5000\tmeanenergyP1:             0.1685\tmeanenergyP2: 0.1988\tmeanenergyP3: 0.2118\tmeanlatencyP1: 0.0227\tmeanlatencyP2: 0.0228\tmeanlatencyP3:0.0203"
     ]
    }
   ],
   "source": [
    "def dqnp(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "\n",
    "\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    bucket_tasks_mean = {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_task_len= {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_latency_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_data_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    #bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        \n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        for t in range(max_t):\n",
    "\n",
    "            state = mec_evn.get_state(tasks)\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, feedback,done,action_task,next_task,rec_mec_idx = mec_evn.step(action,tasks)\n",
    "            agent.step(state, action, feedback['reward'], next_state, done)\n",
    "\n",
    "            score += feedback['reward']\n",
    "            energy.append(feedback['energy'])\n",
    "            datasize.append(action_task['data_size'])\n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            if feedback['task_done']==1:\n",
    "\n",
    "              latency.append(feedback['latency'])\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 and user_distance!=1000 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              if action_task['priority']==1:\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P1.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P1_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n",
    "                 \n",
    "                  reward_list_P2.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P2_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P3.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P3_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            tasks=next_task\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n",
    "                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n",
    "            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n",
    "                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n",
    "\n",
    "\n",
    "\n",
    "                                                                                                                                                                                                                                                       ))\n",
    "\n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P3_latency_mean'][-window_size:]))\n",
    "            \n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), model_path)\n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n",
    "\n",
    "dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\\\n",
    "dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,dqnp_epi_task_select_P3,\\\n",
    "dqnp_mean_scores,dqnp_mean_task,dqnp_mean_energy,dqnp_mean_latency,dqnp_win_num_task, dqnp_mean_tasks_P1,dqnp_mean_tasks_P2,dqnp_mean_tasks_P3,\\\n",
    "dqnp_mean_energy_P1,dqnp_mean_energy_P2,dqnp_mean_energy_P3,dqnp_mean_latency_P1,dqnp_mean_latency_P2,dqnp_mean_latency_P3 ,dqnp_win_num_task_P1, dqnp_win_num_task_P2,dqnp_win_num_task_P3,\\\n",
    "dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_mean_datasize,dqnp_mean_datasize_P1,dqnp_mean_datasize_P2,dqnp_mean_datasize_P3 = dqnp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FCat57h05aF",
    "outputId": "e2e04adf-c8c5-4584-9eab-e336c976d89c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53xoR59lZevt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNcbaKBSXB1O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv4vHu2WdTeh"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(dqnp_epi_scores) + 1), dqnp_epi_scores,dqnp_epi_task,dqnp_epi_energy,dqnp_epi_latency,dqnp_epi_num_task,dqnp_epi_task_P1,dqnp_epi_task_P2,\n",
    "           dqnp_epi_task_P3,dqnp_epi_latency_P1,dqnp_epi_latency_P2,dqnp_epi_latency_P3,\n",
    "           dqnp_epi_energy_P1,dqnp_epi_energy_P2,dqnp_epi_energy_P3,dqnp_epi_num_task_P1,dqnp_epi_num_task_P2,dqnp_epi_num_task_P3,\n",
    "           dqnp_epi_datasize,dqnp_epi_datasize_P1,dqnp_epi_datasize_P2,dqnp_epi_datasize_P3,dqnp_epi_task_select_P1,dqnp_epi_task_select_P2,dqnp_epi_task_select_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_dqnp.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"dqnp_epi_scores\",\"dqnp_epi_task\",\"dqnp_epi_energy\",\"dqnp_epi_latency\",\"dqnp_epi_num_task\",\"dqnp_epi_task_P1\",\"dqnp_epi_task_P2\",\"dqnp_epi_task_P3\",\n",
    "                     \"dqnp_epi_latency_P1\",\"dqnp_epi_latency_P2\",\"dqnp_epi_latency_P3\",\"dqnp_epi_energy_P1\",\"dqnp_epi_energy_P2\",\"dqnp_epi_energy_P3\",\"dqnp_epi_num_task_P1\",\n",
    "                     \"dqnp_epi_num_task_P2\",\"dqnp_epi_num_task_P3\",\"dqnp_epi_datasize\",\"dqnp_epi_datasize_P1\",\"dqnp_epi_datasize_P2\"\n",
    "                     \"dqnp_epi_datasize_P3\",\"dqnp_epi_task_select_P1\",\"dqnp_epi_task_select_P2\",\"dqnp_epi_task_select_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8dj2oNedTej"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyrrgUOrP78d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE4R2jl-P78e"
   },
   "outputs": [],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "Task=mec_evn.get_task()\n",
    "states = mec_evn.get_state(Task)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBtx8tG1MEGO"
   },
   "outputs": [],
   "source": [
    "epoch_no =2500\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRB1DlbNP78e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from greedy_agent import GreedyAgent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHi0hSOaP78f"
   },
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n",
    "model_path = os.path.join(current_directory, 'model_dqnb_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7k4M5QjPjS1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dqnb(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "\n",
    "\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    bucket_tasks_mean = {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_task_len= {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_latency_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_data_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    #bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        \n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        for t in range(max_t):\n",
    "\n",
    "            state = mec_evn.get_state(tasks)\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, feedback,done,action_task,next_task,rec_mec_idx = mec_evn.step(action,tasks)\n",
    "            agent.step(state, action, feedback['reward'], next_state, done)\n",
    "\n",
    "            score += feedback['reward']\n",
    "            energy.append(feedback['energy'])\n",
    "            datasize.append(action_task['data_size'])\n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            if feedback['task_done']==1:\n",
    "\n",
    "              latency.append(feedback['latency'])\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 and user_distance!=1000 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              if action_task['priority']==1:\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P1.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P1_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n",
    "                 \n",
    "                  reward_list_P2.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P2_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P3.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P3_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            tasks=next_task\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n",
    "                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n",
    "            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n",
    "                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n",
    "\n",
    "\n",
    "\n",
    "                                                                                                                                                                                                                                                       ))\n",
    "\n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P3_latency_mean'][-window_size:]))\n",
    "            \n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), model_path)\n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n",
    "\n",
    "dqnb_epi_scores,dqnb_epi_task,dqnb_epi_energy,dqnb_epi_latency,dqnb_epi_num_task,dqnb_epi_task_P1,dqnb_epi_task_P2,dqnb_epi_task_P3,dqnb_epi_latency_P1,dqnb_epi_latency_P2,dqnb_epi_latency_P3,\\\n",
    "dqnb_epi_energy_P1,dqnb_epi_energy_P2,dqnb_epi_energy_P3,dqnb_epi_num_task_P1,dqnb_epi_num_task_P2,dqnb_epi_num_task_P3,dqnb_epi_task_select_P1,dqnb_epi_task_select_P2,dqnb_epi_task_select_P3,\\\n",
    "dqnb_mean_scores,dqnb_mean_task,dqnb_mean_energy,dqnb_mean_latency,dqnb_win_num_task, dqnb_mean_tasks_P1,dqnb_mean_tasks_P2,dqnb_mean_tasks_P3,\\\n",
    "dqnb_mean_energy_P1,dqnb_mean_energy_P2,dqnb_mean_energy_P3,dqnb_mean_latency_P1,dqnb_mean_latency_P2,dqnb_mean_latency_P3 ,dqnb_win_num_task_P1, dqnb_win_num_task_P2,dqnb_win_num_task_P3,\\\n",
    "dqnb_epi_datasize,dqnb_epi_datasize_P1,dqnb_epi_datasize_P2,dqnb_epi_datasize_P3,dqnb_mean_datasize,dqnb_mean_datasize_P1,dqnb_mean_datasize_P2,dqnb_mean_datasize_P3 = dqnb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(dqnb_epi_scores) + 1), dqnb_epi_scores,dqnb_epi_task,dqnb_epi_energy,dqnb_epi_latency,dqnb_epi_num_task,dqnb_epi_task_P1,dqnb_epi_task_P2,\n",
    "           dqnb_epi_task_P3,dqnb_epi_latency_P1,dqnb_epi_latency_P2,dqnb_epi_latency_P3,\n",
    "           dqnb_epi_energy_P1,dqnb_epi_energy_P2,dqnb_epi_energy_P3,dqnb_epi_num_task_P1,dqnb_epi_num_task_P2,dqnb_epi_num_task_P3,\n",
    "           dqnb_epi_datasize,dqnb_epi_datasize_P1,dqnb_epi_datasize_P2,dqnb_epi_datasize_P3,dqnb_epi_task_select_P1,dqnb_epi_task_select_P2,dqnb_epi_task_select_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_dqnb.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"dqnb_epi_scores\",\"dqnb_epi_task\",\"dqnb_epi_energy\",\"dqnb_epi_latency\",\"dqnb_epi_num_task\",\"dqnb_epi_task_P1\",\"dqnb_epi_task_P2\",\"dqnb_epi_task_P3\",\n",
    "                     \"dqnb_epi_latency_P1\",\"dqnb_epi_latency_P2\",\"dqnb_epi_latency_P3\",\"dqnb_epi_energy_P1\",\"dqnb_epi_energy_P2\",\"dqnb_epi_energy_P3\",\"dqnb_epi_num_task_P1\",\n",
    "                     \"dqnb_epi_num_task_P2\",\"dqnb_epi_num_task_P3\",\"dqnb_epi_datasize\",\"dqnb_epi_datasize_P1\",\"dqnb_epi_datasize_P2\"\n",
    "                     \"dqnb_epi_datasize_P3\",\"dqnb_epi_task_select_P1\",\"dqnb_epi_task_select_P2\",\"dqnb_epi_task_select_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV5UdDQqNc2o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQsAqZ2tNdDV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMFP_jFzT2Dt"
   },
   "outputs": [],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "Task=mec_evn.get_task()\n",
    "states = mec_evn.get_state(Task)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUrKDDq1T9gV"
   },
   "outputs": [],
   "source": [
    "epoch_no =2500\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIRVmp4ZNdNf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from greedy_agent import GreedyAgent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2x4kT8pTjQ-"
   },
   "outputs": [],
   "source": [
    "greedy_agent = GreedyAgent(action_size=action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "\n",
    "\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    bucket_tasks_mean = {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_task_len= {(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_latency_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    bucket_data_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    #bucket_energy_mean={(25,45):{},(45,65):{},(65,85):{},(85,105):{},(105,128):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        \n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        for t in range(max_t):\n",
    "\n",
    "            state = mec_evn.get_state(tasks)\n",
    "            max_reward_task,max_reward_server,max_reward_frequency = greedy_agent.action(tasks,mec_evn)\n",
    "            greedy_action=[(max_reward_server,max_reward_frequency)]\n",
    "            #greedy_task=mec_evn.priority_queues[max_reward_task].pop(0)\n",
    "\n",
    "#             print(\"action=\",action)\n",
    "            next_state, feedback,done,action_task = mec_evn.greedy_step(greedy_action,tasks,max_reward_task)\n",
    "            \n",
    "            score += feedback['reward']\n",
    "            energy.append(feedback['energy'])\n",
    "            datasize.append(action_task['data_size'])\n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            if feedback['task_done']==1:\n",
    "\n",
    "              latency.append(feedback['latency'])\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 and user_distance!=1000 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              if action_task['priority']==1:\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P1.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P1_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n",
    "                 \n",
    "                  reward_list_P2.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P2_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  \n",
    "                  reward_list_P3.append(feedback['reward'])\n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P3_latency'].append(feedback['latency'])\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            tasks = mec_evn.get_task()\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(energy_P1), np.mean(energy_P2), np.mean(energy_P3), \\\n",
    "                                    np.mean(latency_P1), np.mean(latency_P2), np.mean(latency_P3)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "            {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f}' .format(i_episode, mean_score,\\\n",
    "            mean_tasks_P1[-1],mean_tasks_P2[-1],mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1],mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], \\\n",
    "                                                                                                                          mean_datasize_P2[-1],mean_datasize_P3[-1]\n",
    "\n",
    "\n",
    "\n",
    "                                                                                                                                                                                                                                                       ))\n",
    "\n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(25,45)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(45,65)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(65,85)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(85,105)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(105,128)]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(25,45)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(45,65)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(65,85)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(85,105)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(105,128)]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(25,45)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(45,65)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(65,85)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(85,105)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(105,128)]['P3_latency_mean'][-window_size:]))\n",
    "            \n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(25,45)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(45,65)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(65,85)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(85,105)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(105,128)]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(25,45)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(45,65)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(65,85)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(85,105)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(105,128)]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                \n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3\n",
    "\n",
    "greedy_epi_scores,greedy_epi_task,greedy_epi_energy,greedy_epi_latency,greedy_epi_num_task,greedy_epi_task_P1,greedy_epi_task_P2,greedy_epi_task_P3,greedy_epi_latency_P1,greedy_epi_latency_P2,greedy_epi_latency_P3,\\\n",
    "greedy_epi_energy_P1,greedy_epi_energy_P2,greedy_epi_energy_P3,greedy_epi_num_task_P1,greedy_epi_num_task_P2,greedy_epi_num_task_P3,greedy_epi_task_select_P1,greedy_epi_task_select_P2,greedy_epi_task_select_P3,\\\n",
    "greedy_mean_scores,greedy_mean_task,greedy_mean_energy,greedy_mean_latency,greedy_win_num_task, greedy_mean_tasks_P1,greedy_mean_tasks_P2,greedy_mean_tasks_P3,\\\n",
    "greedy_mean_energy_P1,greedy_mean_energy_P2,greedy_mean_energy_P3,greedy_mean_latency_P1,greedy_mean_latency_P2,greedy_mean_latency_P3 ,greedy_win_num_task_P1, greedy_win_num_task_P2,greedy_win_num_task_P3,\\\n",
    "greedy_epi_datasize,greedy_epi_datasize_P1,greedy_epi_datasize_P2,greedy_epi_datasize_P3,greedy_mean_datasize,greedy_mean_datasize_P1,greedy_mean_datasize_P2,greedy_mean_datasize_P3 = greedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp_DO8LLrFbK"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(greedy_epi_scores) + 1), greedy_epi_scores,greedy_epi_task,greedy_epi_energy,greedy_epi_latency,greedy_epi_num_task,greedy_epi_task_P1,greedy_epi_task_P2,\n",
    "           greedy_epi_task_P3,greedy_epi_latency_P1,greedy_epi_latency_P2,greedy_epi_latency_P3,\n",
    "           greedy_epi_energy_P1,greedy_epi_energy_P2,greedy_epi_energy_P3,greedy_epi_num_task_P1,greedy_epi_num_task_P2,greedy_epi_num_task_P3,\n",
    "           greedy_epi_datasize,greedy_epi_datasize_P1,greedy_epi_datasize_P2,greedy_epi_datasize_P3,greedy_epi_task_select_P1,greedy_epi_task_select_P2,greedy_epi_task_select_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_greedy.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"greedy_epi_scores\",\"greedy_epi_task\",\"greedy_epi_energy\",\"greedy_epi_latency\",\"greedy_epi_num_task\",\"greedy_epi_task_P1\",\"greedy_epi_task_P2\",\"greedy_epi_task_P3\",\n",
    "                     \"greedy_epi_latency_P1\",\"greedy_epi_latency_P2\",\"greedy_epi_latency_P3\",\"greedy_epi_energy_P1\",\"greedy_epi_energy_P2\",\"greedy_epi_energy_P3\",\"greedy_epi_num_task_P1\",\n",
    "                     \"greedy_epi_num_task_P2\",\"greedy_epi_num_task_P3\",\"greedy_epi_datasize\",\"greedy_epi_datasize_P1\",\"greedy_epi_datasize_P2\"\n",
    "                     \"greedy_epi_datasize_P3\",\"greedy_epi_task_select_P1\",\"greedy_epi_task_select_P2\",\"greedy_epi_task_select_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPOR-vhHGnKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0IPp62mG4OL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBbu3Rgm1yrC"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
