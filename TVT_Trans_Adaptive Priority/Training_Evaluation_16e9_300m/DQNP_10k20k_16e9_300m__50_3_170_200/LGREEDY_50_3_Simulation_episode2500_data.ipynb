{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_2c3s5mPjSr"
   },
   "source": [
    "+++++[link text](https:// [link text](https://))### 1. Read environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32923,
     "status": "ok",
     "timestamp": 1705362321730,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "jc1n8GcSNWxH",
    "outputId": "abef88a4-81ad-407a-e969-720aa69ed4ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1705362321766,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "4v2mf8TUrIW6",
    "outputId": "edd8159b-c99d-48b5-bcfc-37a584fe662b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\uddin81\\Documents\\Customize_RL_MEC Env\\Test for Journal\\Final Result\\backup\\Test_1_V8_1_10k20k_16e9_300m__50_3_170_200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pw1W2pj5R-9H"
   },
   "outputs": [],
   "source": [
    "# ! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1705362324095,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "yDgZsDSYPjSu",
    "outputId": "33fb275d-ff33-4095-d717-846af1fc4bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "{}\n",
      "112\n",
      "72\n",
      "18\n",
      "{'data_size': 12632, 'circle': 8422720, 'user_index': 48, 'priority': 1, 'user_distance': [71.09688711738363, 229.82754910940886, 529.7042923193028], 'delta_max': 0.2}\n",
      "{'data_size': 18248, 'circle': 8506222, 'user_index': 49, 'priority': 2, 'user_distance': [487.1432239034105, 187.30770478916358, 113.40119907549713], 'delta_max': 0.183}\n",
      "{'data_size': 14712, 'circle': 8744696, 'user_index': 38, 'priority': 3, 'user_distance': [334.1468718191083, 35.43740743746833, 266.19069808181257], 'delta_max': 0.176}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mec_environment import MECEnvironment\n",
    "from random_agent import RandomAgent\n",
    "\n",
    "mec_evn = MECEnvironment(user_cnt=50, mec_cnt=3,Env_Type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALZLc1DEPjSw"
   },
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1705362324096,
     "user": {
      "displayName": "Ashab Uddin",
      "userId": "01269056925752111948"
     },
     "user_tz": 300
    },
    "id": "tLC_64NIPjSx",
    "outputId": "449b79d3-3ec3-41eb-e40f-0841df76c732",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{48: {'speed': array([124426.98979871,  11880.63016759,    319.76603408])}, 49: {'speed': array([ 2769.01331504, 33368.62254256, 11033.4456205 ])}, 38: {'speed': array([   7818.7462443 , 1227939.48311405,   21471.30896939])}}\n",
      "Action size: 15\n",
      "Action space: [(0, 0.1), (0, 0.325), (0, 0.55), (0, 0.775), (0, 1.0), (1, 0.1), (1, 0.325), (1, 0.55), (1, 0.775), (1, 1.0), (2, 0.1), (2, 0.325), (2, 0.55), (2, 0.775), (2, 1.0)]\n",
      "Observes a state with length: 27\n",
      "state size: 27\n",
      "The state for the first agent looks like: [1.00750641e-01 2.24211698e-03 6.33097127e-03 9.61994749e-03\n",
      " 2.70191389e-02 9.94283399e-01 2.58919974e-04 8.93396781e-03\n",
      " 1.73856826e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.00000000e-01 1.00000000e+00 2.50000000e-01 6.31600000e-01\n",
      " 8.42272000e-01 1.00000000e+00 3.33333333e-01 9.12400000e-01\n",
      " 8.50622200e-01 9.15000000e-01 6.66666667e-01 7.35600000e-01\n",
      " 8.74469600e-01 8.80000000e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "action_size = mec_evn.action_size()\n",
    "\n",
    "task=mec_evn.get_task()\n",
    "\n",
    "states = mec_evn.get_state(task)\n",
    "print(mec_evn.trans_speed_matrix)\n",
    "state_size = mec_evn.state_size()\n",
    "action_space = mec_evn.actions\n",
    "print('Action size: {}'.format(action_size))\n",
    "print('Action space: {}'.format(action_space))\n",
    "print('Observes a state with length: {}'.format(state_size))\n",
    "print('state size: {}'.format(len(states)))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vapCU_9PjSy"
   },
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF7ASsRcPjSz"
   },
   "source": [
    "### 6. Take Actions with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dq2lQI0LPjSz"
   },
   "outputs": [],
   "source": [
    "epoch_no =3000\n",
    "window_size =250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OmtnPud5PjS0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from latency_greedy_agent import GreedyAgent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PSLBUj5oPjS1"
   },
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,seed=0)\n",
    "model_path = os.path.join(current_directory, 'model_greedy_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 37.58324094593227), (37.58324094593227, 75.16648189186454), (75.16648189186454, 112.74972283779681), (112.74972283779681, 150.33296378372907), (150.33296378372907, inf)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "Mec_2_Mec=300\n",
    "Range=Mec_2_Mec/2\n",
    "max_dis=math.sqrt(10*10+Range*Range)\n",
    "\n",
    "\n",
    "\n",
    "bucket_ranges = [(10, 0.25*max_dis) ,(0.25*max_dis,0.5*max_dis),(0.5*max_dis,0.75*max_dis),(0.75*max_dis,1*max_dis),(1*max_dis,float('inf'))]\n",
    "\n",
    "print(bucket_ranges)\n",
    "# Function to determine the bucket for a given value\n",
    "def find_bucket(value, ranges):\n",
    "    for start, end in ranges:\n",
    "        if start <= value <= end:\n",
    "            return (start, end)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgreedy_agent = GreedyAgent(action_size=action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250\tAverage Score: -866.9139\tmeantaskP1: 0.8556\tmeantaskP2: 0.8647\tmeantaskP3: 0.9062\tmeanenergyP1:                     11.3975\tmeanenergyP2: 9.2540\tmeanenergyP3: 10.3715 \tmeanlatencyP1: 0.0802 \tmeanlatencyP2: 0.0732 \tmeanlatencyP3:                     0.0716 \tmeandatasize: 14811.4145 \tmeandatasizeP1: 14982.9416 \tmeandatasizeP2: 14858.0374 \tmeandatasizeP3: 14719.1793 \tmean_tran_latencyP1: 0.0509                      \tmean_tran_latencyP2: 0.0430  \tmean_tran_latencyP3: 0.0463  \tmean_comp_latencyP1: 0.0292                      \tmean_comp_latencyP2: 0.0301 \tmean_comp_latencyP3: 0.0253\n",
      "mean_task_till_this_window 0.663768 T1:: 0.6141093307730646 T2:: 0.6565361830884117 T3:: 0.6955243252508517\n",
      "task_select_P1 249.656 task_select_P2 315.348 task_select_P3 434.996\n",
      "total_task_done_P1:: 143.616 total_task_done_P2:: 205.172 total_task_done_P3:: 314.98\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.7763275978779908 0.7254062483032889 0.5922012979058566 0.40711005368768527 0.24241134707505382\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.7862563995699564 0.7452830871415331 0.6418187198925588 0.4946263091653617 0.40258807707811983\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.7962250121906507 0.7627020736850657 0.6859396248395927 0.5732591142551521 0.5179995487410962\n",
      "mean_task_P1_select_by_bucket_51_10_100 60.888 63.884 60.54 50.492 13.852\n",
      "mean_task_P2_select_by_bucket_51_10_100 75.072 79.064 77.292 63.196 20.724\n",
      "mean_task_P3_select_by_bucket_51_10_100 102.376 109.448 104.144 86.048 32.98\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.002935352118257731 0.02655472841149067 0.06750698569453562 0.10575578097573168 0.12175589424848522\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.003238557865780983 0.02554643077663319 0.065575190903155 0.10175227634385045 0.09182304187483789\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0034033189356350822 0.025364849567267384 0.06359981391797104 0.09673607983950051 0.0768869454454413\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.898518677857768 7.845534537744199 7.9639237162934515 8.542500153301237 10.710608886829851\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.8489784548646 7.844738094890186 8.0570181736073 8.513335123090497 10.329452494590905\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.874225967540385 7.86585264308724 8.070760388996675 8.62386906455284 9.91566123694199\n",
      "mean_data_P1_data_by_bucket_51_10_100 15013.86707155152 14986.816036915681 14862.308957629495 14552.923828832034 12543.316569841269\n",
      "mean_data_P2_data_by_bucket_51_10_100 14978.631728793052 14988.10949122806 14949.46185737197 14808.109906941127 14488.165517765894\n",
      "mean_data_P3_data_by_bucket_51_10_100 15016.235567300115 15005.455539003166 14909.826706894815 14804.701945646775 14897.894435408178\n",
      "all_tran 0.07763641718363308 all_comp 0.1029099436317365\n",
      "all_tran_P1 0.08698647325451497 all_tran_P2 0.0803115733601364 all_tran_P3 0.07167312466928419\n",
      "all_comp_P1 0.11146578346842378 all_comp_P2 0.10400553149631551 all_comp_P3 0.09580342757032446\n",
      "all_data_P1 14993.565467650835 all_data_P2 15012.800330875933 all_data_P3 15005.033128164157\n",
      "epi_comp_energy 8.19136724353568\n",
      "epi_comp_freq 7772600000.0\n",
      "epi_comp_latency 0.1029099436317365\n",
      "Episode 500\tAverage Score: -857.0642\tmeantaskP1: 0.8568\tmeantaskP2: 0.8638\tmeantaskP3: 0.9197\tmeanenergyP1:                     10.7551\tmeanenergyP2: 9.7337\tmeanenergyP3: 10.5049 \tmeanlatencyP1: 0.0783 \tmeanlatencyP2: 0.0707 \tmeanlatencyP3:                     0.0695 \tmeandatasize: 14933.4514 \tmeandatasizeP1: 15120.1132 \tmeandatasizeP2: 15076.7569 \tmeandatasizeP3: 14803.7860 \tmean_tran_latencyP1: 0.0505                      \tmean_tran_latencyP2: 0.0450  \tmean_tran_latencyP3: 0.0455  \tmean_comp_latencyP1: 0.0278                      \tmean_comp_latencyP2: 0.0257 \tmean_comp_latencyP3: 0.0239\n",
      "mean_task_till_this_window 0.671776 T1:: 0.6165784962830569 T2:: 0.6657836613123311 T3:: 0.7057405292164615\n",
      "task_select_P1 244.068 task_select_P2 319.908 task_select_P3 436.024\n",
      "total_task_done_P1:: 139.688 total_task_done_P2:: 210.476 total_task_done_P3:: 321.612\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.7785769164047698 0.7302003953482292 0.5960185513146719 0.4052626700770438 0.23093489798324057\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.7870453091184075 0.7504366900240832 0.6537657438706406 0.5114475386417892 0.41788056472034063\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8024553370823478 0.7717173084584943 0.6999843746852471 0.5821895820245712 0.534787774948956\n",
      "mean_task_P1_select_by_bucket_51_10_100 59.044 62.5 60.164 48.724 13.636\n",
      "mean_task_P2_select_by_bucket_51_10_100 75.868 81.0 78.092 64.296 20.652\n",
      "mean_task_P3_select_by_bucket_51_10_100 103.588 108.584 103.708 87.24 32.904\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.00301676875337037 0.026191226008371763 0.06720070779508135 0.10540713311440124 0.11773044629211298\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0032374708439656583 0.025497500059550444 0.06530586973105722 0.1019292104295252 0.08758196860574377\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0034434009255872224 0.025283898358043906 0.06408264402605846 0.0969843250246752 0.07778641790210712\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.532897430374858 7.612577598888742 7.673214746133519 8.220567184700368 9.907900675200379\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.576042957546772 7.558089011645335 7.756774768801361 8.192105709103492 9.831261591543276\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.631937970866793 7.655397886549394 7.924746582592484 8.252300382855761 9.457544517545063\n",
      "mean_data_P1_data_by_bucket_51_10_100 15033.188014784735 14961.617219158523 14853.332661178618 14643.251122367245 12256.202565800866\n",
      "mean_data_P2_data_by_bucket_51_10_100 14986.536217255947 14976.719093208656 14911.833797041145 14755.286390072002 14351.877425147984\n",
      "mean_data_P3_data_by_bucket_51_10_100 15009.450391906033 14967.722853929949 14928.069647163407 14770.668200755983 14908.30975569448\n",
      "all_tran 0.07682794077100266 all_comp 0.09983341466940425\n",
      "all_tran_P1 0.08714534046566176 all_tran_P2 0.07831038964581305 all_tran_P3 0.07109513934613404\n",
      "all_comp_P1 0.10914610264485418 all_comp_P2 0.10084833772462354 all_comp_P3 0.09208886152457897\n",
      "all_data_P1 14987.902670956248 all_data_P2 14997.670435379849 all_data_P3 14998.278436286795\n",
      "epi_comp_energy 7.91463900639632\n",
      "epi_comp_freq 7668504000.0\n",
      "epi_comp_latency 0.09983341466940425\n",
      "Episode 750\tAverage Score: -858.6483\tmeantaskP1: 0.7691\tmeantaskP2: 0.7900\tmeantaskP3: 0.8329\tmeanenergyP1:                     10.4198\tmeanenergyP2: 9.8097\tmeanenergyP3: 10.5527 \tmeanlatencyP1: 0.0754 \tmeanlatencyP2: 0.0677 \tmeanlatencyP3:                     0.0675 \tmeandatasize: 14962.5450 \tmeandatasizeP1: 15052.2333 \tmeandatasizeP2: 15051.7411 \tmeandatasizeP3: 14903.8024 \tmean_tran_latencyP1: 0.0494                      \tmean_tran_latencyP2: 0.0430  \tmean_tran_latencyP3: 0.0459  \tmean_comp_latencyP1: 0.0260                      \tmean_comp_latencyP2: 0.0247 \tmean_comp_latencyP3: 0.0216\n",
      "mean_task_till_this_window 0.67102 T1:: 0.6231238501301627 T2:: 0.6634008722772303 T3:: 0.7033977182620124\n",
      "task_select_P1 249.168 task_select_P2 320.124 task_select_P3 430.708\n",
      "total_task_done_P1:: 145.76 total_task_done_P2:: 210.268 total_task_done_P3:: 314.992\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.7839052827832036 0.7346420287786672 0.6021374490464612 0.4162963588038911 0.23477994056575732\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.7876992380960482 0.7502124571636622 0.6500894179971592 0.5094412964171809 0.39977252504389593\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8045922106657826 0.7715019688817278 0.6980899906675464 0.5779442236665059 0.5194160651157349\n",
      "mean_task_P1_select_by_bucket_51_10_100 60.756 64.452 59.572 50.72 13.668\n",
      "mean_task_P2_select_by_bucket_51_10_100 76.364 81.136 76.964 64.5 21.16\n",
      "mean_task_P3_select_by_bucket_51_10_100 101.324 107.048 103.368 86.352 32.616\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0031666437980768115 0.026125951588217664 0.06773963067780141 0.10640241828617734 0.12193150109720469\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.003291699767232054 0.026082972520097458 0.06627856273949873 0.10274029717899481 0.09225993088437068\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0033554816537684044 0.025584131117011764 0.06371548571791143 0.09703961961983415 0.0767288494673634\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.526746423260724 7.677926322637649 7.8587647634366276 8.391767552647078 10.131949439346192\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.674234118509779 7.720927167204883 7.794775544475034 8.471687923485192 10.020296870840737\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.718774605653093 7.628186682532359 7.8490023591811156 8.35821208805393 9.608890322904484\n",
      "mean_data_P1_data_by_bucket_51_10_100 14979.289199172465 14958.970687732733 14907.523187877718 14625.111734949935 12499.743306349206\n",
      "mean_data_P2_data_by_bucket_51_10_100 15030.860778826334 14992.7510585864 14921.66442622941 14730.72992780672 14571.966838363185\n",
      "mean_data_P3_data_by_bucket_51_10_100 15034.096252942152 14983.001940664542 14921.64256355625 14767.39776059985 14758.544935608876\n",
      "all_tran 0.07742147666398132 all_comp 0.09736388654320174\n",
      "all_tran_P1 0.08689510376241472 all_tran_P2 0.07904739907043216 all_tran_P3 0.07189896058905168\n",
      "all_comp_P1 0.10478548540838259 all_comp_P2 0.09914946695671639 all_comp_P3 0.09000814473885362\n",
      "all_data_P1 14999.788480911022 all_data_P2 15014.424071100124 all_data_P3 14989.079367907643\n",
      "epi_comp_energy 7.991407924671839\n",
      "epi_comp_freq 7693376000.0\n",
      "epi_comp_latency 0.09736388654320174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tAverage Score: -871.3204\tmeantaskP1: 0.7390\tmeantaskP2: 0.7628\tmeantaskP3: 0.8050\tmeanenergyP1:                     10.1547\tmeanenergyP2: 9.9299\tmeanenergyP3: 10.5158 \tmeanlatencyP1: 0.0726 \tmeanlatencyP2: 0.0675 \tmeanlatencyP3:                     0.0648 \tmeandatasize: 14894.1479 \tmeandatasizeP1: 14868.8677 \tmeandatasizeP2: 15022.4579 \tmeandatasizeP3: 14850.4189 \tmean_tran_latencyP1: 0.0491                      \tmean_tran_latencyP2: 0.0445  \tmean_tran_latencyP3: 0.0449  \tmean_comp_latencyP1: 0.0236                      \tmean_comp_latencyP2: 0.0230 \tmean_comp_latencyP3: 0.0199\n",
      "mean_task_till_this_window 0.6861439999999999 T1:: 0.632800004999333 T2:: 0.6805871855691338 T3:: 0.7172867906169008\n",
      "task_select_P1 240.196 task_select_P2 317.212 task_select_P3 442.592\n",
      "total_task_done_P1:: 140.756 total_task_done_P2:: 212.644 total_task_done_P3:: 332.744\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.7856512058293483 0.7410487151685552 0.6135034036249242 0.43564593294289716 0.2499029001710015\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.7954414307117668 0.7623887089503207 0.6718345480751052 0.5324037856963126 0.43335323858827385\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8064319803593301 0.7842366652454398 0.7095477507358864 0.6048009197711235 0.5553760882527835\n",
      "mean_task_P1_select_by_bucket_51_10_100 58.016 61.34 58.748 48.896 13.196\n",
      "mean_task_P2_select_by_bucket_51_10_100 75.924 79.908 76.944 64.04 20.396\n",
      "mean_task_P3_select_by_bucket_51_10_100 103.984 109.24 106.584 89.228 33.556\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.003251132917720888 0.02625707242621202 0.06904329868653548 0.10792550183668559 0.1215801198650799\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0031575869653242723 0.026037308691207548 0.06620607450895233 0.10403402678106236 0.09441113459897034\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0034543644017993886 0.026067773589375624 0.06422857179724087 0.09805952195905164 0.07882194920794519\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.773985083513227 7.997185747293003 8.107903295114207 8.576995266835812 10.062290003508796\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.864762375684027 7.89723552438152 8.032612371534299 8.681933344756827 9.86341369073796\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.836676291930626 7.937570710757078 8.063728709541925 8.537042099047033 9.623468096220483\n",
      "mean_data_P1_data_by_bucket_51_10_100 15055.75818343949 14950.99861708972 14856.707823677401 14699.712655624939 12678.610831746033\n",
      "mean_data_P2_data_by_bucket_51_10_100 15005.475917706677 14945.971031253055 14962.46216914239 14731.8721069042 14467.043077754872\n",
      "mean_data_P3_data_by_bucket_51_10_100 15018.579541921687 14981.48898573443 14960.31689791449 14839.433844859388 14871.72912515668\n",
      "all_tran 0.07668454094057145 all_comp 0.0907968771534615\n",
      "all_tran_P1 0.08912921977777577 all_tran_P2 0.07750041078175067 all_tran_P3 0.07093927382004318\n",
      "all_comp_P1 0.09844433239401755 all_comp_P2 0.09145704260744224 all_comp_P3 0.08435964027404079\n",
      "all_data_P1 15003.019376406439 all_data_P2 14994.723463781474 all_data_P3 15010.880965582095\n",
      "epi_comp_energy 8.190512011806238\n",
      "epi_comp_freq 7804872000.0\n",
      "epi_comp_latency 0.0907968771534615\n",
      "Episode 1250\tAverage Score: -828.2711\tmeantaskP1: 0.7633\tmeantaskP2: 0.7945\tmeantaskP3: 0.8366\tmeanenergyP1:                     12.7057\tmeanenergyP2: 12.5845\tmeanenergyP3: 13.0180 \tmeanlatencyP1: 0.0666 \tmeanlatencyP2: 0.0646 \tmeanlatencyP3:                     0.0625 \tmeandatasize: 14949.7869 \tmeandatasizeP1: 14925.3680 \tmeandatasizeP2: 14998.2048 \tmeandatasizeP3: 14936.9510 \tmean_tran_latencyP1: 0.0473                      \tmean_tran_latencyP2: 0.0457  \tmean_tran_latencyP3: 0.0462  \tmean_comp_latencyP1: 0.0193                      \tmean_comp_latencyP2: 0.0188 \tmean_comp_latencyP3: 0.0163\n",
      "mean_task_till_this_window 0.707524 T1:: 0.6517631114440804 T2:: 0.7005852751015558 T3:: 0.738121554888345\n",
      "task_select_P1 232.004 task_select_P2 313.448 task_select_P3 454.548\n",
      "total_task_done_P1:: 140.796 total_task_done_P2:: 217.132 total_task_done_P3:: 349.596\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.8090687459510113 0.7613416948139079 0.634505413271743 0.4511074252055608 0.267542296892938\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.8156618443715353 0.7809399221508524 0.6930371228394301 0.5521141131274719 0.45235418431074653\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8222017276138879 0.7964311235694466 0.7354629314469872 0.6372122665102229 0.561619777703577\n",
      "mean_task_P1_select_by_bucket_51_10_100 56.46 59.128 56.784 46.58 13.052\n",
      "mean_task_P2_select_by_bucket_51_10_100 74.956 78.34 76.124 63.808 20.22\n",
      "mean_task_P3_select_by_bucket_51_10_100 107.54 113.228 108.956 91.172 33.652\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.003104265067122314 0.026797941870457826 0.06812178320669475 0.10806276740372639 0.1242461084161452\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0032956953386598735 0.026175986176843444 0.06732724126053131 0.10307589858500264 0.09541281736771191\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0034217833595710854 0.026216139685175804 0.06477402693920711 0.0983724054502439 0.0800644878587193\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.387145838191904 7.3062107558865685 7.376735335045252 7.846701657822708 8.854658755175922\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.295483257796588 7.282783380786309 7.3961571169292295 7.942806861347309 8.686780624889261\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.335882798478186 7.30741612623567 7.550317706736965 8.01967568235311 8.289185104112452\n",
      "mean_data_P1_data_by_bucket_51_10_100 15019.399881843596 14949.964810408832 14859.094731419582 14688.554380900901 12816.581439682539\n",
      "mean_data_P2_data_by_bucket_51_10_100 14987.079510325755 14986.979650872247 14924.972509746305 14818.306192501717 14470.050967203058\n",
      "mean_data_P3_data_by_bucket_51_10_100 15002.772713863456 14986.265193616471 14976.632781657314 14826.427254007378 14818.210459284846\n",
      "all_tran 0.07569406418901356 all_comp 0.08055604358666775\n",
      "all_tran_P1 0.08694954354388248 all_tran_P2 0.07739664895179478 all_tran_P3 0.07016953089710856\n",
      "all_comp_P1 0.08734891016709129 all_comp_P2 0.08119076021264791 all_comp_P3 0.07526409779114335\n",
      "all_data_P1 15000.26188608137 all_data_P2 14991.511130741404 all_data_P3 15006.005107707006\n",
      "epi_comp_energy 7.5462176968568\n",
      "epi_comp_freq 7479264000.0\n",
      "epi_comp_latency 0.08055604358666775\n",
      "Episode 1500\tAverage Score: -866.2475\tmeantaskP1: 0.7081\tmeantaskP2: 0.7295\tmeantaskP3: 0.7679\tmeanenergyP1:                     10.7152\tmeanenergyP2: 10.6259\tmeanenergyP3: 10.9802 \tmeanlatencyP1: 0.0741 \tmeanlatencyP2: 0.0715 \tmeanlatencyP3:                     0.0673 \tmeandatasize: 14921.6149 \tmeandatasizeP1: 14937.5574 \tmeandatasizeP2: 14937.0641 \tmeandatasizeP3: 14904.4140 \tmean_tran_latencyP1: 0.0461                      \tmean_tran_latencyP2: 0.0440  \tmean_tran_latencyP3: 0.0444  \tmean_comp_latencyP1: 0.0280                      \tmean_comp_latencyP2: 0.0275 \tmean_comp_latencyP3: 0.0228\n",
      "mean_task_till_this_window 0.7554280000000001 T1:: 0.6954886388909085 T2:: 0.7477805178077653 T3:: 0.7847105453231413\n",
      "task_select_P1 215.028 task_select_P2 310.008 task_select_P3 474.964\n",
      "total_task_done_P1:: 139.968 total_task_done_P2:: 228.752 total_task_done_P3:: 386.708\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.8460996130457102 0.8053295360214717 0.6912290803556714 0.4881719233829323 0.2974552041844975\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.8512741744157545 0.8236625911283377 0.7417923007150655 0.610784029874595 0.5088952679028903\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8634875842053712 0.8435754301937636 0.7791828328126251 0.6855970812585586 0.6246276136474521\n",
      "mean_task_P1_select_by_bucket_51_10_100 52.348 54.248 52.668 44.136 11.628\n",
      "mean_task_P2_select_by_bucket_51_10_100 73.676 77.628 76.7 62.924 19.08\n",
      "mean_task_P3_select_by_bucket_51_10_100 111.38 117.624 116.204 95.856 33.9\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.00302887428537304 0.027042659560570923 0.07086851676023496 0.10990376850084638 0.1257746350633944\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0033020932254707756 0.02655734020384432 0.06888273602614764 0.10474572199129267 0.09851445420757433\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.003715655120625902 0.02638003990432681 0.0662145833010398 0.10030411806441004 0.08205444960450152\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.766780517312271 7.872252409048924 8.018453717806153 8.417667371650605 9.876790748342858\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.861711576018354 7.8118270233182105 7.857343939727732 8.343210821326668 9.48678457778088\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.8277204041811 7.867591542221633 7.926869850868355 8.31050115565326 9.204317540847773\n",
      "mean_data_P1_data_by_bucket_51_10_100 14994.203323289279 14947.141108414708 14928.569735843426 14688.363614190317 13220.20394761905\n",
      "mean_data_P2_data_by_bucket_51_10_100 14998.702218019735 14986.929458551995 14924.463716179092 14837.780282150849 14562.052861406624\n",
      "mean_data_P3_data_by_bucket_51_10_100 15008.604474676138 15006.76234306746 14994.527432590618 14920.634349683716 14849.51734709729\n",
      "all_tran 0.0746461630964655 all_comp 0.0608140380582\n",
      "all_tran_P1 0.08876278362658942 all_tran_P2 0.07603900737401545 all_tran_P3 0.06862251834800209\n",
      "all_comp_P1 0.0658096084434245 all_comp_P2 0.06158887962263097 all_comp_P3 0.056869256729831265\n",
      "all_data_P1 14990.52060335628 all_data_P2 14992.362164683806 all_data_P3 15026.209360638857\n",
      "epi_comp_energy 8.05121188546944\n",
      "epi_comp_freq 7783736000.0\n",
      "epi_comp_latency 0.0608140380582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1750\tAverage Score: -804.1277\tmeantaskP1: 0.6621\tmeantaskP2: 0.6918\tmeantaskP3: 0.7306\tmeanenergyP1:                     10.4522\tmeanenergyP2: 10.3161\tmeanenergyP3: 10.5264 \tmeanlatencyP1: 0.0737 \tmeanlatencyP2: 0.0730 \tmeanlatencyP3:                     0.0686 \tmeandatasize: 14942.8309 \tmeandatasizeP1: 14940.0858 \tmeandatasizeP2: 14962.2913 \tmeandatasizeP3: 14933.2434 \tmean_tran_latencyP1: 0.0463                      \tmean_tran_latencyP2: 0.0438  \tmean_tran_latencyP3: 0.0443  \tmean_comp_latencyP1: 0.0274                      \tmean_comp_latencyP2: 0.0292 \tmean_comp_latencyP3: 0.0243\n",
      "mean_task_till_this_window 0.741668 T1:: 0.6806504099627169 T2:: 0.7329198541997003 T3:: 0.7747645742666774\n",
      "task_select_P1 220.324 task_select_P2 308.528 task_select_P3 471.148\n",
      "total_task_done_P1:: 139.592 total_task_done_P2:: 222.976 total_task_done_P3:: 379.1\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.8288797325909252 0.7914168008391081 0.6687767029495063 0.48297076126500926 0.2904914824881744\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.840417854920114 0.806601018440954 0.7316036058005623 0.5930976599963997 0.48412676672437166\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.849902433983911 0.8321598989965068 0.7726694752114802 0.6756803972222815 0.6207864510535176\n",
      "mean_task_P1_select_by_bucket_51_10_100 53.256 55.796 54.124 45.436 11.712\n",
      "mean_task_P2_select_by_bucket_51_10_100 73.94 77.912 74.56 63.432 18.684\n",
      "mean_task_P3_select_by_bucket_51_10_100 111.616 116.924 113.42 96.196 32.992\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0031970430478243978 0.0272829846553744 0.06901053226166219 0.10902610757836223 0.1237922224783376\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.003314870113500741 0.026676634233094156 0.06738101683709473 0.10478365385043455 0.09486738120921619\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.003492064247495771 0.026612507687329603 0.06630881786111213 0.0987295070560488 0.08087709445003222\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.027204827154035 7.020349164625195 7.2300699781249165 7.450558333840642 8.766553873655365\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.13607850909835 7.009073770354042 7.187692937433782 7.480341800404856 8.645609505623657\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.052222472362807 7.156211825470812 7.202287276776469 7.520692349331458 8.321858057345812\n",
      "mean_data_P1_data_by_bucket_51_10_100 15017.272958328098 14948.338383592856 14803.345951186884 14700.846856851833 12988.22121746032\n",
      "mean_data_P2_data_by_bucket_51_10_100 15026.926911117669 15014.842807051453 14965.348447531807 14793.857776795183 14598.98854128094\n",
      "mean_data_P3_data_by_bucket_51_10_100 15027.451497928083 15015.994974509986 14912.973255300603 14899.235727166659 14876.029798962565\n",
      "all_tran 0.0736554981266699 all_comp 0.067396093736095\n",
      "all_tran_P1 0.08684755961795856 all_tran_P2 0.07489945233861567 all_tran_P3 0.06778131716441996\n",
      "all_comp_P1 0.07289086631122492 all_comp_P2 0.06876681094889764 all_comp_P3 0.062430382447027574\n",
      "all_data_P1 14986.852143628956 all_data_P2 15017.668994258485 all_data_P3 14996.847371157604\n",
      "epi_comp_energy 7.269952421423841\n",
      "epi_comp_freq 7328752000.0\n",
      "epi_comp_latency 0.067396093736095\n",
      "Episode 2000\tAverage Score: -786.1973\tmeantaskP1: 0.6625\tmeantaskP2: 0.6917\tmeantaskP3: 0.7418\tmeanenergyP1:                     10.3340\tmeanenergyP2: 10.2968\tmeanenergyP3: 10.4964 \tmeanlatencyP1: 0.0739 \tmeanlatencyP2: 0.0724 \tmeanlatencyP3:                     0.0682 \tmeandatasize: 14953.8653 \tmeandatasizeP1: 14945.5691 \tmeandatasizeP2: 14978.9186 \tmeandatasizeP3: 14941.9641 \tmean_tran_latencyP1: 0.0470                      \tmean_tran_latencyP2: 0.0447  \tmean_tran_latencyP3: 0.0447  \tmean_comp_latencyP1: 0.0269                      \tmean_comp_latencyP2: 0.0278 \tmean_comp_latencyP3: 0.0235\n",
      "mean_task_till_this_window 0.743884 T1:: 0.6832624683934894 T2:: 0.735027407182828 T3:: 0.7767767084025368\n",
      "task_select_P1 221.996 task_select_P2 309.792 task_select_P3 468.212\n",
      "total_task_done_P1:: 141.016 total_task_done_P2:: 225.244 total_task_done_P3:: 377.624\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.8345352312246949 0.7971038166509422 0.6725873132219156 0.4777768262153383 0.27525993070644145\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.8426910242201981 0.8163573195265499 0.7307377993303112 0.5933738520723978 0.46793097915149995\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8554175364381119 0.8334797546258851 0.7739273443368243 0.67444043467217 0.6190326818438457\n",
      "mean_task_P1_select_by_bucket_51_10_100 53.224 57.396 54.868 45.128 11.38\n",
      "mean_task_P2_select_by_bucket_51_10_100 73.876 78.352 74.688 64.064 18.812\n",
      "mean_task_P3_select_by_bucket_51_10_100 110.352 116.576 113.82 95.332 32.132\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.0029736796066325106 0.027234748217321393 0.07003743806027245 0.10704218730328785 0.12000553371867707\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.003359967039814132 0.026847678771363726 0.06752399203255885 0.10433985949638834 0.09321557913903956\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.0035869629693012404 0.026236320119628353 0.06579112912182643 0.09866715944058571 0.08120861143776818\n",
      "mean_task_P1_energy_by_bucket_51_10_100 6.820142769821033 6.920073870123072 7.0030032854823965 7.3479416670333695 8.359253970094086\n",
      "mean_task_P2_energy_by_bucket_51_10_100 6.844356848013772 6.8411928626294465 6.887473213680707 7.298174785553859 7.970549767335342\n",
      "mean_task_P3_energy_by_bucket_51_10_100 6.841546643426796 6.947115702733721 6.941319370323571 7.291901462328018 7.926584849473628\n",
      "mean_data_P1_data_by_bucket_51_10_100 15043.323956662804 14999.224886807366 14901.436158520582 14787.679776814843 12324.414871428571\n",
      "mean_data_P2_data_by_bucket_51_10_100 14988.742884243358 15012.524521301786 14903.72449221256 14814.588178755035 14433.95364537334\n",
      "mean_data_P3_data_by_bucket_51_10_100 15036.826217665444 14987.608450426962 14976.987904279149 14877.52138848007 14784.418675533163\n",
      "all_tran 0.07370880600981672 all_comp 0.06727154588924424\n",
      "all_tran_P1 0.08714646012943027 all_tran_P2 0.07574878780301544 all_tran_P3 0.06751459410008386\n",
      "all_comp_P1 0.07313173004666136 all_comp_P2 0.06799579732662928 all_comp_P3 0.062358865685155446\n",
      "all_data_P1 15020.437840255181 all_data_P2 15010.875629136704 all_data_P3 15009.692294635748\n",
      "epi_comp_energy 7.04012760268672\n",
      "epi_comp_freq 7199832000.0\n",
      "epi_comp_latency 0.06727154588924424\n",
      "Episode 2250\tAverage Score: -844.9439\tmeantaskP1: 0.6834\tmeantaskP2: 0.7190\tmeantaskP3: 0.7652\tmeanenergyP1:                     11.0628\tmeanenergyP2: 10.9614\tmeanenergyP3: 11.0938 \tmeanlatencyP1: 0.0723 \tmeanlatencyP2: 0.0707 \tmeanlatencyP3:                     0.0674 \tmeandatasize: 14961.1293 \tmeandatasizeP1: 14976.1872 \tmeandatasizeP2: 14973.1725 \tmeandatasizeP3: 14950.3907 \tmean_tran_latencyP1: 0.0471                      \tmean_tran_latencyP2: 0.0449  \tmean_tran_latencyP3: 0.0451  \tmean_comp_latencyP1: 0.0252                      \tmean_comp_latencyP2: 0.0258 \tmean_comp_latencyP3: 0.0223\n",
      "mean_task_till_this_window 0.758808 T1:: 0.6968605892638027 T2:: 0.7509685385373536 T3:: 0.790526679797988\n",
      "task_select_P1 214.548 task_select_P2 312.992 task_select_P3 472.46\n",
      "total_task_done_P1:: 140.356 total_task_done_P2:: 231.804 total_task_done_P3:: 386.648\n",
      "mean_task_P1_ratio_by_bucket_51_10_100 0.8474433868639141 0.8131792847405316 0.6888538343925554 0.4744949800824799 0.3194630510415939\n",
      "mean_task_P2_ratio_by_bucket_51_10_100 0.8496862264495445 0.8290920805168341 0.7475804268110796 0.6139384981230152 0.5080431951689606\n",
      "mean_task_P3_ratio_by_bucket_51_10_100 0.8652961784063343 0.8466056039875272 0.7908534904329312 0.6900329817126468 0.6393382524346126\n",
      "mean_task_P1_select_by_bucket_51_10_100 52.428 54.492 52.388 43.964 11.276\n",
      "mean_task_P2_select_by_bucket_51_10_100 74.128 79.888 76.212 63.364 19.4\n",
      "mean_task_P3_select_by_bucket_51_10_100 112.128 117.224 113.788 95.776 33.544\n",
      "mean_task_P1_latency_by_bucket_51_10_100 0.003063843375809597 0.02764942163352014 0.07095191805397857 0.11060468908346202 0.1289047190692595\n",
      "mean_task_P2_latency_by_bucket_51_10_100 0.0033309615338781074 0.02648834631331107 0.06885130267383008 0.10508579362098601 0.09477217487584662\n",
      "mean_task_P3_latency_by_bucket_51_10_100 0.003585309840056472 0.02642867157612175 0.06615997245645244 0.10021828166286165 0.0832415787347503\n",
      "mean_task_P1_energy_by_bucket_51_10_100 7.601645797035316 7.5641285546859764 7.674928930543849 8.007205942005607 9.432763971615822\n",
      "mean_task_P2_energy_by_bucket_51_10_100 7.4952880314193555 7.552762468037436 7.522654762604396 7.9919275948682245 8.949145710916204\n",
      "mean_task_P3_energy_by_bucket_51_10_100 7.498692742998503 7.499080352263398 7.663313533499362 8.071700394883234 8.887910393306933\n",
      "mean_data_P1_data_by_bucket_51_10_100 15053.809608314716 15032.280339947589 14871.15987649341 14687.886469121084 13011.748596825399\n",
      "mean_data_P2_data_by_bucket_51_10_100 14978.502026585433 14996.544900059658 14940.317958068728 14829.895646154977 14633.720218844932\n",
      "mean_data_P3_data_by_bucket_51_10_100 15016.03870661838 15004.485882478659 14974.07462975245 14856.296739735577 14790.84812743546\n",
      "all_tran 0.07374812039077323 all_comp 0.05972983354348776\n",
      "all_tran_P1 0.08839907348952461 all_tran_P2 0.07491031083381426 all_tran_P3 0.06765159153082755\n",
      "all_comp_P1 0.06453288871991532 all_comp_P2 0.060651487743135835 all_comp_P3 0.05553590793203736\n",
      "all_data_P1 15017.369827437158 all_data_P2 15001.98817508791 all_data_P3 14997.105889565468\n",
      "epi_comp_energy 7.733112129458081\n",
      "epi_comp_freq 7619872000.0\n",
      "epi_comp_latency 0.05972983354348776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2274\tAverage Score: -839.2151\tmeantaskP1: 0.4641\tmeantaskP2: 0.4618\tmeantaskP3: 0.4878\tcomplatencyP1:             0.0368\tcomplatencyP2: 0.0264\tcomplatencyP3: 0.0333\tmeanlatencyP1: 0.0502\tmeanlatencyP2: 0.0496\tmeanlatencyP3:0.0415\tmeanlatreward:0.0387\tmeanengreward:0.9982"
     ]
    }
   ],
   "source": [
    "def lgreedy(n_episodes=epoch_no, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995,bench_score=1500000):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of atimesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-lgreedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    epi_scores = []                        # list containing scores from each episode\n",
    "    epi_task=[]\n",
    "    epi_task_P1=[]\n",
    "    epi_task_P2=[]\n",
    "    epi_task_P3=[]\n",
    "    \n",
    "    epi_all_trans_latency=[]\n",
    "    epi_all_trans_latency_P1=[]\n",
    "    epi_all_trans_latency_P2=[]\n",
    "    epi_all_trans_latency_P3=[]\n",
    "    epi_all_comp_latency=[]\n",
    "    epi_all_comp_latency_P1=[]\n",
    "    epi_all_comp_latency_P2=[]\n",
    "    epi_all_comp_latency_P3=[]\n",
    "    \n",
    "    \n",
    "    epi_comp_latency=[]\n",
    "    epi_comp_latency_P1=[]\n",
    "    epi_comp_latency_P2=[]\n",
    "    epi_comp_latency_P3=[]\n",
    "    epi_tran_latency=[]\n",
    "    epi_tran_latency_P1=[]\n",
    "    epi_tran_latency_P2=[]\n",
    "    epi_tran_latency_P3=[]\n",
    "    epi_latency=[]\n",
    "    epi_latency_P1=[]\n",
    "    epi_latency_P2=[]\n",
    "    epi_latency_P3=[]\n",
    "    epi_task_select_P1=[]\n",
    "    epi_task_select_P2=[]\n",
    "    epi_task_select_P3=[]\n",
    "    epi_datasize=[]\n",
    "    epi_datasize_P1=[]\n",
    "    epi_datasize_P2=[]\n",
    "    epi_datasize_P3=[]\n",
    "    epi_all_datasize_P1=[]\n",
    "    epi_all_datasize_P2=[]\n",
    "    epi_all_datasize_P3=[]\n",
    "    epi_energy=[]\n",
    "    epi_energy_P1=[]\n",
    "    epi_energy_P2=[]\n",
    "    epi_energy_P3=[]\n",
    "\n",
    "    epi_num_task=[]\n",
    "    epi_num_task_P1=[]\n",
    "    epi_num_task_P2=[]\n",
    "    epi_num_task_P3=[]\n",
    "    epi_comp_energy=[]\n",
    "    epi_comp_frequency=[]\n",
    "    mean_scores = [] # average score by the windos size\n",
    "    mean_task=[] # average task ratio by window size\n",
    "    mean_energy = [] # average energy cost by window size\n",
    "    mean_latency=[]\n",
    "    mean_datasize=[]\n",
    "    mean_tran_latency=[]\n",
    "    mean_comp_latency=[]\n",
    "\n",
    "    mean_tasks_P1=[]\n",
    "    mean_tasks_P2=[]\n",
    "    mean_tasks_P3=[]\n",
    "\n",
    "    mean_energy_P1=[]\n",
    "    mean_energy_P2=[]\n",
    "    mean_energy_P3=[]\n",
    "\n",
    "    mean_latency_P1=[]\n",
    "    mean_latency_P2=[]\n",
    "    mean_latency_P3=[]\n",
    "    mean_tran_latency_P1=[]\n",
    "    mean_tran_latency_P2=[]\n",
    "    mean_tran_latency_P3=[]\n",
    "    mean_comp_latency_P1=[]\n",
    "    mean_comp_latency_P2=[]\n",
    "    mean_comp_latency_P3=[]\n",
    "\n",
    "    mean_datasize_P1=[]\n",
    "    mean_datasize_P2=[]\n",
    "    mean_datasize_P3=[]\n",
    "    reward_list_P1=[]\n",
    "    reward_list_P2=[]\n",
    "    reward_list_P3=[]\n",
    "\n",
    "    scores_window = deque(maxlen=window_size)  # last score_window_size scores\n",
    "    task_done_ratio_window = deque(maxlen=window_size)  # last  task dones\n",
    "    energy_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    latency_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    datasize_window= deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "    mean_tasks_P1_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_tasks_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    win_num_task = deque(maxlen=window_size)\n",
    "    win_num_task_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    win_num_task_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_datasize_window=deque(maxlen=window_size)\n",
    "    mean_datasize_P1_window= deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P2_window = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_datasize_P3_window = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_energy_window_P1 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P2 = deque(maxlen=window_size)  # last  engery cost\n",
    "    mean_energy_window_P3 = deque(maxlen=window_size)  # last  engery cost\n",
    "\n",
    "    mean_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_comp_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_comp_latency_P3_window=deque(maxlen=window_size)\n",
    "    \n",
    "    mean_tran_latency_P1_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P2_window=deque(maxlen=window_size)\n",
    "    mean_tran_latency_P3_window=deque(maxlen=window_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    bucket_tasks_mean = {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_task_len= {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_latency_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_energy_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    bucket_data_mean= {(10, 0.25*max_dis):{},(0.25*max_dis,0.5*max_dis):{},(0.5*max_dis,0.75*max_dis):{},\\\n",
    "                         (0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    #bucket_energy_mean={(10, 0.25*max_dis):{},(0.25*max_dis,0.50*max_dis):{},(0.5*max_dis,0.75*max_dis):{},(0.75*max_dis,1*max_dis):{},(1*max_dis,float('inf')):{}}\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        mec_evn.reset() # reset the environment\n",
    "\n",
    "        score = 0\n",
    "        energy = []\n",
    "        latency=[]\n",
    "        task_done = []\n",
    "        energy_P1=[]\n",
    "        energy_P2=[]\n",
    "        energy_P3=[]\n",
    "        task_done_P1=[]\n",
    "        task_done_P2=[]\n",
    "        task_done_P3=[]\n",
    "        latency_P1=[]\n",
    "        latency_P2=[]\n",
    "        latency_P3=[]\n",
    "        comp_latency=[]\n",
    "        comp_latency_P1=[]\n",
    "        comp_latency_P2=[]\n",
    "        comp_latency_P3=[]\n",
    "        tran_latency=[]\n",
    "        tran_latency_P1=[]\n",
    "        tran_latency_P2=[]\n",
    "        tran_latency_P3=[]\n",
    "        compt_energy=[]\n",
    "        compt_freq=[]\n",
    "        all_trans_latency=[]\n",
    "        all_trans_latency_P1=[]\n",
    "        all_trans_latency_P2=[]\n",
    "        all_trans_latency_P3=[]\n",
    "        \n",
    "        all_comp_latency=[]\n",
    "        all_comp_latency_P1=[]\n",
    "        all_comp_latency_P2=[]\n",
    "        all_comp_latency_P3=[]\n",
    "        \n",
    "        all_datasize_P1=[]\n",
    "        all_datasize_P2=[]\n",
    "        all_datasize_P3=[]\n",
    "        datasize=[]\n",
    "        datasize_P1=[]\n",
    "        datasize_P2=[]\n",
    "        datasize_P3=[]\n",
    "\n",
    "        reward_lat=[]\n",
    "        reward_eng=[]\n",
    "        bucket_task = {range_tuple: {'P1_task_done': [], 'P2_task_done': [], 'P3_task_done': []} for range_tuple in bucket_ranges}\n",
    "        bucket_latency = {range_tuple: {'P1_latency': [], 'P2_latency': [], 'P3_latency': []} for range_tuple in bucket_ranges}\n",
    "        bucket_energy = {range_tuple: {'P1_energy': [], 'P2_energy': [], 'P3_energy': []} for range_tuple in bucket_ranges}\n",
    "        bucket_data = {range_tuple: {'P1_data': [], 'P2_data': [], 'P3_data': []} for range_tuple in bucket_ranges}\n",
    "\n",
    "\n",
    "        tasks = mec_evn.get_task()\n",
    "        state = mec_evn.get_state(tasks)\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            max_reward_task,max_reward_server,max_reward_frequency = lgreedy_agent.action(tasks,mec_evn)\n",
    "           \n",
    "            lgreedy_action=[(max_reward_server,max_reward_frequency)]\n",
    "           \n",
    "            rec_mec_idx=max_reward_server\n",
    "            #lgreedy_task=mec_evn.priority_queues[max_reward_task].pop(0)\n",
    "\n",
    "#             print(\"action=\",action)\n",
    "            next_state, feedback, done ,action_task,next_task,rec_mec_index = mec_evn.greedy_step(lgreedy_action,tasks,max_reward_task)\n",
    "          #  print(rec_mec_idx, rec_mec_index)\n",
    "            score += feedback['reward']\n",
    "            \n",
    "            energy.append(feedback['energy'])\n",
    "            \n",
    "            user_distance=action_task['user_distance'][rec_mec_idx]\n",
    "            #print(user_distance)\n",
    "           # print(user_distance,rec_mec_idx,action_task['user_distance'])\n",
    "            bucket = find_bucket(user_distance, bucket_ranges)\n",
    "            tran_time=feedback['lat_vec'][0]\n",
    "            comp_time=feedback['lat_vec'][1]+feedback['lat_vec'][2] #comp_time+wait_time\n",
    "            reward_lat.append(feedback['reward_lat'])\n",
    "            reward_eng.append(feedback['reward_eng'])\n",
    "            all_trans_latency.append(tran_time)\n",
    "            all_comp_latency.append(comp_time)\n",
    "            trans_energy=feedback['eng_vector'][0]\n",
    "            comp_energy=feedback['eng_vector'][1]\n",
    "            compt_energy.append(comp_energy)\n",
    "            compt_freq.append(max(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*max_reward_frequency))\n",
    "           # print(lgreedy_action, (max(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*max_reward_frequency)), mec_evn.max_freq_server)\n",
    "            \n",
    "           # print(min(2*10**9,mec_evn.max_freq_server[rec_mec_idx]*mec_evn.actions[action][1]))\n",
    "           # print(tran_time,comp_time)\n",
    "            if feedback['task_done']==1:\n",
    "              datasize.append(action_task['data_size'])\n",
    "              latency.append(feedback['latency'])\n",
    "              comp_latency.append(comp_time)\n",
    "              tran_latency.append(tran_time)\n",
    "\n",
    "\n",
    "            if action_task['data_size'] != 0 :\n",
    "              task_done.append(feedback['task_done'])\n",
    "              \n",
    "              if action_task['priority']==1:\n",
    "                  \n",
    "                  task_done_P1.append(feedback['task_done'])\n",
    "                  energy_P1.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P1_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P1_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P1.append(tran_time)\n",
    "                  all_comp_latency_P1.append(comp_time)\n",
    "                  all_datasize_P1.append(action_task['data_size'])\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P1.append(feedback['latency'])\n",
    "                    comp_latency_P1.append(comp_time)\n",
    "                    tran_latency_P1.append(tran_time)\n",
    "                    datasize_P1.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P1_latency'].append( tran_time)\n",
    "                    bucket_data[bucket]['P1_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==2:\n",
    "                  \n",
    "                  task_done_P2.append(feedback['task_done']*feedback['task_done'])\n",
    "                  energy_P2.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P2_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P2_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P2.append(tran_time)\n",
    "                  all_comp_latency_P2.append(comp_time)\n",
    "                  all_datasize_P2.append(action_task['data_size'])\n",
    "                  \n",
    "                 \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P2.append(feedback['latency'])\n",
    "                    comp_latency_P2.append(comp_time)\n",
    "                    tran_latency_P2.append(tran_time)\n",
    "                    datasize_P2.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P2_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P2_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "              if action_task['priority']==3:\n",
    "                 \n",
    "                  task_done_P3.append(feedback['task_done'])\n",
    "                  energy_P3.append(feedback['energy'])\n",
    "                  \n",
    "                  \n",
    "                  bucket_task[bucket]['P3_task_done'].append(feedback['task_done'])\n",
    "                  bucket_energy[bucket]['P3_energy'].append(feedback['energy'])\n",
    "                  all_trans_latency_P3.append(tran_time)\n",
    "                  all_comp_latency_P3.append(comp_time)\n",
    "                  all_datasize_P3.append(action_task['data_size'])\n",
    "                  \n",
    "                  if feedback['task_done']:\n",
    "                    latency_P3.append(feedback['latency'])\n",
    "                    comp_latency_P3.append(comp_time)\n",
    "                    tran_latency_P3.append(tran_time)\n",
    "                    datasize_P3.append(action_task['data_size'])\n",
    "                    bucket_latency[bucket]['P3_latency'].append(tran_time)\n",
    "                    bucket_data[bucket]['P3_data'].append(action_task['data_size'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                # Append values to their respective lists within the bucket\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            tasks=next_task\n",
    "            state=next_state\n",
    "            if done:\n",
    "                print(t)\n",
    "                \n",
    "                break\n",
    "        \n",
    "\n",
    "        for range_tuple, tasks in bucket_task.items():\n",
    "            \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for task, values in tasks.items():\n",
    "        # Calculate the mean for each task list\n",
    "                mean_value = sum(values) / len(values) if values else 0  # Ensure division is valid\n",
    "                mean_len = len(values)\n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{task}_mean'\n",
    "                len_key = f'{task}_mean_len'\n",
    "                # Ensure the sub-dictionary for mean values exists for the current range_tuple\n",
    "                if mean_key not in bucket_tasks_mean[range_tuple]:\n",
    "                    bucket_tasks_mean[range_tuple][mean_key] = []\n",
    "                if len_key not in bucket_task_len[range_tuple]:\n",
    "                    bucket_task_len[range_tuple][len_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_tasks_mean[range_tuple][mean_key].append(mean_value)\n",
    "                bucket_task_len[range_tuple][len_key].append(mean_len)\n",
    "        for range_tuple, lat in bucket_latency.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for l, v in lat.items():\n",
    "               # print(l,v)\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{l}_mean'\n",
    "                if mean_key not in bucket_latency_mean[range_tuple]:\n",
    "                    bucket_latency_mean[range_tuple][mean_key] = []\n",
    "                \n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_latency_mean[range_tuple][mean_key].append(mean_value)\n",
    "        for range_tuple, eng in bucket_energy.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for e, v in eng.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{e}_mean'\n",
    "                if mean_key not in bucket_energy_mean[range_tuple]:\n",
    "                    bucket_energy_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_energy_mean[range_tuple][mean_key].append(mean_value)\n",
    "        \n",
    "        for range_tuple, dat in bucket_data.items():\n",
    "             \n",
    "            \n",
    "            # Initialize a sub-dictionary for each range\n",
    "            for d, v in dat.items():\n",
    "                # Calculate the mean for each task list\n",
    "                mean_value = sum(v) / len(v) if v else 0  # Ensure division is valid\n",
    "                \n",
    "                # Create a new key for storing the mean value of the task list\n",
    "                mean_key = f'{d}_mean'\n",
    "                if mean_key not in bucket_data_mean[range_tuple]:\n",
    "                    bucket_data_mean[range_tuple][mean_key] = []\n",
    "                # Store the mean value in the corresponding range's sub-dictionary\n",
    "                bucket_data_mean[range_tuple][mean_key].append(mean_value)\n",
    "                \n",
    "\n",
    "# Now, bucket_means contains only the mean values for each task list within each bucket range.\n",
    "# Displaying the new bucket_means dictionary\n",
    "\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        epi_scores.append(score)              # save most recent score\n",
    "        mean_score = np.mean(scores_window)\n",
    "        epi_task.append(np.mean(task_done))\n",
    "        epi_task_P1.append(np.mean(task_done_P1))\n",
    "        epi_task_P2.append(np.mean(task_done_P2))\n",
    "        epi_task_P3.append(np.mean(task_done_P3))\n",
    "\n",
    "        epi_task_select_P1.append(len(task_done_P1))\n",
    "        epi_task_select_P2.append(len(task_done_P2))\n",
    "        epi_task_select_P3.append(len(task_done_P3))\n",
    "\n",
    "        epi_latency.append(np.mean(latency))\n",
    "        epi_latency_P1.append(np.mean(latency_P1))\n",
    "        epi_latency_P2.append(np.mean(latency_P2))\n",
    "        epi_latency_P3.append(np.mean(latency_P3))\n",
    "        \n",
    "        epi_comp_latency.append(np.mean(comp_latency))\n",
    "        epi_comp_latency_P1.append(np.mean(comp_latency_P1))\n",
    "        epi_comp_latency_P2.append(np.mean(comp_latency_P2))\n",
    "        epi_comp_latency_P3.append(np.mean(comp_latency_P3))\n",
    "        \n",
    "        epi_tran_latency.append(np.mean(tran_latency))\n",
    "        epi_tran_latency_P1.append(np.mean(tran_latency_P1))\n",
    "        epi_tran_latency_P2.append(np.mean(tran_latency_P2))\n",
    "        epi_tran_latency_P3.append(np.mean(tran_latency_P3))\n",
    "        \n",
    "\n",
    "        epi_energy.append(np.mean(energy))\n",
    "        epi_energy_P1.append(np.mean(energy_P1))\n",
    "        epi_energy_P2.append(np.mean(energy_P2))\n",
    "        epi_energy_P3.append(np.mean(energy_P3))\n",
    "\n",
    "        epi_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "        epi_num_task_P1.append(sum(task_done_P1))\n",
    "        epi_num_task_P2.append(sum(task_done_P2))\n",
    "        epi_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "        epi_datasize.append(np.mean(datasize))\n",
    "        epi_datasize_P1.append(np.mean(datasize_P1))\n",
    "        epi_datasize_P2.append(np.mean(datasize_P2))\n",
    "        epi_datasize_P3.append(np.mean(datasize_P3))\n",
    "        \n",
    "        epi_all_datasize_P1.append(np.mean(all_datasize_P1))\n",
    "        epi_all_datasize_P2.append(np.mean(all_datasize_P2))\n",
    "        epi_all_datasize_P3.append(np.mean(all_datasize_P3))\n",
    "\n",
    "        \n",
    "        epi_all_trans_latency.append(np.mean(all_trans_latency))\n",
    "        epi_all_trans_latency_P1.append(np.mean(all_trans_latency_P1))\n",
    "        epi_all_trans_latency_P2.append(np.mean(all_trans_latency_P2))\n",
    "        epi_all_trans_latency_P3.append(np.mean(all_trans_latency_P3))\n",
    "        epi_all_comp_latency.append(np.mean(all_comp_latency))\n",
    "        epi_all_comp_latency_P1.append(np.mean(all_comp_latency_P1))\n",
    "        epi_all_comp_latency_P2.append(np.mean(all_comp_latency_P2))\n",
    "        epi_all_comp_latency_P3.append(np.mean(all_comp_latency_P3))\n",
    "       \n",
    "        epi_comp_energy.append(np.mean(compt_energy))\n",
    "        epi_comp_frequency.append(np.mean(compt_freq))\n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tcomplatencyP1: \\\n",
    "            {:.4f}\\tcomplatencyP2: {:.4f}\\tcomplatencyP3: {:.4f}\\tmeanlatencyP1: {:.4f}\\tmeanlatencyP2: {:.4f}\\tmeanlatencyP3:{:.4f}\\tmeanlatreward:{:.4f}\\tmeanengreward:{:.4f}'.format(i_episode, \\\n",
    "            mean_score, np.mean(task_done_P1), np.mean(task_done_P2), np.mean(task_done_P3), np.mean(comp_latency_P1), \\\n",
    "            np.mean(comp_latency_P2), np.mean(comp_latency_P3), \\\n",
    "                                    np.mean(tran_latency_P1), np.mean(tran_latency_P2), np.mean(tran_latency_P3),np.mean(reward_lat),np.mean(reward_eng)), end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if i_episode % window_size == 0:\n",
    "            \n",
    "\n",
    "            mean_scores.append(mean_score)\n",
    "            task_done_ratio_window.append(np.mean(task_done))       # task done ratio\n",
    "            mean_task.append(np.mean(task_done_ratio_window))\n",
    "            energy_window.append(np.mean(energy))\n",
    "            latency_window.append(np.mean(latency))\n",
    "\n",
    "            mean_energy.append(np.mean(energy_window))\n",
    "            mean_latency.append(np.mean(latency_window))\n",
    "\n",
    "\n",
    "            mean_datasize_window.append(np.mean(datasize))\n",
    "            mean_datasize.append(np.mean(mean_datasize_window))\n",
    "\n",
    "            mean_tasks_P1_window.append(np.mean(task_done_P1))\n",
    "            mean_tasks_P1.append(np.mean( mean_tasks_P1_window))\n",
    "\n",
    "            mean_tasks_P2_window.append(np.mean(task_done_P2))\n",
    "            mean_tasks_P2.append(np.mean( mean_tasks_P2_window))\n",
    "\n",
    "            mean_tasks_P3_window.append(np.mean(task_done_P3))\n",
    "            mean_tasks_P3.append(np.mean( mean_tasks_P3_window))\n",
    "\n",
    "            mean_energy_window_P1.append(np.mean(energy_P1))\n",
    "            mean_energy_P1.append(np.mean(mean_energy_window_P1))\n",
    "\n",
    "            mean_energy_window_P2.append(np.mean(energy_P2))\n",
    "            mean_energy_P2.append(np.mean(mean_energy_window_P2))\n",
    "\n",
    "            mean_energy_window_P3.append(np.mean(energy_P3))\n",
    "            mean_energy_P3.append(np.mean(mean_energy_window_P3))\n",
    "\n",
    "\n",
    "            mean_latency_P1_window.append(np.mean(latency_P1))\n",
    "            mean_latency_P1.append(np.mean( mean_latency_P1_window))\n",
    "\n",
    "            mean_latency_P2_window.append(np.mean(latency_P2))\n",
    "            mean_latency_P2.append(np.mean( mean_latency_P2_window))\n",
    "\n",
    "            mean_latency_P3_window.append(np.mean(latency_P3))\n",
    "            mean_latency_P3.append(np.mean( mean_latency_P3_window))\n",
    "            \n",
    "            mean_comp_latency_P1_window.append(np.mean(comp_latency_P1))\n",
    "            mean_comp_latency_P1.append(np.mean( mean_comp_latency_P1_window))\n",
    "            mean_comp_latency_P2_window.append(np.mean(comp_latency_P2))\n",
    "            mean_comp_latency_P2.append(np.mean( mean_comp_latency_P2_window))\n",
    "            mean_comp_latency_P3_window.append(np.mean(comp_latency_P3))\n",
    "            mean_comp_latency_P3.append(np.mean( mean_comp_latency_P3_window))\n",
    "            \n",
    "            mean_tran_latency_P1_window.append(np.mean(tran_latency_P1))\n",
    "            mean_tran_latency_P1.append(np.mean( mean_tran_latency_P1_window))\n",
    "            mean_tran_latency_P2_window.append(np.mean(tran_latency_P2))\n",
    "            mean_tran_latency_P2.append(np.mean( mean_tran_latency_P2_window))\n",
    "            mean_tran_latency_P3_window.append(np.mean(tran_latency_P3))\n",
    "            mean_tran_latency_P3.append(np.mean( mean_tran_latency_P3_window))\n",
    "\n",
    "            mean_datasize_P1_window.append(np.mean(datasize_P1))\n",
    "            mean_datasize_P1.append(np.mean(mean_datasize_P1_window))\n",
    "\n",
    "            mean_datasize_P2_window.append(np.mean(datasize_P2))\n",
    "            mean_datasize_P2.append(np.mean(mean_datasize_P2_window))\n",
    "\n",
    "            mean_datasize_P3_window.append(np.mean(datasize_P3))\n",
    "            mean_datasize_P3.append(np.mean(mean_datasize_P3_window))\n",
    "\n",
    "\n",
    "            win_num_task.append(sum(task_done_P1)+sum(task_done_P2)+sum(task_done_P3))\n",
    "            win_num_task_P1.append(sum(task_done_P1))\n",
    "            win_num_task_P2.append(sum(task_done_P2))\n",
    "            win_num_task_P3.append(sum(task_done_P3))\n",
    "\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tmeantaskP1: {:.4f}\\tmeantaskP2: {:.4f}\\tmeantaskP3: {:.4f}\\tmeanenergyP1: \\\n",
    "                    {:.4f}\\tmeanenergyP2: {:.4f}\\tmeanenergyP3: {:.4f} \\tmeanlatencyP1: {:.4f} \\tmeanlatencyP2: {:.4f} \\tmeanlatencyP3: \\\n",
    "                    {:.4f} \\tmeandatasize: {:.4f} \\tmeandatasizeP1: {:.4f} \\tmeandatasizeP2: {:.4f} \\tmeandatasizeP3: {:.4f} \\tmean_tran_latencyP1: {:.4f}  \\\n",
    "                    \\tmean_tran_latencyP2: {:.4f}  \\tmean_tran_latencyP3: {:.4f}  \\tmean_comp_latencyP1: {:.4f}  \\\n",
    "                    \\tmean_comp_latencyP2: {:.4f} \\tmean_comp_latencyP3: {:.4f}'.format(i_episode, mean_score,mean_tasks_P1[-1],mean_tasks_P2[-1],\\\n",
    "                    mean_tasks_P3[-1],mean_energy_P1[-1],mean_energy_P2[-1] ,mean_energy_P3[-1], mean_latency_P1[-1],mean_latency_P2[-1],\\\n",
    "                    mean_latency_P3[-1],mean_datasize[-1],mean_datasize_P1[-1], mean_datasize_P2[-1],mean_datasize_P3[-1],\\\n",
    "                        mean_tran_latency_P1[-1], mean_tran_latency_P2[-1],mean_tran_latency_P3[-1],mean_comp_latency_P1[-1],\\\n",
    "                            mean_comp_latency_P2[-1],mean_comp_latency_P3[-1]                                                                                                                                                                                                                   ))\n",
    "\n",
    "\n",
    "            #print(len(task_done_P1),len(task_done_P2),len(task_done_P3))\n",
    "           # print(len(task_done_P1)+len(task_done_P2)+len(task_done_P3))\n",
    "            print('mean_task_till_this_window',np.mean(epi_task[-window_size:]), 'T1::',   np.mean(epi_task_P1[-window_size:]) ,'T2::' ,np.mean(epi_task_P2[-window_size:]) ,'T3::',np.mean(epi_task_P3[-window_size:]))\n",
    "            #print('mean_energy_till_this_window',np.mean(mean_energy[-window_size:]), 'T1::', np.mean(mean_energy_P1[-window_size:])  ,'T2::', np.mean(mean_energy_P2[-window_size:])  ,'T3::',np.mean(mean_energy_P3[-window_size:]))\n",
    "           # print('mean Latency till this window',np.mean(mean_latency[-window_size:]),'T1::', np.mean(mean_latency_P1[-window_size:]),'T1::', np.mean(mean_latency_P2[-window_size:]),'T1::', np.mean(mean_latency_P3[-window_size:]))\n",
    "           # print(type(mean_tasks_P1),type(epi_num_task_P1))\n",
    "            #print('mean_datasize', mean_datasize[-1])\n",
    "            print( 'task_select_P1', np.mean(epi_task_select_P1[-window_size:]), 'task_select_P2', np.mean(epi_task_select_P2[-window_size:]),'task_select_P3', np.mean(epi_task_select_P3[-window_size:]))\n",
    "            print('total_task_done_P1::', np.mean(epi_num_task_P1[-window_size:]),'total_task_done_P2::', np.mean(epi_num_task_P2[-window_size:]),'total_task_done_P3::',np.mean(epi_num_task_P3[-window_size:]))\n",
    "\n",
    "            #print(np.mean(reward_list_P1), np.mean(reward_list_P2), np.mean(reward_list_P3))\n",
    "            #print(min(reward_list_P1), min(reward_list_P2), min(reward_list_P3))\n",
    "           # print(max(reward_list_P1), max(reward_list_P2), max(reward_list_P3))\n",
    "            \n",
    "            #print(mean_tasks_P1)\n",
    "           # print(epi_task_P1)\n",
    "            print('mean_task_P1_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P1_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P1_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P1_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P1_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P1_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P2_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P2_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P2_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P2_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P2_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P2_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P3_ratio_by_bucket_51_10_100', np.mean(bucket_tasks_mean[(10, 0.25*max_dis)]['P3_task_done_mean'][-window_size:]),\n",
    "                  np.mean(bucket_tasks_mean[(0.25*max_dis,0.50*max_dis)]['P3_task_done_mean'][-window_size:]) , np.mean(bucket_tasks_mean[(0.5*max_dis,0.75*max_dis)]['P3_task_done_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_tasks_mean[(0.75*max_dis,1*max_dis)]['P3_task_done_mean'][-window_size:]), np.mean(bucket_tasks_mean[(1*max_dis,float('inf'))]['P3_task_done_mean'][-window_size:]))\n",
    "            print('mean_task_P1_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P1_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P1_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P1_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P1_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P1_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P2_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P2_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P2_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P2_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P2_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P2_task_done_mean_len'][-window_size:]))\n",
    "            print('mean_task_P3_select_by_bucket_51_10_100', np.mean(bucket_task_len[(10, 0.25*max_dis)]['P3_task_done_mean_len'][-window_size:]),\n",
    "                  np.mean(bucket_task_len[(0.25*max_dis,0.50*max_dis)]['P3_task_done_mean_len'][-window_size:]) , np.mean(bucket_task_len[(0.5*max_dis,0.75*max_dis)]['P3_task_done_mean_len'][-window_size:])\n",
    "                  ,np.mean(bucket_task_len[(0.75*max_dis,1*max_dis)]['P3_task_done_mean_len'][-window_size:]), np.mean(bucket_task_len[(1*max_dis,float('inf'))]['P3_task_done_mean_len'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P1_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P1_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P1_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P1_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P1_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P2_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P2_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P2_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P2_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P2_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P2_latency_mean'][-window_size:]))\n",
    "            print('mean_task_P3_latency_by_bucket_51_10_100', np.mean(bucket_latency_mean[(10, 0.25*max_dis)]['P3_latency_mean'][-window_size:]),\n",
    "                  np.mean(bucket_latency_mean[(0.25*max_dis,0.50*max_dis)]['P3_latency_mean'][-window_size:]) , np.mean(bucket_latency_mean[(0.5*max_dis,0.75*max_dis)]['P3_latency_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_latency_mean[(0.75*max_dis,1*max_dis)]['P3_latency_mean'][-window_size:]), np.mean(bucket_latency_mean[(1*max_dis,float('inf'))]['P3_latency_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_task_P1_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P1_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P1_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P1_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P1_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P1_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P2_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P2_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P2_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P2_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P2_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P2_energy_mean'][-window_size:]))\n",
    "            print('mean_task_P3_energy_by_bucket_51_10_100', np.mean(bucket_energy_mean[(10, 0.25*max_dis)]['P3_energy_mean'][-window_size:]),\n",
    "                  np.mean(bucket_energy_mean[(0.25*max_dis,0.50*max_dis)]['P3_energy_mean'][-window_size:]) , np.mean(bucket_energy_mean[(0.5*max_dis,0.75*max_dis)]['P3_energy_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_energy_mean[(0.75*max_dis,1*max_dis)]['P3_energy_mean'][-window_size:]), np.mean(bucket_energy_mean[(1*max_dis,float('inf'))]['P3_energy_mean'][-window_size:]))\n",
    "\n",
    "            print('mean_data_P1_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P1_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P1_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P1_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P1_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P1_data_mean'][-window_size:]))\n",
    "            print('mean_data_P2_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P2_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P2_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P2_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P2_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P2_data_mean'][-window_size:]))\n",
    "            print('mean_data_P3_data_by_bucket_51_10_100', np.mean(bucket_data_mean[(10, 0.25*max_dis)]['P3_data_mean'][-window_size:]),\n",
    "                  np.mean(bucket_data_mean[(0.25*max_dis,0.50*max_dis)]['P3_data_mean'][-window_size:]) , np.mean(bucket_data_mean[(0.5*max_dis,0.75*max_dis)]['P3_data_mean'][-window_size:])\n",
    "                  ,np.mean(bucket_data_mean[(0.75*max_dis,1*max_dis)]['P3_data_mean'][-window_size:]), np.mean(bucket_data_mean[(1*max_dis,float('inf'))]['P3_data_mean'][-window_size:]))\n",
    "\n",
    "\n",
    "            print('all_tran',np.mean(epi_all_trans_latency[-window_size:]), 'all_comp',np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            print('all_tran_P1',np.mean(epi_all_trans_latency_P1[-window_size:]),\\\n",
    "                  'all_tran_P2',np.mean(epi_all_trans_latency_P2[-window_size:]),\\\n",
    "                      'all_tran_P3',np.mean(epi_all_trans_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_comp_P1',np.mean(epi_all_comp_latency_P1[-window_size:]),\\\n",
    "                  'all_comp_P2',np.mean(epi_all_comp_latency_P2[-window_size:]),\\\n",
    "                 'all_comp_P3',np.mean(epi_all_comp_latency_P3[-window_size:]))\n",
    "            \n",
    "            print('all_data_P1',np.mean(epi_all_datasize_P1[-window_size:]),\\\n",
    "                  'all_data_P2',np.mean(epi_all_datasize_P2[-window_size:]),\\\n",
    "                 'all_data_P3',np.mean(epi_all_datasize_P3[-window_size:]))\n",
    "            \n",
    "            \n",
    "            print('epi_comp_energy', np.mean(epi_comp_energy[-window_size:]))\n",
    "            print('epi_comp_freq', np.mean(epi_comp_frequency[-window_size:]))\n",
    "            print('epi_comp_latency', np.mean(epi_all_comp_latency[-window_size:]))\n",
    "            \n",
    "            if np.mean(scores_window)>=bench_score or i_episode % n_episodes==0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, mean_score))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), model_path)\n",
    "                break\n",
    "\n",
    "    return epi_scores,epi_task,epi_energy,epi_latency,epi_num_task, epi_task_P1,epi_task_P2,epi_task_P3,epi_latency_P1,epi_latency_P2,epi_latency_P3,epi_energy_P1,epi_energy_P2,epi_energy_P3,epi_num_task_P1,epi_num_task_P2,epi_num_task_P3, \\\n",
    "    epi_task_select_P1,epi_task_select_P2,epi_task_select_P3,mean_scores,mean_task,mean_energy,mean_latency,win_num_task, mean_tasks_P1,mean_tasks_P2,mean_tasks_P3, mean_energy_P1,\\\n",
    "                 mean_energy_P2, mean_energy_P3,mean_latency_P1,mean_latency_P2,mean_latency_P3,win_num_task_P1,win_num_task_P2,win_num_task_P3,epi_datasize,epi_datasize_P1,epi_datasize_P2,epi_datasize_P3,\\\n",
    "                 mean_datasize,mean_datasize_P1,mean_datasize_P2,mean_datasize_P3,epi_tran_latency_P1,epi_tran_latency_P2,\\\n",
    "                 epi_tran_latency_P3,epi_comp_latency_P1,epi_comp_latency_P2,epi_comp_latency_P3\n",
    "\n",
    "lgreedy_epi_scores,lgreedy_epi_task,lgreedy_epi_energy,lgreedy_epi_latency,lgreedy_epi_num_task,lgreedy_epi_task_P1,lgreedy_epi_task_P2,lgreedy_epi_task_P3,lgreedy_epi_latency_P1,lgreedy_epi_latency_P2,lgreedy_epi_latency_P3,\\\n",
    "lgreedy_epi_energy_P1,lgreedy_epi_energy_P2,lgreedy_epi_energy_P3,lgreedy_epi_num_task_P1,lgreedy_epi_num_task_P2,lgreedy_epi_num_task_P3,lgreedy_epi_task_select_P1,lgreedy_epi_task_select_P2,lgreedy_epi_task_select_P3,\\\n",
    "lgreedy_mean_scores,lgreedy_mean_task,lgreedy_mean_energy,lgreedy_mean_latency,lgreedy_win_num_task, lgreedy_mean_tasks_P1,lgreedy_mean_tasks_P2,lgreedy_mean_tasks_P3,\\\n",
    "lgreedy_mean_energy_P1,lgreedy_mean_energy_P2,lgreedy_mean_energy_P3,lgreedy_mean_latency_P1,lgreedy_mean_latency_P2,lgreedy_mean_latency_P3 ,lgreedy_win_num_task_P1, lgreedy_win_num_task_P2,lgreedy_win_num_task_P3,\\\n",
    "lgreedy_epi_datasize,lgreedy_epi_datasize_P1,lgreedy_epi_datasize_P2,lgreedy_epi_datasize_P3,lgreedy_mean_datasize,lgreedy_mean_datasize_P1,lgreedy_mean_datasize_P2,lgreedy_mean_datasize_P3,\\\n",
    "lgreedy_epi_tran_latency_P1,lgreedy_epi_tran_latency_P2,lgreedy_epi_tran_latency_P3,lgreedy_epi_comp_latency_P1,lgreedy_epi_comp_latency_P2,\\\n",
    "lgreedy_epi_comp_latency_P3= lgreedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNcbaKBSXB1O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv4vHu2WdTeh"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Combining data into a list of tuples\n",
    "data = zip(range(1, len(lgreedy_epi_scores) + 1), lgreedy_epi_scores,lgreedy_epi_task,lgreedy_epi_energy,lgreedy_epi_latency,lgreedy_epi_num_task,lgreedy_epi_task_P1,lgreedy_epi_task_P2,\n",
    "           lgreedy_epi_task_P3,lgreedy_epi_latency_P1,lgreedy_epi_latency_P2,lgreedy_epi_latency_P3,\n",
    "           lgreedy_epi_energy_P1,lgreedy_epi_energy_P2,lgreedy_epi_energy_P3,lgreedy_epi_num_task_P1,lgreedy_epi_num_task_P2,lgreedy_epi_num_task_P3,\n",
    "           lgreedy_epi_datasize,lgreedy_epi_datasize_P1,lgreedy_epi_datasize_P2,lgreedy_epi_datasize_P3,lgreedy_epi_task_select_P1,lgreedy_epi_task_select_P2,\\\n",
    "           lgreedy_epi_task_select_P3,lgreedy_epi_tran_latency_P1,lgreedy_epi_tran_latency_P2,lgreedy_epi_tran_latency_P3,\\\n",
    "                    lgreedy_epi_comp_latency_P1,lgreedy_epi_comp_latency_P2,lgreedy_epi_comp_latency_P3)\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(\"data_lgreedy.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\",\"lgreedy_epi_scores\",\"lgreedy_epi_task\",\"lgreedy_epi_energy\",\"lgreedy_epi_latency\",\"lgreedy_epi_num_task\",\"lgreedy_epi_task_P1\",\"lgreedy_epi_task_P2\",\"lgreedy_epi_task_P3\",\n",
    "                     \"lgreedy_epi_latency_P1\",\"lgreedy_epi_latency_P2\",\"lgreedy_epi_latency_P3\",\"lgreedy_epi_energy_P1\",\"lgreedy_epi_energy_P2\",\"lgreedy_epi_energy_P3\",\"lgreedy_epi_num_task_P1\",\n",
    "                     \"lgreedy_epi_num_task_P2\",\"lgreedy_epi_num_task_P3\",\"lgreedy_epi_datasize\",\"lgreedy_epi_datasize_P1\",\"lgreedy_epi_datasize_P2\"\n",
    "                     \"lgreedy_epi_datasize_P3\",\"lgreedy_epi_task_select_P1\",\"lgreedy_epi_task_select_P2\",\"lgreedy_epi_task_select_P3\",\\\n",
    "                    \"lgreedy_epi_tran_latency_P1\",\"lgreedy_epi_tran_latency_P2\",\"lgreedy_epi_tran_latency_P3\",\\\n",
    "                    \"lgreedy_epi_comp_latency_P1\",\"lgreedy_epi_comp_latency_P2\",\"lgreedy_epi_comp_latency_P3\"])  # Writing header\n",
    "    writer.writerows(data)  # Writing data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPOR-vhHGnKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0IPp62mG4OL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBbu3Rgm1yrC"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
